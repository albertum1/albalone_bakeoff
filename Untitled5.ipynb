{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "train_df = pd.read_csv('training_data.csv', index_col = 0)\n",
    "\n",
    "_columns = ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
    "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1',\n",
    "       'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "       'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5',\n",
    "       'PAY_AMT6', 'target']\n",
    "train_df.columns = _columns\n",
    "train_df.drop('ID', axis=0, inplace=True)\n",
    "\n",
    "for col in _columns:\n",
    "    try:\n",
    "        train_df[col] = train_df[col].astype('float64')\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    10516\n",
       "3     7919\n",
       "1     3713\n",
       "4      351\n",
       "Name: EDUCATION, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    train_df['EDUCATION'].eq(1),\n",
    "    train_df['EDUCATION'].eq(2),\n",
    "    train_df['EDUCATION'].eq(3)\n",
    "]\n",
    "choices = [\n",
    "    3,\n",
    "    2,\n",
    "    1\n",
    "]\n",
    "\n",
    "train_df['EDUCATION'] = np.select(conditions, choices, 4)\n",
    "train_df['EDUCATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    12026\n",
       "1    10195\n",
       "3      278\n",
       "Name: MARRIAGE, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    train_df['MARRIAGE'].eq(1),\n",
    "    train_df['MARRIAGE'].eq(2),\n",
    "]\n",
    "choices = [\n",
    "    1,\n",
    "    2\n",
    "]\n",
    "\n",
    "train_df['MARRIAGE'] = np.select(conditions, choices, 3)\n",
    "train_df['MARRIAGE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28835</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222598.0</td>\n",
       "      <td>222168.0</td>\n",
       "      <td>217900.0</td>\n",
       "      <td>221193.0</td>\n",
       "      <td>181859.0</td>\n",
       "      <td>184605.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>8018.0</td>\n",
       "      <td>10121.0</td>\n",
       "      <td>6006.0</td>\n",
       "      <td>10987.0</td>\n",
       "      <td>143779.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25329</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18894</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51372.0</td>\n",
       "      <td>51872.0</td>\n",
       "      <td>47593.0</td>\n",
       "      <td>43882.0</td>\n",
       "      <td>42256.0</td>\n",
       "      <td>42527.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8257.0</td>\n",
       "      <td>7995.0</td>\n",
       "      <td>4878.0</td>\n",
       "      <td>5444.0</td>\n",
       "      <td>2639.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "28835   220000.0  2.0          3         2  36.0    0.0    0.0    0.0    0.0   \n",
       "25329   200000.0  2.0          1         2  29.0   -1.0   -1.0   -1.0   -1.0   \n",
       "18894   180000.0  2.0          3         2  27.0   -2.0   -2.0   -2.0   -2.0   \n",
       "690      80000.0  1.0          2         2  32.0    0.0    0.0    0.0    0.0   \n",
       "6239     10000.0  1.0          2         2  27.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "28835    0.0    0.0   222598.0   222168.0   217900.0   221193.0   181859.0   \n",
       "25329   -1.0   -1.0      326.0      326.0      326.0      326.0      326.0   \n",
       "18894   -2.0   -2.0        0.0        0.0        0.0        0.0        0.0   \n",
       "690      0.0    0.0    51372.0    51872.0    47593.0    43882.0    42256.0   \n",
       "6239     0.0    0.0     8257.0     7995.0     4878.0     5444.0     2639.0   \n",
       "\n",
       "       BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "28835   184605.0   10000.0    8018.0   10121.0    6006.0   10987.0  143779.0   \n",
       "25329      326.0     326.0     326.0     326.0     326.0     326.0     326.0   \n",
       "18894        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "690      42527.0    1853.0    1700.0    1522.0    1548.0    1488.0    1500.0   \n",
       "6239      2697.0    2000.0    1100.0     600.0     300.0     300.0    1000.0   \n",
       "\n",
       "       target  \n",
       "28835     1.0  \n",
       "25329     0.0  \n",
       "18894     0.0  \n",
       "690       0.0  \n",
       "6239      1.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def return_slope_pay_amt(_x):\n",
    "    _slope = stats.linregress(x= list(range(1,7)),\n",
    "                             y= [_x['PAY_AMT6'],_x['PAY_AMT5'],_x['PAY_AMT4'], \n",
    "                                 _x['PAY_AMT3'],_x['PAY_AMT2'],_x['PAY_AMT1']])[0]\n",
    "    return _slope\n",
    "\n",
    "def return_slope_bill_amt(_x):\n",
    "    _slope = stats.linregress(x= list(range(1,7)),\n",
    "                             y= [_x['BILL_AMT6'],_x['BILL_AMT5'],_x['BILL_AMT4'], \n",
    "                                 _x['BILL_AMT3'],_x['BILL_AMT2'],_x['BILL_AMT1']])[0]\n",
    "    return _slope\n",
    "\n",
    "def return_slope_pay(_x):\n",
    "    _slope = stats.linregress(x= list(range(1,7)),\n",
    "                             y= [_x['PAY_6'],_x['PAY_5'],_x['PAY_4'], \n",
    "                                 _x['PAY_3'],_x['PAY_2'],_x['PAY_0']])[0]\n",
    "    return _slope\n",
    "\n",
    "train_df['PAY_AMT_SLOPE'] = train_df.apply(return_slope_pay_amt, axis=1)\n",
    "train_df['BILL_AMT_SLOPE'] = train_df.apply(return_slope_bill_amt, axis=1)\n",
    "train_df['PAY_SLOPE'] = train_df.apply(return_slope_pay, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>target</th>\n",
       "      <th>PAY_AMT_SLOPE</th>\n",
       "      <th>BILL_AMT_SLOPE</th>\n",
       "      <th>PAY_SLOPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28835</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222598.0</td>\n",
       "      <td>222168.0</td>\n",
       "      <td>217900.0</td>\n",
       "      <td>221193.0</td>\n",
       "      <td>181859.0</td>\n",
       "      <td>184605.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>8018.0</td>\n",
       "      <td>10121.0</td>\n",
       "      <td>6006.0</td>\n",
       "      <td>10987.0</td>\n",
       "      <td>143779.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-19248.200000</td>\n",
       "      <td>8788.542857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25329</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18894</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51372.0</td>\n",
       "      <td>51872.0</td>\n",
       "      <td>47593.0</td>\n",
       "      <td>43882.0</td>\n",
       "      <td>42256.0</td>\n",
       "      <td>42527.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.857143</td>\n",
       "      <td>2193.828571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8257.0</td>\n",
       "      <td>7995.0</td>\n",
       "      <td>4878.0</td>\n",
       "      <td>5444.0</td>\n",
       "      <td>2639.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>1237.200000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "28835   220000.0  2.0          3         2  36.0    0.0    0.0    0.0    0.0   \n",
       "25329   200000.0  2.0          1         2  29.0   -1.0   -1.0   -1.0   -1.0   \n",
       "18894   180000.0  2.0          3         2  27.0   -2.0   -2.0   -2.0   -2.0   \n",
       "690      80000.0  1.0          2         2  32.0    0.0    0.0    0.0    0.0   \n",
       "6239     10000.0  1.0          2         2  27.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "28835    0.0    0.0   222598.0   222168.0   217900.0   221193.0   181859.0   \n",
       "25329   -1.0   -1.0      326.0      326.0      326.0      326.0      326.0   \n",
       "18894   -2.0   -2.0        0.0        0.0        0.0        0.0        0.0   \n",
       "690      0.0    0.0    51372.0    51872.0    47593.0    43882.0    42256.0   \n",
       "6239     0.0    0.0     8257.0     7995.0     4878.0     5444.0     2639.0   \n",
       "\n",
       "       BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "28835   184605.0   10000.0    8018.0   10121.0    6006.0   10987.0  143779.0   \n",
       "25329      326.0     326.0     326.0     326.0     326.0     326.0     326.0   \n",
       "18894        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "690      42527.0    1853.0    1700.0    1522.0    1548.0    1488.0    1500.0   \n",
       "6239      2697.0    2000.0    1100.0     600.0     300.0     300.0    1000.0   \n",
       "\n",
       "       target  PAY_AMT_SLOPE  BILL_AMT_SLOPE  PAY_SLOPE  \n",
       "28835     1.0  -19248.200000     8788.542857        0.0  \n",
       "25329     0.0       0.000000        0.000000        0.0  \n",
       "18894     0.0       0.000000        0.000000        0.0  \n",
       "690       0.0      67.857143     2193.828571        0.0  \n",
       "6239      1.0     220.000000     1237.200000        0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.000000    11196\n",
       " 0.285714      781\n",
       "-0.142857      765\n",
       " 0.428571      624\n",
       " 0.228571      619\n",
       "             ...  \n",
       " 0.457143        1\n",
       "-0.028571        1\n",
       " 0.828571        1\n",
       "-0.142857        1\n",
       "-0.085714        1\n",
       "Name: PAY_SLOPE, Length: 146, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['PAY_SLOPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def return_slope_pay_amt(_x):\n",
    "    _slope = stats.linregress(x= list(range(1,7)),\n",
    "                             y= [_x['PAY_AMT6'],_x['PAY_AMT5'],_x['PAY_AMT4'], \n",
    "                                 _x['PAY_AMT3'],_x['PAY_AMT2'],_x['PAY_AMT1']])[0]\n",
    "    return _slope\n",
    "\n",
    "def return_slope_bill_amt(_x):\n",
    "    _slope = stats.linregress(x= list(range(1,7)),\n",
    "                             y= [_x['BILL_AMT6'],_x['BILL_AMT5'],_x['BILL_AMT4'], \n",
    "                                 _x['BILL_AMT3'],_x['BILL_AMT2'],_x['BILL_AMT1']])[0]\n",
    "    return _slope\n",
    "\n",
    "def return_slope_pay(_x):\n",
    "    _slope = stats.linregress(x= list(range(1,7)),\n",
    "                             y= [_x['PAY_6'],_x['PAY_5'],_x['PAY_4'], \n",
    "                                 _x['PAY_3'],_x['PAY_2'],_x['PAY_0']])[0]\n",
    "    return _slope\n",
    "\n",
    "train_df['PAY_AMT_SLOPE'] = train_df.apply(return_slope_pay_amt, axis=1)\n",
    "train_df['BILL_AMT_SLOPE'] = train_df.apply(return_slope_bill_amt, axis=1)\n",
    "train_df['PAY_SLOPE'] = train_df.apply(return_slope_pay, axis=1)\n",
    "\n",
    "def return_std_pay_amt(_x):\n",
    "    _std = np.std([_x['PAY_AMT6'],_x['PAY_AMT5'],_x['PAY_AMT4'], \n",
    "                                 _x['PAY_AMT3'],_x['PAY_AMT2'],_x['PAY_AMT1']])\n",
    "    return _std\n",
    "\n",
    "def return_std_bill_amt(_x):\n",
    "    _std = np.std([_x['BILL_AMT6'],_x['BILL_AMT5'],_x['BILL_AMT4'], \n",
    "                                 _x['BILL_AMT3'],_x['BILL_AMT2'],_x['BILL_AMT1']])\n",
    "    return _std\n",
    "train_df['PAY_AMT_STD'] = train_df.apply(return_std_pay_amt, axis=1)\n",
    "train_df['BILL_AMT_STD'] = train_df.apply(return_std_bill_amt, axis=1)\n",
    "\n",
    "\n",
    "def return_mean_pay_amt(_x):\n",
    "    _mean = np.mean([_x['PAY_AMT6'],_x['PAY_AMT5'],_x['PAY_AMT4'], \n",
    "                                 _x['PAY_AMT3'],_x['PAY_AMT2'],_x['PAY_AMT1']])\n",
    "    return _mean\n",
    "\n",
    "def return_mean_bill_amt(_x):\n",
    "    _mean = np.mean([_x['BILL_AMT6'],_x['BILL_AMT5'],_x['BILL_AMT4'], \n",
    "                                 _x['BILL_AMT3'],_x['BILL_AMT2'],_x['BILL_AMT1']])\n",
    "    return _mean\n",
    "train_df['PAY_AMT_MEAN'] = train_df.apply(return_mean_pay_amt, axis=1)\n",
    "train_df['BILL_AMT_MEAN'] = train_df.apply(return_std_bill_amt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (train_df['BILL_AMT6'] == train_df['PAY_AMT5']) & (train_df['BILL_AMT6'] != 0)\n",
    "]\n",
    "choices = [\n",
    "    1\n",
    "]\n",
    "\n",
    "train_df['PAID_BILL_AMT6_FULL'] = np.select(conditions, choices, 0)\n",
    "\n",
    "conditions = [\n",
    "    (train_df['BILL_AMT5'] == train_df['PAY_AMT4']) & (train_df['BILL_AMT5'] != 0)\n",
    "]\n",
    "choices = [\n",
    "    1\n",
    "]\n",
    "\n",
    "train_df['PAID_BILL_AMT5_FULL'] = np.select(conditions, choices, 0)\n",
    "\n",
    "conditions = [\n",
    "    (train_df['BILL_AMT4'] == train_df['PAY_AMT3']) & (train_df['BILL_AMT4'] != 0)\n",
    "]\n",
    "choices = [\n",
    "    1\n",
    "]\n",
    "\n",
    "train_df['PAID_BILL_AMT4_FULL'] = np.select(conditions, choices, 0)\n",
    "\n",
    "conditions = [\n",
    "    (train_df['BILL_AMT3'] == train_df['PAY_AMT2']) & (train_df['BILL_AMT3'] != 0)\n",
    "]\n",
    "choices = [\n",
    "    1\n",
    "]\n",
    "\n",
    "train_df['PAID_BILL_AMT3_FULL'] = np.select(conditions, choices, 0)\n",
    "\n",
    "conditions = [\n",
    "    (train_df['BILL_AMT2'] == train_df['PAY_AMT1']) & (train_df['BILL_AMT2'] != 0)\n",
    "]\n",
    "choices = [\n",
    "    1\n",
    "]\n",
    "\n",
    "train_df['PAID_BILL_AMT2_FULL'] = np.select(conditions, choices, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TOTAL_PAID_BILL_FULL'] = train_df['PAID_BILL_AMT6_FULL'] + train_df['PAID_BILL_AMT5_FULL'] + train_df['PAID_BILL_AMT4_FULL'] + train_df['PAID_BILL_AMT3_FULL'] + train_df['PAID_BILL_AMT2_FULL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (train_df['BILL_AMT6'] != train_df['PAY_AMT5']) & (train_df['BILL_AMT6'] < 0)\n",
    "]\n",
    "choices = [\n",
    "    1\n",
    "]\n",
    "\n",
    "train_df['PAID_BILL_AMT6_PARTIAL'] = np.select(conditions, choices, 0)\n",
    "\n",
    "\n",
    "conditions = [\n",
    "    (train_df['BILL_AMT5'] != train_df['PAY_AMT4']) & (train_df['BILL_AMT5'] < 0)\n",
    "]\n",
    "choices = [\n",
    "    1\n",
    "]\n",
    "\n",
    "train_df['PAID_BILL_AMT5_PARTIAL'] = np.select(conditions, choices, 0)\n",
    "\n",
    "\n",
    "conditions = [\n",
    "    (train_df['BILL_AMT4'] != train_df['PAY_AMT3']) & (train_df['BILL_AMT4'] < 0)\n",
    "]\n",
    "choices = [\n",
    "    1\n",
    "]\n",
    "\n",
    "train_df['PAID_BILL_AMT4_PARTIAL'] = np.select(conditions, choices, 0)\n",
    "\n",
    "\n",
    "\n",
    "conditions = [\n",
    "    (train_df['BILL_AMT3'] != train_df['PAY_AMT2']) & (train_df['BILL_AMT3'] < 0)\n",
    "]\n",
    "choices = [\n",
    "    1\n",
    "]\n",
    "\n",
    "train_df['PAID_BILL_AMT3_PARTIAL'] = np.select(conditions, choices, 0)\n",
    "\n",
    "conditions = [\n",
    "    (train_df['BILL_AMT2'] != train_df['PAY_AMT1']) & (train_df['BILL_AMT2'] < 0)\n",
    "]\n",
    "choices = [\n",
    "    1\n",
    "]\n",
    "\n",
    "train_df['PAID_BILL_AMT2_PARTIAL'] = np.select(conditions, choices, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TOTAL_PAY'] = train_df['PAY_0'] + train_df['PAY_2'] + train_df['PAY_3'] +train_df['PAY_4'] + train_df['PAY_5'] + train_df['PAY_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['BILL_AMT1_SIN'] = np.sin(train_df['BILL_AMT1'])\n",
    "train_df['BILL_AMT2_SIN'] = np.sin(train_df['BILL_AMT2'])\n",
    "train_df['BILL_AMT3_SIN'] = np.sin(train_df['BILL_AMT3'])\n",
    "train_df['BILL_AMT4_SIN'] = np.sin(train_df['BILL_AMT4'])\n",
    "train_df['BILL_AMT5_SIN'] = np.sin(train_df['BILL_AMT5'])\n",
    "train_df['BILL_AMT6_SIN'] = np.sin(train_df['BILL_AMT6'])\n",
    "train_df['BILL_AMT1_COS'] = np.cos(train_df['BILL_AMT1'])\n",
    "train_df['BILL_AMT2_COS'] = np.cos(train_df['BILL_AMT2'])\n",
    "train_df['BILL_AMT3_COS'] = np.cos(train_df['BILL_AMT3'])\n",
    "train_df['BILL_AMT4_COS'] = np.cos(train_df['BILL_AMT4'])\n",
    "train_df['BILL_AMT5_COS'] = np.cos(train_df['BILL_AMT5'])\n",
    "train_df['BILL_AMT6_COS'] = np.cos(train_df['BILL_AMT6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['PAYL_AMT1_SIN'] = np.sin(train_df['BILL_AMT1'])\n",
    "train_df['PAYL_AMT2_SIN'] = np.sin(train_df['BILL_AMT2'])\n",
    "train_df['PAYL_AMT3_SIN'] = np.sin(train_df['BILL_AMT3'])\n",
    "train_df['PAYL_AMT4_SIN'] = np.sin(train_df['BILL_AMT4'])\n",
    "train_df['PAYL_AMT5_SIN'] = np.sin(train_df['BILL_AMT5'])\n",
    "train_df['PAYL_AMT6_SIN'] = np.sin(train_df['BILL_AMT6'])\n",
    "train_df['PAYL_AMT1_COS'] = np.cos(train_df['BILL_AMT1'])\n",
    "train_df['PAYL_AMT2_COS'] = np.cos(train_df['BILL_AMT2'])\n",
    "train_df['PAYL_AMT3_COS'] = np.cos(train_df['BILL_AMT3'])\n",
    "train_df['PAYL_AMT4_COS'] = np.cos(train_df['BILL_AMT4'])\n",
    "train_df['PAYL_AMT5_COS'] = np.cos(train_df['BILL_AMT5'])\n",
    "train_df['PAYL_AMT6_COS'] = np.cos(train_df['BILL_AMT6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>target</th>\n",
       "      <th>PAY_AMT_SLOPE</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTAL_PAY</th>\n",
       "      <th>BILL_AMT1_SIN</th>\n",
       "      <th>BILL_AMT2_SIN</th>\n",
       "      <th>BILL_AMT3_SIN</th>\n",
       "      <th>BILL_AMT4_SIN</th>\n",
       "      <th>BILL_AMT5_SIN</th>\n",
       "      <th>BILL_AMT6_SIN</th>\n",
       "      <th>BILL_AMT1_COS</th>\n",
       "      <th>BILL_AMT2_COS</th>\n",
       "      <th>BILL_AMT3_COS</th>\n",
       "      <th>BILL_AMT4_COS</th>\n",
       "      <th>BILL_AMT5_COS</th>\n",
       "      <th>BILL_AMT6_COS</th>\n",
       "      <th>PAYL_AMT1_SIN</th>\n",
       "      <th>PAYL_AMT2_SIN</th>\n",
       "      <th>PAYL_AMT3_SIN</th>\n",
       "      <th>PAYL_AMT4_SIN</th>\n",
       "      <th>PAYL_AMT5_SIN</th>\n",
       "      <th>PAYL_AMT6_SIN</th>\n",
       "      <th>PAYL_AMT1_COS</th>\n",
       "      <th>PAYL_AMT2_COS</th>\n",
       "      <th>PAYL_AMT3_COS</th>\n",
       "      <th>PAYL_AMT4_COS</th>\n",
       "      <th>PAYL_AMT5_COS</th>\n",
       "      <th>PAYL_AMT6_COS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28835</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222598.0</td>\n",
       "      <td>222168.0</td>\n",
       "      <td>217900.0</td>\n",
       "      <td>221193.0</td>\n",
       "      <td>181859.0</td>\n",
       "      <td>184605.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>8018.0</td>\n",
       "      <td>10121.0</td>\n",
       "      <td>6006.0</td>\n",
       "      <td>10987.0</td>\n",
       "      <td>143779.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-19248.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>0.751758</td>\n",
       "      <td>-0.762037</td>\n",
       "      <td>-0.252781</td>\n",
       "      <td>-0.998473</td>\n",
       "      <td>-0.954360</td>\n",
       "      <td>-0.899344</td>\n",
       "      <td>0.659439</td>\n",
       "      <td>0.647534</td>\n",
       "      <td>0.967523</td>\n",
       "      <td>0.055237</td>\n",
       "      <td>0.298658</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>0.751758</td>\n",
       "      <td>-0.762037</td>\n",
       "      <td>-0.252781</td>\n",
       "      <td>-0.998473</td>\n",
       "      <td>-0.954360</td>\n",
       "      <td>-0.899344</td>\n",
       "      <td>0.659439</td>\n",
       "      <td>0.647534</td>\n",
       "      <td>0.967523</td>\n",
       "      <td>0.055237</td>\n",
       "      <td>0.298658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25329</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>-0.663611</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>0.748078</td>\n",
       "      <td>0.748078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18894</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51372.0</td>\n",
       "      <td>51872.0</td>\n",
       "      <td>47593.0</td>\n",
       "      <td>43882.0</td>\n",
       "      <td>42256.0</td>\n",
       "      <td>42527.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.626402</td>\n",
       "      <td>-0.918273</td>\n",
       "      <td>-0.848366</td>\n",
       "      <td>0.231690</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.674104</td>\n",
       "      <td>0.779500</td>\n",
       "      <td>-0.395948</td>\n",
       "      <td>-0.529411</td>\n",
       "      <td>0.972790</td>\n",
       "      <td>-0.008013</td>\n",
       "      <td>-0.738636</td>\n",
       "      <td>0.626402</td>\n",
       "      <td>-0.918273</td>\n",
       "      <td>-0.848366</td>\n",
       "      <td>0.231690</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.674104</td>\n",
       "      <td>0.779500</td>\n",
       "      <td>-0.395948</td>\n",
       "      <td>-0.529411</td>\n",
       "      <td>0.972790</td>\n",
       "      <td>-0.008013</td>\n",
       "      <td>-0.738636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8257.0</td>\n",
       "      <td>7995.0</td>\n",
       "      <td>4878.0</td>\n",
       "      <td>5444.0</td>\n",
       "      <td>2639.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.779900</td>\n",
       "      <td>0.345999</td>\n",
       "      <td>0.779202</td>\n",
       "      <td>0.370984</td>\n",
       "      <td>0.062131</td>\n",
       "      <td>0.998359</td>\n",
       "      <td>0.625904</td>\n",
       "      <td>-0.938235</td>\n",
       "      <td>-0.626773</td>\n",
       "      <td>-0.928639</td>\n",
       "      <td>0.998068</td>\n",
       "      <td>0.057262</td>\n",
       "      <td>0.779900</td>\n",
       "      <td>0.345999</td>\n",
       "      <td>0.779202</td>\n",
       "      <td>0.370984</td>\n",
       "      <td>0.062131</td>\n",
       "      <td>0.998359</td>\n",
       "      <td>0.625904</td>\n",
       "      <td>-0.938235</td>\n",
       "      <td>-0.626773</td>\n",
       "      <td>-0.928639</td>\n",
       "      <td>0.998068</td>\n",
       "      <td>0.057262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "28835   220000.0  2.0          3         2  36.0    0.0    0.0    0.0    0.0   \n",
       "25329   200000.0  2.0          1         2  29.0   -1.0   -1.0   -1.0   -1.0   \n",
       "18894   180000.0  2.0          3         2  27.0   -2.0   -2.0   -2.0   -2.0   \n",
       "690      80000.0  1.0          2         2  32.0    0.0    0.0    0.0    0.0   \n",
       "6239     10000.0  1.0          2         2  27.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "28835    0.0    0.0   222598.0   222168.0   217900.0   221193.0   181859.0   \n",
       "25329   -1.0   -1.0      326.0      326.0      326.0      326.0      326.0   \n",
       "18894   -2.0   -2.0        0.0        0.0        0.0        0.0        0.0   \n",
       "690      0.0    0.0    51372.0    51872.0    47593.0    43882.0    42256.0   \n",
       "6239     0.0    0.0     8257.0     7995.0     4878.0     5444.0     2639.0   \n",
       "\n",
       "       BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "28835   184605.0   10000.0    8018.0   10121.0    6006.0   10987.0  143779.0   \n",
       "25329      326.0     326.0     326.0     326.0     326.0     326.0     326.0   \n",
       "18894        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "690      42527.0    1853.0    1700.0    1522.0    1548.0    1488.0    1500.0   \n",
       "6239      2697.0    2000.0    1100.0     600.0     300.0     300.0    1000.0   \n",
       "\n",
       "       target  PAY_AMT_SLOPE  ...  TOTAL_PAY  BILL_AMT1_SIN  BILL_AMT2_SIN  \\\n",
       "28835     1.0  -19248.200000  ...        0.0      -0.437242       0.751758   \n",
       "25329     0.0       0.000000  ...       -6.0      -0.663611      -0.663611   \n",
       "18894     0.0       0.000000  ...      -12.0       0.000000       0.000000   \n",
       "690       0.0      67.857143  ...        0.0       0.626402      -0.918273   \n",
       "6239      1.0     220.000000  ...        0.0       0.779900       0.345999   \n",
       "\n",
       "       BILL_AMT3_SIN  BILL_AMT4_SIN  BILL_AMT5_SIN  BILL_AMT6_SIN  \\\n",
       "28835      -0.762037      -0.252781      -0.998473      -0.954360   \n",
       "25329      -0.663611      -0.663611      -0.663611      -0.663611   \n",
       "18894       0.000000       0.000000       0.000000       0.000000   \n",
       "690        -0.848366       0.231690       0.999968       0.674104   \n",
       "6239        0.779202       0.370984       0.062131       0.998359   \n",
       "\n",
       "       BILL_AMT1_COS  BILL_AMT2_COS  BILL_AMT3_COS  BILL_AMT4_COS  \\\n",
       "28835      -0.899344       0.659439       0.647534       0.967523   \n",
       "25329       0.748078       0.748078       0.748078       0.748078   \n",
       "18894       1.000000       1.000000       1.000000       1.000000   \n",
       "690         0.779500      -0.395948      -0.529411       0.972790   \n",
       "6239        0.625904      -0.938235      -0.626773      -0.928639   \n",
       "\n",
       "       BILL_AMT5_COS  BILL_AMT6_COS  PAYL_AMT1_SIN  PAYL_AMT2_SIN  \\\n",
       "28835       0.055237       0.298658      -0.437242       0.751758   \n",
       "25329       0.748078       0.748078      -0.663611      -0.663611   \n",
       "18894       1.000000       1.000000       0.000000       0.000000   \n",
       "690        -0.008013      -0.738636       0.626402      -0.918273   \n",
       "6239        0.998068       0.057262       0.779900       0.345999   \n",
       "\n",
       "       PAYL_AMT3_SIN  PAYL_AMT4_SIN  PAYL_AMT5_SIN  PAYL_AMT6_SIN  \\\n",
       "28835      -0.762037      -0.252781      -0.998473      -0.954360   \n",
       "25329      -0.663611      -0.663611      -0.663611      -0.663611   \n",
       "18894       0.000000       0.000000       0.000000       0.000000   \n",
       "690        -0.848366       0.231690       0.999968       0.674104   \n",
       "6239        0.779202       0.370984       0.062131       0.998359   \n",
       "\n",
       "       PAYL_AMT1_COS  PAYL_AMT2_COS  PAYL_AMT3_COS  PAYL_AMT4_COS  \\\n",
       "28835      -0.899344       0.659439       0.647534       0.967523   \n",
       "25329       0.748078       0.748078       0.748078       0.748078   \n",
       "18894       1.000000       1.000000       1.000000       1.000000   \n",
       "690         0.779500      -0.395948      -0.529411       0.972790   \n",
       "6239        0.625904      -0.938235      -0.626773      -0.928639   \n",
       "\n",
       "       PAYL_AMT5_COS  PAYL_AMT6_COS  \n",
       "28835       0.055237       0.298658  \n",
       "25329       0.748078       0.748078  \n",
       "18894       1.000000       1.000000  \n",
       "690        -0.008013      -0.738636  \n",
       "6239        0.998068       0.057262  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=['target'])\n",
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X.columns:\n",
    "    X[i+'_PAY_0'] = X[i] * X['PAY_0']\n",
    "#     X[i+'_TOTAL_PAY'] = X[i] * X['TOTAL_PAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>LIMIT_BAL_PAY_0</th>\n",
       "      <th>SEX_PAY_0</th>\n",
       "      <th>EDUCATION_PAY_0</th>\n",
       "      <th>MARRIAGE_PAY_0</th>\n",
       "      <th>AGE_PAY_0</th>\n",
       "      <th>PAY_0_PAY_0</th>\n",
       "      <th>PAY_2_PAY_0</th>\n",
       "      <th>PAY_3_PAY_0</th>\n",
       "      <th>PAY_4_PAY_0</th>\n",
       "      <th>PAY_5_PAY_0</th>\n",
       "      <th>PAY_6_PAY_0</th>\n",
       "      <th>BILL_AMT1_PAY_0</th>\n",
       "      <th>BILL_AMT2_PAY_0</th>\n",
       "      <th>BILL_AMT3_PAY_0</th>\n",
       "      <th>BILL_AMT4_PAY_0</th>\n",
       "      <th>BILL_AMT5_PAY_0</th>\n",
       "      <th>BILL_AMT6_PAY_0</th>\n",
       "      <th>PAY_AMT1_PAY_0</th>\n",
       "      <th>PAY_AMT2_PAY_0</th>\n",
       "      <th>PAY_AMT3_PAY_0</th>\n",
       "      <th>PAY_AMT4_PAY_0</th>\n",
       "      <th>PAY_AMT5_PAY_0</th>\n",
       "      <th>PAY_AMT6_PAY_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28835</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222598.0</td>\n",
       "      <td>222168.0</td>\n",
       "      <td>217900.0</td>\n",
       "      <td>221193.0</td>\n",
       "      <td>181859.0</td>\n",
       "      <td>184605.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>8018.0</td>\n",
       "      <td>10121.0</td>\n",
       "      <td>6006.0</td>\n",
       "      <td>10987.0</td>\n",
       "      <td>143779.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25329</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>-200000.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18894</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-360000.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51372.0</td>\n",
       "      <td>51872.0</td>\n",
       "      <td>47593.0</td>\n",
       "      <td>43882.0</td>\n",
       "      <td>42256.0</td>\n",
       "      <td>42527.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8257.0</td>\n",
       "      <td>7995.0</td>\n",
       "      <td>4878.0</td>\n",
       "      <td>5444.0</td>\n",
       "      <td>2639.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16247</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35183.0</td>\n",
       "      <td>39197.0</td>\n",
       "      <td>39477.0</td>\n",
       "      <td>39924.0</td>\n",
       "      <td>39004.0</td>\n",
       "      <td>41462.0</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3069.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>350000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>3138.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>8210.0</td>\n",
       "      <td>3138.0</td>\n",
       "      <td>4160.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>8210.0</td>\n",
       "      <td>9731.0</td>\n",
       "      <td>-350000.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3800.0</td>\n",
       "      <td>-3138.0</td>\n",
       "      <td>-4150.0</td>\n",
       "      <td>-3750.0</td>\n",
       "      <td>-1362.0</td>\n",
       "      <td>-8210.0</td>\n",
       "      <td>-3138.0</td>\n",
       "      <td>-4160.0</td>\n",
       "      <td>-3750.0</td>\n",
       "      <td>-2272.0</td>\n",
       "      <td>-8210.0</td>\n",
       "      <td>-9731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7856.0</td>\n",
       "      <td>16544.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7856.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7856.0</td>\n",
       "      <td>16544.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7856.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20213</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5141.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>6906.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3754.0</td>\n",
       "      <td>6906.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20000.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5141.0</td>\n",
       "      <td>-3455.0</td>\n",
       "      <td>-6906.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3754.0</td>\n",
       "      <td>-6906.0</td>\n",
       "      <td>-290.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7624</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11729.0</td>\n",
       "      <td>12236.0</td>\n",
       "      <td>17994.0</td>\n",
       "      <td>17412.0</td>\n",
       "      <td>18422.0</td>\n",
       "      <td>18768.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11729.0</td>\n",
       "      <td>12236.0</td>\n",
       "      <td>17994.0</td>\n",
       "      <td>17412.0</td>\n",
       "      <td>18422.0</td>\n",
       "      <td>18768.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22499 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "28835   220000.0  2.0          3         2  36.0    0.0    0.0    0.0    0.0   \n",
       "25329   200000.0  2.0          1         2  29.0   -1.0   -1.0   -1.0   -1.0   \n",
       "18894   180000.0  2.0          3         2  27.0   -2.0   -2.0   -2.0   -2.0   \n",
       "690      80000.0  1.0          2         2  32.0    0.0    0.0    0.0    0.0   \n",
       "6239     10000.0  1.0          2         2  27.0    0.0    0.0    0.0    0.0   \n",
       "...          ...  ...        ...       ...   ...    ...    ...    ...    ...   \n",
       "16247    40000.0  2.0          2         1  38.0    0.0    0.0    3.0    2.0   \n",
       "2693    350000.0  1.0          3         1  42.0   -1.0   -1.0   -1.0   -1.0   \n",
       "8076    100000.0  2.0          1         2  46.0    1.0   -1.0    2.0    2.0   \n",
       "20213    20000.0  2.0          1         1  50.0   -1.0   -1.0   -1.0   -1.0   \n",
       "7624     20000.0  2.0          3         2  25.0    1.0    2.0    2.0    2.0   \n",
       "\n",
       "       PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "28835    0.0    0.0   222598.0   222168.0   217900.0   221193.0   181859.0   \n",
       "25329   -1.0   -1.0      326.0      326.0      326.0      326.0      326.0   \n",
       "18894   -2.0   -2.0        0.0        0.0        0.0        0.0        0.0   \n",
       "690      0.0    0.0    51372.0    51872.0    47593.0    43882.0    42256.0   \n",
       "6239     0.0    0.0     8257.0     7995.0     4878.0     5444.0     2639.0   \n",
       "...      ...    ...        ...        ...        ...        ...        ...   \n",
       "16247    2.0    2.0    35183.0    39197.0    39477.0    39924.0    39004.0   \n",
       "2693    -1.0   -1.0     3800.0     3138.0     4150.0     3750.0     1362.0   \n",
       "8076    -1.0    0.0        0.0      203.0      203.0        0.0     7856.0   \n",
       "20213   -2.0   -2.0     5141.0     3455.0     6906.0        0.0        0.0   \n",
       "7624     2.0    2.0    11729.0    12236.0    17994.0    17412.0    18422.0   \n",
       "\n",
       "       BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "28835   184605.0   10000.0    8018.0   10121.0    6006.0   10987.0  143779.0   \n",
       "25329      326.0     326.0     326.0     326.0     326.0     326.0     326.0   \n",
       "18894        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "690      42527.0    1853.0    1700.0    1522.0    1548.0    1488.0    1500.0   \n",
       "6239      2697.0    2000.0    1100.0     600.0     300.0     300.0    1000.0   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "16247    41462.0    4600.0    1200.0    1400.0       0.0    3069.0       0.0   \n",
       "2693      8210.0    3138.0    4160.0    3750.0    2272.0    8210.0    9731.0   \n",
       "8076     16544.0     203.0       0.0       0.0    7856.0   10000.0     865.0   \n",
       "20213        0.0    3754.0    6906.0     290.0       0.0       0.0       0.0   \n",
       "7624     18768.0    1000.0    6000.0       0.0    1600.0     800.0     800.0   \n",
       "\n",
       "       LIMIT_BAL_PAY_0  SEX_PAY_0  EDUCATION_PAY_0  MARRIAGE_PAY_0  AGE_PAY_0  \\\n",
       "28835              0.0        0.0              0.0             0.0        0.0   \n",
       "25329        -200000.0       -2.0             -1.0            -2.0      -29.0   \n",
       "18894        -360000.0       -4.0             -6.0            -4.0      -54.0   \n",
       "690                0.0        0.0              0.0             0.0        0.0   \n",
       "6239               0.0        0.0              0.0             0.0        0.0   \n",
       "...                ...        ...              ...             ...        ...   \n",
       "16247              0.0        0.0              0.0             0.0        0.0   \n",
       "2693         -350000.0       -1.0             -3.0            -1.0      -42.0   \n",
       "8076          100000.0        2.0              1.0             2.0       46.0   \n",
       "20213         -20000.0       -2.0             -1.0            -1.0      -50.0   \n",
       "7624           20000.0        2.0              3.0             2.0       25.0   \n",
       "\n",
       "       PAY_0_PAY_0  PAY_2_PAY_0  PAY_3_PAY_0  PAY_4_PAY_0  PAY_5_PAY_0  \\\n",
       "28835          0.0          0.0          0.0          0.0          0.0   \n",
       "25329          1.0          1.0          1.0          1.0          1.0   \n",
       "18894          4.0          4.0          4.0          4.0          4.0   \n",
       "690            0.0          0.0          0.0          0.0          0.0   \n",
       "6239           0.0          0.0          0.0          0.0          0.0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "16247          0.0          0.0          0.0          0.0          0.0   \n",
       "2693           1.0          1.0          1.0          1.0          1.0   \n",
       "8076           1.0         -1.0          2.0          2.0         -1.0   \n",
       "20213          1.0          1.0          1.0          1.0          2.0   \n",
       "7624           1.0          2.0          2.0          2.0          2.0   \n",
       "\n",
       "       PAY_6_PAY_0  BILL_AMT1_PAY_0  BILL_AMT2_PAY_0  BILL_AMT3_PAY_0  \\\n",
       "28835          0.0              0.0              0.0              0.0   \n",
       "25329          1.0           -326.0           -326.0           -326.0   \n",
       "18894          4.0             -0.0             -0.0             -0.0   \n",
       "690            0.0              0.0              0.0              0.0   \n",
       "6239           0.0              0.0              0.0              0.0   \n",
       "...            ...              ...              ...              ...   \n",
       "16247          0.0              0.0              0.0              0.0   \n",
       "2693           1.0          -3800.0          -3138.0          -4150.0   \n",
       "8076           0.0              0.0            203.0            203.0   \n",
       "20213          2.0          -5141.0          -3455.0          -6906.0   \n",
       "7624           2.0          11729.0          12236.0          17994.0   \n",
       "\n",
       "       BILL_AMT4_PAY_0  BILL_AMT5_PAY_0  BILL_AMT6_PAY_0  PAY_AMT1_PAY_0  \\\n",
       "28835              0.0              0.0              0.0             0.0   \n",
       "25329           -326.0           -326.0           -326.0          -326.0   \n",
       "18894             -0.0             -0.0             -0.0            -0.0   \n",
       "690                0.0              0.0              0.0             0.0   \n",
       "6239               0.0              0.0              0.0             0.0   \n",
       "...                ...              ...              ...             ...   \n",
       "16247              0.0              0.0              0.0             0.0   \n",
       "2693           -3750.0          -1362.0          -8210.0         -3138.0   \n",
       "8076               0.0           7856.0          16544.0           203.0   \n",
       "20213             -0.0             -0.0             -0.0         -3754.0   \n",
       "7624           17412.0          18422.0          18768.0          1000.0   \n",
       "\n",
       "       PAY_AMT2_PAY_0  PAY_AMT3_PAY_0  PAY_AMT4_PAY_0  PAY_AMT5_PAY_0  \\\n",
       "28835             0.0             0.0             0.0             0.0   \n",
       "25329          -326.0          -326.0          -326.0          -326.0   \n",
       "18894            -0.0            -0.0            -0.0            -0.0   \n",
       "690               0.0             0.0             0.0             0.0   \n",
       "6239              0.0             0.0             0.0             0.0   \n",
       "...               ...             ...             ...             ...   \n",
       "16247             0.0             0.0             0.0             0.0   \n",
       "2693          -4160.0         -3750.0         -2272.0         -8210.0   \n",
       "8076              0.0             0.0          7856.0         10000.0   \n",
       "20213         -6906.0          -290.0            -0.0            -0.0   \n",
       "7624           6000.0             0.0          1600.0           800.0   \n",
       "\n",
       "       PAY_AMT6_PAY_0  \n",
       "28835             0.0  \n",
       "25329          -326.0  \n",
       "18894            -0.0  \n",
       "690               0.0  \n",
       "6239              0.0  \n",
       "...               ...  \n",
       "16247             0.0  \n",
       "2693          -9731.0  \n",
       "8076            865.0  \n",
       "20213            -0.0  \n",
       "7624            800.0  \n",
       "\n",
       "[22499 rows x 46 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=0.2)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(data = X_train,\n",
    "                      columns = X.columns)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(data = X_test,\n",
    "                     columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.8289547682172411\n",
      "Testing Precision:  0.5069565217391304\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.7376322562196168\n",
      "Testing Recall:  0.5732546705998034\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.792715184443809\n",
      "Testing Accuracy:  0.7775555555555556\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.7806317382258369\n",
      "Testing F1-Score:  0.5380710659898477\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=0.2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=19, max_features=0.5,\n",
    "                       max_leaf_nodes=74, max_samples=0.66,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=13, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
    "                       warm_start=False)\n",
    "\n",
    "\n",
    "\n",
    "# parameters = {'max_leaf_nodes': range(10,100,1)}\n",
    "#     'min_samples_split': range(2,10,1)}\n",
    "#     'n_estimators': range(100, 500, 50)}\n",
    "#     'max_depth': range(10,25,1)}\n",
    "#              'min_samples_leaf': range(1,10,1),\n",
    "#              'class_weight': ['balanced',None,'balanced_subsample']}\n",
    "# grid_tree = GridSearchCV(rfc, parameters, cv=5, scoring='f1', n_jobs=-1,verbose=1)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "y_train_pred = rfc.predict(X_train)\n",
    "y_test_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 2, 32)\n",
    "    rf_max_leaf_nodes = trial.suggest_int('rf_max_leaf_nodes', 10, 64)\n",
    "    rf_max_features = trial.suggest_loguniform('rf_max_features', .1, .9)\n",
    "    rf_min_samples_leaf = trial.suggest_int('rf_min_samples_leaf', 2, 20)\n",
    "    rf_max_samples = trial.suggest_loguniform('rf_max_samples', .1, .9)\n",
    "    rf_criterion = trial.suggest_categorical('rf_criterion', ['gini', 'entropy'])\n",
    "    \n",
    "    regressor_obj = RandomForestClassifier(max_depth = rf_max_depth,\n",
    "                                          max_leaf_nodes = rf_max_leaf_nodes,\n",
    "                                          max_features = rf_max_features,\n",
    "                                          min_samples_leaf = rf_min_samples_leaf,\n",
    "                                          max_samples = rf_max_samples,\n",
    "                                          n_estimators=300,\n",
    "                                          random_state=42,\n",
    "                                          criterion = rf_criterion)\n",
    "    \n",
    "    regressor_obj.fit(X_train, y_train)\n",
    "    y_pred = regressor_obj.predict(X_test)\n",
    "    \n",
    "    return (1 - f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-12 16:16:34,924] Finished trial#0 with value: 0.4557019536574285 with parameters: {'rf_max_depth': 13, 'rf_max_leaf_nodes': 63, 'rf_max_features': 0.2440939167975394, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.11831099836488107, 'rf_criterion': 'gini'}. Best is trial#0 with value: 0.4557019536574285.\n",
      "[I 2020-08-12 16:16:53,759] Finished trial#1 with value: 0.4588665447897624 with parameters: {'rf_max_depth': 19, 'rf_max_leaf_nodes': 62, 'rf_max_features': 0.2058985718792555, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.34024558480495526, 'rf_criterion': 'entropy'}. Best is trial#0 with value: 0.4557019536574285.\n",
      "[I 2020-08-12 16:17:01,153] Finished trial#2 with value: 0.459016393442623 with parameters: {'rf_max_depth': 28, 'rf_max_leaf_nodes': 32, 'rf_max_features': 0.12618076969354372, 'rf_min_samples_leaf': 16, 'rf_max_samples': 0.23164372785422654, 'rf_criterion': 'entropy'}. Best is trial#0 with value: 0.4557019536574285.\n",
      "[I 2020-08-12 16:17:04,953] Finished trial#3 with value: 0.45341018251681076 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 22, 'rf_max_features': 0.1589878665017714, 'rf_min_samples_leaf': 15, 'rf_max_samples': 0.1416283921664019, 'rf_criterion': 'gini'}. Best is trial#3 with value: 0.45341018251681076.\n",
      "[I 2020-08-12 16:17:15,519] Finished trial#4 with value: 0.46238532110091746 with parameters: {'rf_max_depth': 26, 'rf_max_leaf_nodes': 37, 'rf_max_features': 0.1154528878441199, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.7403955888665816, 'rf_criterion': 'gini'}. Best is trial#3 with value: 0.45341018251681076.\n",
      "[I 2020-08-12 16:17:41,246] Finished trial#5 with value: 0.46112115732368897 with parameters: {'rf_max_depth': 18, 'rf_max_leaf_nodes': 29, 'rf_max_features': 0.4384048923272737, 'rf_min_samples_leaf': 16, 'rf_max_samples': 0.5118488396573054, 'rf_criterion': 'gini'}. Best is trial#3 with value: 0.45341018251681076.\n",
      "[I 2020-08-12 16:18:03,155] Finished trial#6 with value: 0.459927140255009 with parameters: {'rf_max_depth': 28, 'rf_max_leaf_nodes': 29, 'rf_max_features': 0.3531547678642063, 'rf_min_samples_leaf': 16, 'rf_max_samples': 0.5419847528970755, 'rf_criterion': 'gini'}. Best is trial#3 with value: 0.45341018251681076.\n",
      "[I 2020-08-12 16:18:10,594] Finished trial#7 with value: 0.4524361948955916 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 34, 'rf_max_features': 0.27164127557057444, 'rf_min_samples_leaf': 13, 'rf_max_samples': 0.11102857136304187, 'rf_criterion': 'entropy'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:18:30,503] Finished trial#8 with value: 0.4596810933940775 with parameters: {'rf_max_depth': 27, 'rf_max_leaf_nodes': 45, 'rf_max_features': 0.2273894066092367, 'rf_min_samples_leaf': 11, 'rf_max_samples': 0.3596061956886733, 'rf_criterion': 'entropy'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:18:35,596] Finished trial#9 with value: 0.4575193094048159 with parameters: {'rf_max_depth': 12, 'rf_max_leaf_nodes': 34, 'rf_max_features': 0.11088960665268494, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.12921456156780486, 'rf_criterion': 'entropy'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:18:52,828] Finished trial#10 with value: 0.4556331006979064 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.8016269642278391, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.1934631103878716, 'rf_criterion': 'entropy'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:18:54,996] Finished trial#11 with value: 0.4742468415937804 with parameters: {'rf_max_depth': 2, 'rf_max_leaf_nodes': 11, 'rf_max_features': 0.1624172069263106, 'rf_min_samples_leaf': 13, 'rf_max_samples': 0.10846336074407863, 'rf_criterion': 'gini'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:19:11,230] Finished trial#12 with value: 0.4588665447897624 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 19, 'rf_max_features': 0.46539406202183786, 'rf_min_samples_leaf': 20, 'rf_max_samples': 0.17366014639460617, 'rf_criterion': 'entropy'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:19:15,805] Finished trial#13 with value: 0.4577818347786399 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 48, 'rf_max_features': 0.15981660094728065, 'rf_min_samples_leaf': 20, 'rf_max_samples': 0.14551817546523302, 'rf_criterion': 'gini'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:19:25,331] Finished trial#14 with value: 0.4549675023212627 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 21, 'rf_max_features': 0.3241997138459458, 'rf_min_samples_leaf': 13, 'rf_max_samples': 0.25682593539823256, 'rf_criterion': 'gini'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:19:30,860] Finished trial#15 with value: 0.46046091278807055 with parameters: {'rf_max_depth': 12, 'rf_max_leaf_nodes': 44, 'rf_max_features': 0.16167151443546054, 'rf_min_samples_leaf': 18, 'rf_max_samples': 0.1032119667994303, 'rf_criterion': 'entropy'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:19:36,178] Finished trial#16 with value: 0.48051948051948046 with parameters: {'rf_max_depth': 2, 'rf_max_leaf_nodes': 23, 'rf_max_features': 0.6038462000991834, 'rf_min_samples_leaf': 13, 'rf_max_samples': 0.15298949432831876, 'rf_criterion': 'gini'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:19:43,566] Finished trial#17 with value: 0.4570259208731242 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 39, 'rf_max_features': 0.2495083285652107, 'rf_min_samples_leaf': 11, 'rf_max_samples': 0.10006650301946196, 'rf_criterion': 'entropy'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:19:54,807] Finished trial#18 with value: 0.45960748516659067 with parameters: {'rf_max_depth': 22, 'rf_max_leaf_nodes': 52, 'rf_max_features': 0.19044042080727408, 'rf_min_samples_leaf': 14, 'rf_max_samples': 0.20889590183295537, 'rf_criterion': 'entropy'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:20:01,942] Finished trial#19 with value: 0.46389891696750907 with parameters: {'rf_max_depth': 15, 'rf_max_leaf_nodes': 27, 'rf_max_features': 0.29975089996135007, 'rf_min_samples_leaf': 18, 'rf_max_samples': 0.1572261920525431, 'rf_criterion': 'gini'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:20:11,697] Finished trial#20 with value: 0.45585412667946257 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 12, 'rf_max_features': 0.3958412072712833, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.2751151389325025, 'rf_criterion': 'gini'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:20:20,720] Finished trial#21 with value: 0.45825771324863895 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 21, 'rf_max_features': 0.3035477561115881, 'rf_min_samples_leaf': 14, 'rf_max_samples': 0.2432728943556616, 'rf_criterion': 'gini'}. Best is trial#7 with value: 0.4524361948955916.\n",
      "[I 2020-08-12 16:20:39,497] Finished trial#22 with value: 0.4522900763358778 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 17, 'rf_max_features': 0.514636299578389, 'rf_min_samples_leaf': 12, 'rf_max_samples': 0.4079811926657012, 'rf_criterion': 'gini'}. Best is trial#22 with value: 0.4522900763358778.\n",
      "[I 2020-08-12 16:21:06,418] Finished trial#23 with value: 0.4623364907532702 with parameters: {'rf_max_depth': 10, 'rf_max_leaf_nodes': 17, 'rf_max_features': 0.604947539959249, 'rf_min_samples_leaf': 11, 'rf_max_samples': 0.4424669738416535, 'rf_criterion': 'gini'}. Best is trial#22 with value: 0.4522900763358778.\n",
      "[I 2020-08-12 16:21:34,242] Finished trial#24 with value: 0.4553314121037464 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 25, 'rf_max_features': 0.5601216353764531, 'rf_min_samples_leaf': 18, 'rf_max_samples': 0.7765237493476506, 'rf_criterion': 'gini'}. Best is trial#22 with value: 0.4522900763358778.\n",
      "[I 2020-08-12 16:22:03,241] Finished trial#25 with value: 0.462062698773285 with parameters: {'rf_max_depth': 10, 'rf_max_leaf_nodes': 15, 'rf_max_features': 0.7273352199907713, 'rf_min_samples_leaf': 15, 'rf_max_samples': 0.405770601445779, 'rf_criterion': 'gini'}. Best is trial#22 with value: 0.4522900763358778.\n",
      "[I 2020-08-12 16:22:28,094] Finished trial#26 with value: 0.4558823529411764 with parameters: {'rf_max_depth': 32, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.5054673782160988, 'rf_min_samples_leaf': 12, 'rf_max_samples': 0.6131791481448196, 'rf_criterion': 'gini'}. Best is trial#22 with value: 0.4522900763358778.\n",
      "[I 2020-08-12 16:22:38,083] Finished trial#27 with value: 0.4505601558694592 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 34, 'rf_max_features': 0.13719538234526127, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.34028068954838564, 'rf_criterion': 'entropy'}. Best is trial#27 with value: 0.4505601558694592.\n",
      "[I 2020-08-12 16:23:47,355] Finished trial#28 with value: 0.45772058823529416 with parameters: {'rf_max_depth': 16, 'rf_max_leaf_nodes': 55, 'rf_max_features': 0.8714863976217021, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.3174735965084463, 'rf_criterion': 'entropy'}. Best is trial#27 with value: 0.4505601558694592.\n",
      "[I 2020-08-12 16:23:57,114] Finished trial#29 with value: 0.4603756298671553 with parameters: {'rf_max_depth': 14, 'rf_max_leaf_nodes': 41, 'rf_max_features': 0.10039849232313676, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.3964753310404183, 'rf_criterion': 'entropy'}. Best is trial#27 with value: 0.4505601558694592.\n",
      "[I 2020-08-12 16:24:22,870] Finished trial#30 with value: 0.46040515653775316 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 34, 'rf_max_features': 0.261602189440813, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.4690719175529118, 'rf_criterion': 'entropy'}. Best is trial#27 with value: 0.4505601558694592.\n",
      "[I 2020-08-12 16:24:27,492] Finished trial#31 with value: 0.45322346097915656 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 31, 'rf_max_features': 0.1462893264623162, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.13251522730264717, 'rf_criterion': 'entropy'}. Best is trial#27 with value: 0.4505601558694592.\n",
      "[I 2020-08-12 16:24:30,181] Finished trial#32 with value: 0.4722624216111915 with parameters: {'rf_max_depth': 2, 'rf_max_leaf_nodes': 31, 'rf_max_features': 0.1326890728790091, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.12093891253581636, 'rf_criterion': 'entropy'}. Best is trial#27 with value: 0.4505601558694592.\n",
      "[I 2020-08-12 16:24:41,871] Finished trial#33 with value: 0.44874274661508695 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 35, 'rf_max_features': 0.1867642243692868, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.3639316903947423, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:24:56,762] Finished trial#34 with value: 0.4579524680073126 with parameters: {'rf_max_depth': 10, 'rf_max_leaf_nodes': 37, 'rf_max_features': 0.19706819838737133, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.29777799763196666, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:25:10,428] Finished trial#35 with value: 0.45082765335929886 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 42, 'rf_max_features': 0.21966650297480386, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.3420216692044956, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:25:20,803] Finished trial#36 with value: 0.4534883720930232 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 61, 'rf_max_features': 0.20530997408445276, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.34790587022359576, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:25:44,975] Finished trial#37 with value: 0.4570383912248629 with parameters: {'rf_max_depth': 12, 'rf_max_leaf_nodes': 43, 'rf_max_features': 0.1865881306651304, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.6231625084037181, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:25:52,024] Finished trial#38 with value: 0.47148090005232857 with parameters: {'rf_max_depth': 2, 'rf_max_leaf_nodes': 50, 'rf_max_features': 0.22331580165728124, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.39619444545951643, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:26:00,082] Finished trial#39 with value: 0.4518013631937683 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 40, 'rf_max_features': 0.13481470340760807, 'rf_min_samples_leaf': 10, 'rf_max_samples': 0.29772242534335946, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:26:09,690] Finished trial#40 with value: 0.46220797068254704 with parameters: {'rf_max_depth': 20, 'rf_max_leaf_nodes': 40, 'rf_max_features': 0.12395855620107872, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.3014853800092476, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:26:19,003] Finished trial#41 with value: 0.45303326810176126 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 46, 'rf_max_features': 0.14052328140655648, 'rf_min_samples_leaf': 10, 'rf_max_samples': 0.354591766679798, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:26:27,678] Finished trial#42 with value: 0.4569842738205365 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 37, 'rf_max_features': 0.11181908036298589, 'rf_min_samples_leaf': 10, 'rf_max_samples': 0.2777656230876824, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:26:42,937] Finished trial#43 with value: 0.44934561318468247 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 42, 'rf_max_features': 0.17493592423622015, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.5114787746442161, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:26:53,317] Finished trial#44 with value: 0.4556154977930359 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 42, 'rf_max_features': 0.17838025742427346, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.5314029198462754, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:27:20,787] Finished trial#45 with value: 0.4510556621880998 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 39, 'rf_max_features': 0.21679873985887263, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.8706718233758971, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:27:55,338] Finished trial#46 with value: 0.4590389016018306 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 35, 'rf_max_features': 0.22213083471990253, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.8849081225719123, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:28:17,418] Finished trial#47 with value: 0.4579614842649131 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 46, 'rf_max_features': 0.17627703083036414, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.6163447312435886, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:28:27,833] Finished trial#48 with value: 0.45159705159705166 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 29, 'rf_max_features': 0.23882850740689887, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.4330688400277332, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:28:40,912] Finished trial#49 with value: 0.4490492442710873 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 38, 'rf_max_features': 0.1471273608324389, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.4917201737715929, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:28:56,007] Finished trial#50 with value: 0.46062271062271054 with parameters: {'rf_max_depth': 11, 'rf_max_leaf_nodes': 35, 'rf_max_features': 0.14524925311113265, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.4863153756636499, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:29:14,544] Finished trial#51 with value: 0.4513189448441247 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 38, 'rf_max_features': 0.1728774828772117, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.6783443815728344, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:29:26,290] Finished trial#52 with value: 0.45622973598888383 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 33, 'rf_max_features': 0.1519436165614952, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.3710528079149195, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:29:38,612] Finished trial#53 with value: 0.45082765335929886 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 48, 'rf_max_features': 0.12069359739561811, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.5596063446667798, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:29:45,641] Finished trial#54 with value: 0.455081001472754 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 52, 'rf_max_features': 0.10153511987525043, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.5103103313270381, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:29:58,140] Finished trial#55 with value: 0.4505601558694592 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 47, 'rf_max_features': 0.12529005780510716, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.5661452074649466, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:30:11,656] Finished trial#56 with value: 0.46062271062271054 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 44, 'rf_max_features': 0.1639386265733955, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.33028601842535726, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:30:18,901] Finished trial#57 with value: 0.46031746031746035 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 57, 'rf_max_features': 0.12540836951065026, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.5652262584979165, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:30:35,301] Finished trial#58 with value: 0.45704793545325106 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 49, 'rf_max_features': 0.11582101667752871, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.7352385688146255, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:30:45,702] Finished trial#59 with value: 0.45259042033235586 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 48, 'rf_max_features': 0.10517739976594341, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.5764761239362698, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:30:59,061] Finished trial#60 with value: 0.45856353591160215 with parameters: {'rf_max_depth': 13, 'rf_max_leaf_nodes': 46, 'rf_max_features': 0.11937293497525044, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.46587286300690384, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:31:09,027] Finished trial#61 with value: 0.4510184287099902 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 43, 'rf_max_features': 0.1526817034632446, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.43635737750983344, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:31:22,917] Finished trial#62 with value: 0.4569719282098481 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 36, 'rf_max_features': 0.16274557344563303, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.37686976138515754, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:31:39,232] Finished trial#63 with value: 0.4493887530562348 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 51, 'rf_max_features': 0.13422704941962502, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.6703188875768242, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:31:55,936] Finished trial#64 with value: 0.45143972669594923 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 52, 'rf_max_features': 0.1344116470840815, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.6988271604905532, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:32:19,449] Finished trial#65 with value: 0.45772058823529416 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 55, 'rf_max_features': 0.20044942867098553, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.5083734239526785, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:32:26,720] Finished trial#66 with value: 0.46899224806201545 with parameters: {'rf_max_depth': 2, 'rf_max_leaf_nodes': 41, 'rf_max_features': 0.17172331587426437, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.6611614575979536, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:32:46,072] Finished trial#67 with value: 0.45109489051094886 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 31, 'rf_max_features': 0.18469940650883707, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.7698466311732268, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:32:59,939] Finished trial#68 with value: 0.45497856121962843 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 55, 'rf_max_features': 0.12805941006065372, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.570092792813981, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:33:07,641] Finished trial#69 with value: 0.44973025993133886 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 26, 'rf_max_features': 0.2790134909769644, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.22917833580534216, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:33:11,257] Finished trial#70 with value: 0.466798810703667 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 28, 'rf_max_features': 0.10599787527561827, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.22980808304500297, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:33:26,179] Finished trial#71 with value: 0.4509246088193456 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 50, 'rf_max_features': 0.3568335042518148, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.18702422032878335, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:33:36,417] Finished trial#72 with value: 0.45401459854014603 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 25, 'rf_max_features': 0.2897922758421848, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.22624321668739053, 'rf_criterion': 'entropy'}. Best is trial#33 with value: 0.44874274661508695.\n",
      "[I 2020-08-12 16:33:48,497] Finished trial#73 with value: 0.4486434108527131 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 39, 'rf_max_features': 0.24795749696390704, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.26471291186578816, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:33:57,459] Finished trial#74 with value: 0.45331398161586844 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 32, 'rf_max_features': 0.27106667384174216, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.20638883250930432, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:34:03,213] Finished trial#75 with value: 0.47710330138445156 with parameters: {'rf_max_depth': 2, 'rf_max_leaf_nodes': 38, 'rf_max_features': 0.24728669480989973, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.2599802841103984, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:34:13,137] Finished trial#76 with value: 0.4513274336283186 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 45, 'rf_max_features': 0.3255131120785112, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.27539542405463935, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:34:21,913] Finished trial#77 with value: 0.4583714547118024 with parameters: {'rf_max_depth': 25, 'rf_max_leaf_nodes': 26, 'rf_max_features': 0.15211583159894324, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.24668795161046184, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:34:35,809] Finished trial#78 with value: 0.4564007421150278 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 36, 'rf_max_features': 0.14250973641730072, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.46730450943894575, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:34:45,370] Finished trial#79 with value: 0.4510184287099902 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 39, 'rf_max_features': 0.23859792145819753, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.21489039861644468, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:35:05,447] Finished trial#80 with value: 0.4576271186440678 with parameters: {'rf_max_depth': 11, 'rf_max_leaf_nodes': 29, 'rf_max_features': 0.13806240029688216, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.8330712616093285, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:35:15,679] Finished trial#81 with value: 0.4551656920077972 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 47, 'rf_max_features': 0.11926485354788662, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.5370883734747648, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:35:30,427] Finished trial#82 with value: 0.4556603773584905 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 50, 'rf_max_features': 0.12905557346114419, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.6361214031044926, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:35:42,949] Finished trial#83 with value: 0.45031507513330105 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 44, 'rf_max_features': 0.11236158088343717, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.5858724624346761, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:35:52,001] Finished trial#84 with value: 0.457022076092062 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 41, 'rf_max_features': 0.1108394092137324, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.32041880413765933, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:36:02,856] Finished trial#85 with value: 0.4572864321608041 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 23, 'rf_max_features': 0.1929036519237342, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.2600823288572223, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:36:21,057] Finished trial#86 with value: 0.4497816593886462 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 44, 'rf_max_features': 0.2075401780886937, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.5959319659118224, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:36:40,818] Finished trial#87 with value: 0.4512845370819195 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 33, 'rf_max_features': 0.25918062900915195, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.701305605151012, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:36:49,017] Finished trial#88 with value: 0.4711340206185567 with parameters: {'rf_max_depth': 2, 'rf_max_leaf_nodes': 44, 'rf_max_features': 0.20637337032785882, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.5880623097281498, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:36:58,164] Finished trial#89 with value: 0.45687530803351406 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 38, 'rf_max_features': 0.21170695014227986, 'rf_min_samples_leaf': 10, 'rf_max_samples': 0.41320846346185297, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:37:15,725] Finished trial#90 with value: 0.4489104116222761 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 43, 'rf_max_features': 0.23670485569105154, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.49132704376681197, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:37:37,370] Finished trial#91 with value: 0.4493731918997107 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 43, 'rf_max_features': 0.27957420281383905, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.5232632215104914, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:37:59,529] Finished trial#92 with value: 0.45067698259187616 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 42, 'rf_max_features': 0.29309543436566543, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.4877679496525169, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:38:14,648] Finished trial#93 with value: 0.45084745762711864 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 44, 'rf_max_features': 0.2325695604289828, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.5244819747664377, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:38:49,820] Finished trial#94 with value: 0.45913124708080333 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 40, 'rf_max_features': 0.3186017921636663, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.6014642354740443, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:39:05,511] Finished trial#95 with value: 0.4521612433220009 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 43, 'rf_max_features': 0.27501705046968206, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.646353345334618, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:39:32,473] Finished trial#96 with value: 0.45287578540357654 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 45, 'rf_max_features': 0.3550877203590528, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.4959453589084655, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:39:47,233] Finished trial#97 with value: 0.4507722007722007 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 40, 'rf_max_features': 0.2523007562217063, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.4514207605053515, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:40:09,536] Finished trial#98 with value: 0.45113143957631197 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 42, 'rf_max_features': 0.28189925075794736, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.5477960004182382, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n",
      "[I 2020-08-12 16:40:30,729] Finished trial#99 with value: 0.4588665447897624 with parameters: {'rf_max_depth': 32, 'rf_max_leaf_nodes': 36, 'rf_max_features': 0.22909760153735284, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.41671668684851265, 'rf_criterion': 'entropy'}. Best is trial#73 with value: 0.4486434108527131.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-60-ea676e26d436>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-60-ea676e26d436>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    min_samples_leaf=8,\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=0.2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=5,\n",
    "                            max_leaf_nodes=39,\n",
    "                            max_features = .2479,\n",
    "                            min_samples_leaf=8,\n",
    "                            max_samples = 0.2647,\n",
    "                            criterion='entropy')\n",
    "\n",
    "\n",
    "# {'rf_max_depth': 5, 'rf_max_leaf_nodes': 39, 'rf_max_features': 0.24795749696390704, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.26471291186578816, 'rf_criterion': 'entropy'}\n",
    "# parameters = {'max_leaf_nodes': range(10,100,1)}\n",
    "#     'min_samples_split': range(2,10,1)}\n",
    "#     'n_estimators': range(100, 500, 50)}\n",
    "#     'max_depth': range(10,25,1)}\n",
    "#              'min_samples_leaf': range(1,10,1),\n",
    "#              'class_weight': ['balanced',None,'balanced_subsample']}\n",
    "# grid_tree = GridSearchCV(rfc, parameters, cv=5, scoring='f1', n_jobs=-1,verbose=1)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "y_train_pred = rfc.predict(X_train)\n",
    "y_test_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.806497175141243\n",
      "Testing Precision:  0.5404896421845574\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.5714898484415213\n",
      "Testing Recall:  0.5644051130776795\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.7171861595653417\n",
      "Testing Accuracy:  0.7931111111111111\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.6689539748953974\n",
      "Testing F1-Score:  0.5521885521885521\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=0.2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=5,\n",
    "                            max_leaf_nodes=39,\n",
    "                            max_features = .2479,\n",
    "                            min_samples_leaf=8,\n",
    "                            max_samples = 0.2647,\n",
    "                            criterion='entropy')\n",
    "\n",
    "\n",
    "# {'rf_max_depth': 5, 'rf_max_leaf_nodes': 39, 'rf_max_features': 0.24795749696390704, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.26471291186578816, 'rf_criterion': 'entropy'}\n",
    "# parameters = {'max_leaf_nodes': range(10,100,1)}\n",
    "#     'min_samples_split': range(2,10,1)}\n",
    "#     'n_estimators': range(100, 500, 50)}\n",
    "#     'max_depth': range(10,25,1)}\n",
    "#              'min_samples_leaf': range(1,10,1),\n",
    "#              'class_weight': ['balanced',None,'balanced_subsample']}\n",
    "# grid_tree = GridSearchCV(rfc, parameters, cv=5, scoring='f1', n_jobs=-1,verbose=1)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "y_train_pred = rfc.predict(X_train)\n",
    "y_test_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>LIMIT_BAL_PAY_0</th>\n",
       "      <th>SEX_PAY_0</th>\n",
       "      <th>EDUCATION_PAY_0</th>\n",
       "      <th>MARRIAGE_PAY_0</th>\n",
       "      <th>AGE_PAY_0</th>\n",
       "      <th>PAY_0_PAY_0</th>\n",
       "      <th>PAY_2_PAY_0</th>\n",
       "      <th>PAY_3_PAY_0</th>\n",
       "      <th>PAY_4_PAY_0</th>\n",
       "      <th>PAY_5_PAY_0</th>\n",
       "      <th>PAY_6_PAY_0</th>\n",
       "      <th>BILL_AMT1_PAY_0</th>\n",
       "      <th>BILL_AMT2_PAY_0</th>\n",
       "      <th>BILL_AMT3_PAY_0</th>\n",
       "      <th>BILL_AMT4_PAY_0</th>\n",
       "      <th>BILL_AMT5_PAY_0</th>\n",
       "      <th>BILL_AMT6_PAY_0</th>\n",
       "      <th>PAY_AMT1_PAY_0</th>\n",
       "      <th>PAY_AMT2_PAY_0</th>\n",
       "      <th>PAY_AMT3_PAY_0</th>\n",
       "      <th>PAY_AMT4_PAY_0</th>\n",
       "      <th>PAY_AMT5_PAY_0</th>\n",
       "      <th>PAY_AMT6_PAY_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.486361</td>\n",
       "      <td>0.811629</td>\n",
       "      <td>-0.300988</td>\n",
       "      <td>0.852130</td>\n",
       "      <td>-0.805526</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.110420</td>\n",
       "      <td>0.135825</td>\n",
       "      <td>0.184195</td>\n",
       "      <td>0.225981</td>\n",
       "      <td>0.248073</td>\n",
       "      <td>-0.525727</td>\n",
       "      <td>-0.439569</td>\n",
       "      <td>-0.379756</td>\n",
       "      <td>-0.054180</td>\n",
       "      <td>0.015515</td>\n",
       "      <td>-0.467170</td>\n",
       "      <td>0.024117</td>\n",
       "      <td>-0.096754</td>\n",
       "      <td>0.770012</td>\n",
       "      <td>-0.173162</td>\n",
       "      <td>-0.216717</td>\n",
       "      <td>0.143194</td>\n",
       "      <td>0.179607</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>0.061382</td>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>-0.467093</td>\n",
       "      <td>-0.361213</td>\n",
       "      <td>-0.340515</td>\n",
       "      <td>-0.332498</td>\n",
       "      <td>-0.329965</td>\n",
       "      <td>-0.331437</td>\n",
       "      <td>-0.162774</td>\n",
       "      <td>-0.161853</td>\n",
       "      <td>-0.148473</td>\n",
       "      <td>-0.151015</td>\n",
       "      <td>-0.151374</td>\n",
       "      <td>-0.150270</td>\n",
       "      <td>0.085032</td>\n",
       "      <td>0.059574</td>\n",
       "      <td>0.077854</td>\n",
       "      <td>0.068343</td>\n",
       "      <td>0.056677</td>\n",
       "      <td>0.054135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.901232</td>\n",
       "      <td>-1.232091</td>\n",
       "      <td>-1.671809</td>\n",
       "      <td>2.775084</td>\n",
       "      <td>2.435316</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.110420</td>\n",
       "      <td>0.135825</td>\n",
       "      <td>0.184195</td>\n",
       "      <td>0.225981</td>\n",
       "      <td>0.248073</td>\n",
       "      <td>-0.070327</td>\n",
       "      <td>-0.030784</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>-0.392657</td>\n",
       "      <td>-0.363018</td>\n",
       "      <td>-0.341661</td>\n",
       "      <td>-0.215464</td>\n",
       "      <td>-0.180760</td>\n",
       "      <td>-0.239690</td>\n",
       "      <td>-0.255754</td>\n",
       "      <td>-0.267770</td>\n",
       "      <td>-0.254844</td>\n",
       "      <td>0.179607</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>0.061382</td>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>-0.467093</td>\n",
       "      <td>-0.361213</td>\n",
       "      <td>-0.340515</td>\n",
       "      <td>-0.332498</td>\n",
       "      <td>-0.329965</td>\n",
       "      <td>-0.331437</td>\n",
       "      <td>-0.162774</td>\n",
       "      <td>-0.161853</td>\n",
       "      <td>-0.148473</td>\n",
       "      <td>-0.151015</td>\n",
       "      <td>-0.151374</td>\n",
       "      <td>-0.150270</td>\n",
       "      <td>0.085032</td>\n",
       "      <td>0.059574</td>\n",
       "      <td>0.077854</td>\n",
       "      <td>0.068343</td>\n",
       "      <td>0.056677</td>\n",
       "      <td>0.054135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.515789</td>\n",
       "      <td>0.811629</td>\n",
       "      <td>-1.671809</td>\n",
       "      <td>-1.070825</td>\n",
       "      <td>0.598839</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.110420</td>\n",
       "      <td>0.135825</td>\n",
       "      <td>0.184195</td>\n",
       "      <td>0.225981</td>\n",
       "      <td>0.248073</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>0.298867</td>\n",
       "      <td>0.338065</td>\n",
       "      <td>0.404934</td>\n",
       "      <td>0.452444</td>\n",
       "      <td>0.393796</td>\n",
       "      <td>-0.183837</td>\n",
       "      <td>-0.127644</td>\n",
       "      <td>-0.123641</td>\n",
       "      <td>-0.164109</td>\n",
       "      <td>-0.161674</td>\n",
       "      <td>-0.157128</td>\n",
       "      <td>0.179607</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>0.061382</td>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>-0.467093</td>\n",
       "      <td>-0.361213</td>\n",
       "      <td>-0.340515</td>\n",
       "      <td>-0.332498</td>\n",
       "      <td>-0.329965</td>\n",
       "      <td>-0.331437</td>\n",
       "      <td>-0.162774</td>\n",
       "      <td>-0.161853</td>\n",
       "      <td>-0.148473</td>\n",
       "      <td>-0.151015</td>\n",
       "      <td>-0.151374</td>\n",
       "      <td>-0.150270</td>\n",
       "      <td>0.085032</td>\n",
       "      <td>0.059574</td>\n",
       "      <td>0.077854</td>\n",
       "      <td>0.068343</td>\n",
       "      <td>0.056677</td>\n",
       "      <td>0.054135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.103069</td>\n",
       "      <td>-1.232091</td>\n",
       "      <td>-1.671809</td>\n",
       "      <td>-1.070825</td>\n",
       "      <td>0.922923</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.110420</td>\n",
       "      <td>0.135825</td>\n",
       "      <td>0.184195</td>\n",
       "      <td>0.225981</td>\n",
       "      <td>0.248073</td>\n",
       "      <td>2.510020</td>\n",
       "      <td>2.704192</td>\n",
       "      <td>2.890568</td>\n",
       "      <td>3.420123</td>\n",
       "      <td>3.768343</td>\n",
       "      <td>3.976015</td>\n",
       "      <td>0.265084</td>\n",
       "      <td>0.150212</td>\n",
       "      <td>0.770012</td>\n",
       "      <td>0.319554</td>\n",
       "      <td>0.385022</td>\n",
       "      <td>0.305064</td>\n",
       "      <td>0.179607</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>0.061382</td>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>-0.467093</td>\n",
       "      <td>-0.361213</td>\n",
       "      <td>-0.340515</td>\n",
       "      <td>-0.332498</td>\n",
       "      <td>-0.329965</td>\n",
       "      <td>-0.331437</td>\n",
       "      <td>-0.162774</td>\n",
       "      <td>-0.161853</td>\n",
       "      <td>-0.148473</td>\n",
       "      <td>-0.151015</td>\n",
       "      <td>-0.151374</td>\n",
       "      <td>-0.150270</td>\n",
       "      <td>0.085032</td>\n",
       "      <td>0.059574</td>\n",
       "      <td>0.077854</td>\n",
       "      <td>0.068343</td>\n",
       "      <td>0.056677</td>\n",
       "      <td>0.054135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.824143</td>\n",
       "      <td>-1.232091</td>\n",
       "      <td>-0.300988</td>\n",
       "      <td>0.852130</td>\n",
       "      <td>-1.021582</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.110420</td>\n",
       "      <td>0.135825</td>\n",
       "      <td>0.184195</td>\n",
       "      <td>0.225981</td>\n",
       "      <td>0.248073</td>\n",
       "      <td>-0.169285</td>\n",
       "      <td>-0.127856</td>\n",
       "      <td>-0.138975</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>-0.156602</td>\n",
       "      <td>-0.095380</td>\n",
       "      <td>-0.215464</td>\n",
       "      <td>-0.173085</td>\n",
       "      <td>-0.176042</td>\n",
       "      <td>-0.229086</td>\n",
       "      <td>-0.121706</td>\n",
       "      <td>-0.215456</td>\n",
       "      <td>0.179607</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>0.061382</td>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>-0.467093</td>\n",
       "      <td>-0.361213</td>\n",
       "      <td>-0.340515</td>\n",
       "      <td>-0.332498</td>\n",
       "      <td>-0.329965</td>\n",
       "      <td>-0.331437</td>\n",
       "      <td>-0.162774</td>\n",
       "      <td>-0.161853</td>\n",
       "      <td>-0.148473</td>\n",
       "      <td>-0.151015</td>\n",
       "      <td>-0.151374</td>\n",
       "      <td>-0.150270</td>\n",
       "      <td>0.085032</td>\n",
       "      <td>0.059574</td>\n",
       "      <td>0.077854</td>\n",
       "      <td>0.068343</td>\n",
       "      <td>0.056677</td>\n",
       "      <td>0.054135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27971</th>\n",
       "      <td>-0.811700</td>\n",
       "      <td>-1.232091</td>\n",
       "      <td>-0.300988</td>\n",
       "      <td>0.852130</td>\n",
       "      <td>-1.328230</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.110420</td>\n",
       "      <td>0.135825</td>\n",
       "      <td>0.184195</td>\n",
       "      <td>0.225981</td>\n",
       "      <td>0.248073</td>\n",
       "      <td>-0.045167</td>\n",
       "      <td>-0.223302</td>\n",
       "      <td>-0.180655</td>\n",
       "      <td>-0.379532</td>\n",
       "      <td>-0.341750</td>\n",
       "      <td>-0.301532</td>\n",
       "      <td>-0.218511</td>\n",
       "      <td>-0.153746</td>\n",
       "      <td>-0.242816</td>\n",
       "      <td>-0.235625</td>\n",
       "      <td>-0.186069</td>\n",
       "      <td>-0.249195</td>\n",
       "      <td>0.179607</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>0.061382</td>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>-0.467093</td>\n",
       "      <td>-0.361213</td>\n",
       "      <td>-0.340515</td>\n",
       "      <td>-0.332498</td>\n",
       "      <td>-0.329965</td>\n",
       "      <td>-0.331437</td>\n",
       "      <td>-0.162774</td>\n",
       "      <td>-0.161853</td>\n",
       "      <td>-0.148473</td>\n",
       "      <td>-0.151015</td>\n",
       "      <td>-0.151374</td>\n",
       "      <td>-0.150270</td>\n",
       "      <td>0.085032</td>\n",
       "      <td>0.059574</td>\n",
       "      <td>0.077854</td>\n",
       "      <td>0.068343</td>\n",
       "      <td>0.056677</td>\n",
       "      <td>0.054135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27972</th>\n",
       "      <td>-1.055409</td>\n",
       "      <td>0.811629</td>\n",
       "      <td>-1.671809</td>\n",
       "      <td>-1.070825</td>\n",
       "      <td>1.945120</td>\n",
       "      <td>1.800127</td>\n",
       "      <td>1.779141</td>\n",
       "      <td>1.800592</td>\n",
       "      <td>1.884800</td>\n",
       "      <td>0.225981</td>\n",
       "      <td>0.248073</td>\n",
       "      <td>-0.358787</td>\n",
       "      <td>-0.350573</td>\n",
       "      <td>-0.286983</td>\n",
       "      <td>-0.267684</td>\n",
       "      <td>-0.227413</td>\n",
       "      <td>-0.181679</td>\n",
       "      <td>-0.330855</td>\n",
       "      <td>-0.097244</td>\n",
       "      <td>-0.281159</td>\n",
       "      <td>-0.222725</td>\n",
       "      <td>-0.163883</td>\n",
       "      <td>-0.282077</td>\n",
       "      <td>0.436274</td>\n",
       "      <td>2.164456</td>\n",
       "      <td>0.824371</td>\n",
       "      <td>1.113255</td>\n",
       "      <td>2.582117</td>\n",
       "      <td>1.014352</td>\n",
       "      <td>1.232187</td>\n",
       "      <td>1.407986</td>\n",
       "      <td>1.513043</td>\n",
       "      <td>-0.329965</td>\n",
       "      <td>-0.331437</td>\n",
       "      <td>0.376162</td>\n",
       "      <td>0.376069</td>\n",
       "      <td>0.451860</td>\n",
       "      <td>0.489233</td>\n",
       "      <td>0.521412</td>\n",
       "      <td>0.591657</td>\n",
       "      <td>0.096301</td>\n",
       "      <td>0.255944</td>\n",
       "      <td>0.077854</td>\n",
       "      <td>0.212478</td>\n",
       "      <td>0.294450</td>\n",
       "      <td>0.064083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27973</th>\n",
       "      <td>-0.975875</td>\n",
       "      <td>0.811629</td>\n",
       "      <td>-0.300988</td>\n",
       "      <td>-1.070825</td>\n",
       "      <td>0.062125</td>\n",
       "      <td>1.800127</td>\n",
       "      <td>1.779141</td>\n",
       "      <td>1.800592</td>\n",
       "      <td>1.884800</td>\n",
       "      <td>1.978054</td>\n",
       "      <td>2.420891</td>\n",
       "      <td>-0.441634</td>\n",
       "      <td>-0.412407</td>\n",
       "      <td>-0.374261</td>\n",
       "      <td>-0.351558</td>\n",
       "      <td>-0.304000</td>\n",
       "      <td>-0.297299</td>\n",
       "      <td>-0.232388</td>\n",
       "      <td>-0.164546</td>\n",
       "      <td>-0.254046</td>\n",
       "      <td>-0.185089</td>\n",
       "      <td>-0.311729</td>\n",
       "      <td>-0.231211</td>\n",
       "      <td>0.524543</td>\n",
       "      <td>2.164456</td>\n",
       "      <td>1.587360</td>\n",
       "      <td>1.113255</td>\n",
       "      <td>1.748579</td>\n",
       "      <td>1.014352</td>\n",
       "      <td>1.232187</td>\n",
       "      <td>1.407986</td>\n",
       "      <td>1.513043</td>\n",
       "      <td>1.659999</td>\n",
       "      <td>2.313924</td>\n",
       "      <td>0.241139</td>\n",
       "      <td>0.276396</td>\n",
       "      <td>0.314748</td>\n",
       "      <td>0.355337</td>\n",
       "      <td>0.402179</td>\n",
       "      <td>0.408945</td>\n",
       "      <td>0.267590</td>\n",
       "      <td>0.156195</td>\n",
       "      <td>0.130793</td>\n",
       "      <td>0.286166</td>\n",
       "      <td>0.056677</td>\n",
       "      <td>0.143367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27974</th>\n",
       "      <td>0.775097</td>\n",
       "      <td>0.811629</td>\n",
       "      <td>1.069833</td>\n",
       "      <td>-1.070825</td>\n",
       "      <td>1.962354</td>\n",
       "      <td>-1.762323</td>\n",
       "      <td>-1.558302</td>\n",
       "      <td>-1.528942</td>\n",
       "      <td>-1.516410</td>\n",
       "      <td>-1.526092</td>\n",
       "      <td>-0.939055</td>\n",
       "      <td>-0.685051</td>\n",
       "      <td>-0.672330</td>\n",
       "      <td>-0.669123</td>\n",
       "      <td>-0.666212</td>\n",
       "      <td>-0.659566</td>\n",
       "      <td>-0.645280</td>\n",
       "      <td>-0.285346</td>\n",
       "      <td>-0.229735</td>\n",
       "      <td>-0.272497</td>\n",
       "      <td>-0.296341</td>\n",
       "      <td>-0.289351</td>\n",
       "      <td>-0.271720</td>\n",
       "      <td>-2.108618</td>\n",
       "      <td>-2.094243</td>\n",
       "      <td>-2.227586</td>\n",
       "      <td>-1.083355</td>\n",
       "      <td>-2.538686</td>\n",
       "      <td>1.014352</td>\n",
       "      <td>1.232187</td>\n",
       "      <td>1.407986</td>\n",
       "      <td>1.513043</td>\n",
       "      <td>1.659999</td>\n",
       "      <td>1.113867</td>\n",
       "      <td>-0.169973</td>\n",
       "      <td>-0.181121</td>\n",
       "      <td>-0.148473</td>\n",
       "      <td>-0.155062</td>\n",
       "      <td>-0.151374</td>\n",
       "      <td>-0.159582</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>0.059574</td>\n",
       "      <td>0.060941</td>\n",
       "      <td>0.068343</td>\n",
       "      <td>0.020688</td>\n",
       "      <td>0.028044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27975</th>\n",
       "      <td>-1.067099</td>\n",
       "      <td>-1.232091</td>\n",
       "      <td>-1.671809</td>\n",
       "      <td>0.308353</td>\n",
       "      <td>2.726635</td>\n",
       "      <td>0.909514</td>\n",
       "      <td>1.779141</td>\n",
       "      <td>1.800592</td>\n",
       "      <td>3.104505</td>\n",
       "      <td>2.606364</td>\n",
       "      <td>1.975368</td>\n",
       "      <td>-0.461553</td>\n",
       "      <td>-0.456479</td>\n",
       "      <td>-0.408303</td>\n",
       "      <td>-0.396690</td>\n",
       "      <td>-0.371128</td>\n",
       "      <td>-0.577009</td>\n",
       "      <td>-0.337333</td>\n",
       "      <td>-0.143422</td>\n",
       "      <td>-0.281159</td>\n",
       "      <td>-0.277183</td>\n",
       "      <td>-0.311729</td>\n",
       "      <td>-0.160980</td>\n",
       "      <td>0.301453</td>\n",
       "      <td>0.567444</td>\n",
       "      <td>0.442876</td>\n",
       "      <td>0.957964</td>\n",
       "      <td>1.476798</td>\n",
       "      <td>-0.096731</td>\n",
       "      <td>0.435487</td>\n",
       "      <td>0.533736</td>\n",
       "      <td>1.252100</td>\n",
       "      <td>1.021826</td>\n",
       "      <td>0.720037</td>\n",
       "      <td>0.022951</td>\n",
       "      <td>0.021751</td>\n",
       "      <td>0.056398</td>\n",
       "      <td>0.066138</td>\n",
       "      <td>0.073150</td>\n",
       "      <td>-0.091671</td>\n",
       "      <td>0.085032</td>\n",
       "      <td>0.123538</td>\n",
       "      <td>0.077854</td>\n",
       "      <td>0.087098</td>\n",
       "      <td>0.056677</td>\n",
       "      <td>0.153485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27976 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL       SEX  EDUCATION  MARRIAGE       AGE     PAY_0     PAY_2  \\\n",
       "0       0.486361  0.811629  -0.300988  0.852130 -0.805526  0.018902  0.110420   \n",
       "1      -0.901232 -1.232091  -1.671809  2.775084  2.435316  0.018902  0.110420   \n",
       "2      -0.515789  0.811629  -1.671809 -1.070825  0.598839  0.018902  0.110420   \n",
       "3       1.103069 -1.232091  -1.671809 -1.070825  0.922923  0.018902  0.110420   \n",
       "4      -0.824143 -1.232091  -0.300988  0.852130 -1.021582  0.018902  0.110420   \n",
       "...          ...       ...        ...       ...       ...       ...       ...   \n",
       "27971  -0.811700 -1.232091  -0.300988  0.852130 -1.328230  0.018902  0.110420   \n",
       "27972  -1.055409  0.811629  -1.671809 -1.070825  1.945120  1.800127  1.779141   \n",
       "27973  -0.975875  0.811629  -0.300988 -1.070825  0.062125  1.800127  1.779141   \n",
       "27974   0.775097  0.811629   1.069833 -1.070825  1.962354 -1.762323 -1.558302   \n",
       "27975  -1.067099 -1.232091  -1.671809  0.308353  2.726635  0.909514  1.779141   \n",
       "\n",
       "          PAY_3     PAY_4     PAY_5     PAY_6  BILL_AMT1  BILL_AMT2  \\\n",
       "0      0.135825  0.184195  0.225981  0.248073  -0.525727  -0.439569   \n",
       "1      0.135825  0.184195  0.225981  0.248073  -0.070327  -0.030784   \n",
       "2      0.135825  0.184195  0.225981  0.248073   0.251352   0.298867   \n",
       "3      0.135825  0.184195  0.225981  0.248073   2.510020   2.704192   \n",
       "4      0.135825  0.184195  0.225981  0.248073  -0.169285  -0.127856   \n",
       "...         ...       ...       ...       ...        ...        ...   \n",
       "27971  0.135825  0.184195  0.225981  0.248073  -0.045167  -0.223302   \n",
       "27972  1.800592  1.884800  0.225981  0.248073  -0.358787  -0.350573   \n",
       "27973  1.800592  1.884800  1.978054  2.420891  -0.441634  -0.412407   \n",
       "27974 -1.528942 -1.516410 -1.526092 -0.939055  -0.685051  -0.672330   \n",
       "27975  1.800592  3.104505  2.606364  1.975368  -0.461553  -0.456479   \n",
       "\n",
       "       BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0      -0.379756  -0.054180   0.015515  -0.467170  0.024117 -0.096754   \n",
       "1       0.005687  -0.392657  -0.363018  -0.341661 -0.215464 -0.180760   \n",
       "2       0.338065   0.404934   0.452444   0.393796 -0.183837 -0.127644   \n",
       "3       2.890568   3.420123   3.768343   3.976015  0.265084  0.150212   \n",
       "4      -0.138975  -0.204064  -0.156602  -0.095380 -0.215464 -0.173085   \n",
       "...          ...        ...        ...        ...       ...       ...   \n",
       "27971  -0.180655  -0.379532  -0.341750  -0.301532 -0.218511 -0.153746   \n",
       "27972  -0.286983  -0.267684  -0.227413  -0.181679 -0.330855 -0.097244   \n",
       "27973  -0.374261  -0.351558  -0.304000  -0.297299 -0.232388 -0.164546   \n",
       "27974  -0.669123  -0.666212  -0.659566  -0.645280 -0.285346 -0.229735   \n",
       "27975  -0.408303  -0.396690  -0.371128  -0.577009 -0.337333 -0.143422   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  LIMIT_BAL_PAY_0  SEX_PAY_0  \\\n",
       "0      0.770012 -0.173162 -0.216717  0.143194         0.179607   0.035107   \n",
       "1     -0.239690 -0.255754 -0.267770 -0.254844         0.179607   0.035107   \n",
       "2     -0.123641 -0.164109 -0.161674 -0.157128         0.179607   0.035107   \n",
       "3      0.770012  0.319554  0.385022  0.305064         0.179607   0.035107   \n",
       "4     -0.176042 -0.229086 -0.121706 -0.215456         0.179607   0.035107   \n",
       "...         ...       ...       ...       ...              ...        ...   \n",
       "27971 -0.242816 -0.235625 -0.186069 -0.249195         0.179607   0.035107   \n",
       "27972 -0.281159 -0.222725 -0.163883 -0.282077         0.436274   2.164456   \n",
       "27973 -0.254046 -0.185089 -0.311729 -0.231211         0.524543   2.164456   \n",
       "27974 -0.272497 -0.296341 -0.289351 -0.271720        -2.108618  -2.094243   \n",
       "27975 -0.281159 -0.277183 -0.311729 -0.160980         0.301453   0.567444   \n",
       "\n",
       "       EDUCATION_PAY_0  MARRIAGE_PAY_0  AGE_PAY_0  PAY_0_PAY_0  PAY_2_PAY_0  \\\n",
       "0             0.061382        0.014950   0.025530    -0.467093    -0.361213   \n",
       "1             0.061382        0.014950   0.025530    -0.467093    -0.361213   \n",
       "2             0.061382        0.014950   0.025530    -0.467093    -0.361213   \n",
       "3             0.061382        0.014950   0.025530    -0.467093    -0.361213   \n",
       "4             0.061382        0.014950   0.025530    -0.467093    -0.361213   \n",
       "...                ...             ...        ...          ...          ...   \n",
       "27971         0.061382        0.014950   0.025530    -0.467093    -0.361213   \n",
       "27972         0.824371        1.113255   2.582117     1.014352     1.232187   \n",
       "27973         1.587360        1.113255   1.748579     1.014352     1.232187   \n",
       "27974        -2.227586       -1.083355  -2.538686     1.014352     1.232187   \n",
       "27975         0.442876        0.957964   1.476798    -0.096731     0.435487   \n",
       "\n",
       "       PAY_3_PAY_0  PAY_4_PAY_0  PAY_5_PAY_0  PAY_6_PAY_0  BILL_AMT1_PAY_0  \\\n",
       "0        -0.340515    -0.332498    -0.329965    -0.331437        -0.162774   \n",
       "1        -0.340515    -0.332498    -0.329965    -0.331437        -0.162774   \n",
       "2        -0.340515    -0.332498    -0.329965    -0.331437        -0.162774   \n",
       "3        -0.340515    -0.332498    -0.329965    -0.331437        -0.162774   \n",
       "4        -0.340515    -0.332498    -0.329965    -0.331437        -0.162774   \n",
       "...            ...          ...          ...          ...              ...   \n",
       "27971    -0.340515    -0.332498    -0.329965    -0.331437        -0.162774   \n",
       "27972     1.407986     1.513043    -0.329965    -0.331437         0.376162   \n",
       "27973     1.407986     1.513043     1.659999     2.313924         0.241139   \n",
       "27974     1.407986     1.513043     1.659999     1.113867        -0.169973   \n",
       "27975     0.533736     1.252100     1.021826     0.720037         0.022951   \n",
       "\n",
       "       BILL_AMT2_PAY_0  BILL_AMT3_PAY_0  BILL_AMT4_PAY_0  BILL_AMT5_PAY_0  \\\n",
       "0            -0.161853        -0.148473        -0.151015        -0.151374   \n",
       "1            -0.161853        -0.148473        -0.151015        -0.151374   \n",
       "2            -0.161853        -0.148473        -0.151015        -0.151374   \n",
       "3            -0.161853        -0.148473        -0.151015        -0.151374   \n",
       "4            -0.161853        -0.148473        -0.151015        -0.151374   \n",
       "...                ...              ...              ...              ...   \n",
       "27971        -0.161853        -0.148473        -0.151015        -0.151374   \n",
       "27972         0.376069         0.451860         0.489233         0.521412   \n",
       "27973         0.276396         0.314748         0.355337         0.402179   \n",
       "27974        -0.181121        -0.148473        -0.155062        -0.151374   \n",
       "27975         0.021751         0.056398         0.066138         0.073150   \n",
       "\n",
       "       BILL_AMT6_PAY_0  PAY_AMT1_PAY_0  PAY_AMT2_PAY_0  PAY_AMT3_PAY_0  \\\n",
       "0            -0.150270        0.085032        0.059574        0.077854   \n",
       "1            -0.150270        0.085032        0.059574        0.077854   \n",
       "2            -0.150270        0.085032        0.059574        0.077854   \n",
       "3            -0.150270        0.085032        0.059574        0.077854   \n",
       "4            -0.150270        0.085032        0.059574        0.077854   \n",
       "...                ...             ...             ...             ...   \n",
       "27971        -0.150270        0.085032        0.059574        0.077854   \n",
       "27972         0.591657        0.096301        0.255944        0.077854   \n",
       "27973         0.408945        0.267590        0.156195        0.130793   \n",
       "27974        -0.159582       -0.005401        0.059574        0.060941   \n",
       "27975        -0.091671        0.085032        0.123538        0.077854   \n",
       "\n",
       "       PAY_AMT4_PAY_0  PAY_AMT5_PAY_0  PAY_AMT6_PAY_0  \n",
       "0            0.068343        0.056677        0.054135  \n",
       "1            0.068343        0.056677        0.054135  \n",
       "2            0.068343        0.056677        0.054135  \n",
       "3            0.068343        0.056677        0.054135  \n",
       "4            0.068343        0.056677        0.054135  \n",
       "...               ...             ...             ...  \n",
       "27971        0.068343        0.056677        0.054135  \n",
       "27972        0.212478        0.294450        0.064083  \n",
       "27973        0.286166        0.056677        0.143367  \n",
       "27974        0.068343        0.020688        0.028044  \n",
       "27975        0.087098        0.056677        0.153485  \n",
       "\n",
       "[27976 rows x 46 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588276\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>target</td>      <th>  No. Observations:  </th>  <td> 27976</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 27929</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    46</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 12 Aug 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.1513</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:58:37</td>     <th>  Log-Likelihood:    </th> <td> -16458.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -19391.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>   -0.1994</td> <td>    0.014</td> <td>  -13.862</td> <td> 0.000</td> <td>   -0.228</td> <td>   -0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LIMIT_BAL</th>       <td>   -0.2322</td> <td>    0.019</td> <td>  -12.286</td> <td> 0.000</td> <td>   -0.269</td> <td>   -0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SEX</th>             <td>   -0.0638</td> <td>    0.013</td> <td>   -4.737</td> <td> 0.000</td> <td>   -0.090</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EDUCATION</th>       <td>    0.0105</td> <td>    0.015</td> <td>    0.706</td> <td> 0.480</td> <td>   -0.019</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MARRIAGE</th>        <td>   -0.1145</td> <td>    0.015</td> <td>   -7.573</td> <td> 0.000</td> <td>   -0.144</td> <td>   -0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>             <td>    0.0135</td> <td>    0.015</td> <td>    0.879</td> <td> 0.380</td> <td>   -0.017</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_0</th>           <td>    0.3103</td> <td>    0.129</td> <td>    2.408</td> <td> 0.016</td> <td>    0.058</td> <td>    0.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_2</th>           <td>    0.1099</td> <td>    0.024</td> <td>    4.598</td> <td> 0.000</td> <td>    0.063</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_3</th>           <td>    0.1520</td> <td>    0.025</td> <td>    6.136</td> <td> 0.000</td> <td>    0.103</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_4</th>           <td>    0.0837</td> <td>    0.028</td> <td>    3.026</td> <td> 0.002</td> <td>    0.029</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_5</th>           <td>   -0.0050</td> <td>    0.029</td> <td>   -0.172</td> <td> 0.864</td> <td>   -0.062</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_6</th>           <td>    0.0299</td> <td>    0.025</td> <td>    1.197</td> <td> 0.231</td> <td>   -0.019</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT1</th>       <td>   -0.3370</td> <td>    0.076</td> <td>   -4.440</td> <td> 0.000</td> <td>   -0.486</td> <td>   -0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT2</th>       <td>    0.2171</td> <td>    0.098</td> <td>    2.219</td> <td> 0.027</td> <td>    0.025</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT3</th>       <td>    0.0953</td> <td>    0.090</td> <td>    1.064</td> <td> 0.287</td> <td>   -0.080</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT4</th>       <td>    0.0738</td> <td>    0.081</td> <td>    0.906</td> <td> 0.365</td> <td>   -0.086</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT5</th>       <td>   -0.1418</td> <td>    0.090</td> <td>   -1.577</td> <td> 0.115</td> <td>   -0.318</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT6</th>       <td>    0.0861</td> <td>    0.069</td> <td>    1.242</td> <td> 0.214</td> <td>   -0.050</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT1</th>        <td>   -0.2713</td> <td>    0.035</td> <td>   -7.729</td> <td> 0.000</td> <td>   -0.340</td> <td>   -0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT2</th>        <td>   -0.3122</td> <td>    0.053</td> <td>   -5.939</td> <td> 0.000</td> <td>   -0.415</td> <td>   -0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT3</th>        <td>   -0.0547</td> <td>    0.030</td> <td>   -1.798</td> <td> 0.072</td> <td>   -0.114</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT4</th>        <td>   -0.0350</td> <td>    0.025</td> <td>   -1.416</td> <td> 0.157</td> <td>   -0.083</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT5</th>        <td>   -0.1103</td> <td>    0.027</td> <td>   -4.160</td> <td> 0.000</td> <td>   -0.162</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT6</th>        <td>   -0.0624</td> <td>    0.022</td> <td>   -2.883</td> <td> 0.004</td> <td>   -0.105</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LIMIT_BAL_PAY_0</th> <td>   -0.2289</td> <td>    0.032</td> <td>   -7.255</td> <td> 0.000</td> <td>   -0.291</td> <td>   -0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SEX_PAY_0</th>       <td>    0.0599</td> <td>    0.051</td> <td>    1.179</td> <td> 0.238</td> <td>   -0.040</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EDUCATION_PAY_0</th> <td>   -0.0043</td> <td>    0.052</td> <td>   -0.084</td> <td> 0.933</td> <td>   -0.106</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MARRIAGE_PAY_0</th>  <td>   -0.0698</td> <td>    0.053</td> <td>   -1.326</td> <td> 0.185</td> <td>   -0.173</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE_PAY_0</th>       <td>    0.0562</td> <td>    0.068</td> <td>    0.826</td> <td> 0.409</td> <td>   -0.077</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_0_PAY_0</th>     <td>    0.8989</td> <td>    0.047</td> <td>   19.085</td> <td> 0.000</td> <td>    0.807</td> <td>    0.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_2_PAY_0</th>     <td>   -0.3451</td> <td>    0.044</td> <td>   -7.795</td> <td> 0.000</td> <td>   -0.432</td> <td>   -0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_3_PAY_0</th>     <td>   -0.1322</td> <td>    0.045</td> <td>   -2.914</td> <td> 0.004</td> <td>   -0.221</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_4_PAY_0</th>     <td>   -0.1000</td> <td>    0.049</td> <td>   -2.044</td> <td> 0.041</td> <td>   -0.196</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_5_PAY_0</th>     <td>   -0.0066</td> <td>    0.049</td> <td>   -0.134</td> <td> 0.893</td> <td>   -0.103</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_6_PAY_0</th>     <td>    0.1545</td> <td>    0.040</td> <td>    3.898</td> <td> 0.000</td> <td>    0.077</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT1_PAY_0</th> <td>    0.2122</td> <td>    0.115</td> <td>    1.841</td> <td> 0.066</td> <td>   -0.014</td> <td>    0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT2_PAY_0</th> <td>    0.0386</td> <td>    0.162</td> <td>    0.238</td> <td> 0.812</td> <td>   -0.279</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT3_PAY_0</th> <td>   -0.1150</td> <td>    0.158</td> <td>   -0.728</td> <td> 0.466</td> <td>   -0.425</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT4_PAY_0</th> <td>   -0.0998</td> <td>    0.130</td> <td>   -0.765</td> <td> 0.444</td> <td>   -0.355</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT5_PAY_0</th> <td>   -0.0432</td> <td>    0.115</td> <td>   -0.374</td> <td> 0.708</td> <td>   -0.269</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BILL_AMT6_PAY_0</th> <td>    0.2947</td> <td>    0.073</td> <td>    4.012</td> <td> 0.000</td> <td>    0.151</td> <td>    0.439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT1_PAY_0</th>  <td>    0.0769</td> <td>    0.043</td> <td>    1.782</td> <td> 0.075</td> <td>   -0.008</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT2_PAY_0</th>  <td>    0.0594</td> <td>    0.070</td> <td>    0.850</td> <td> 0.396</td> <td>   -0.078</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT3_PAY_0</th>  <td>    0.0497</td> <td>    0.033</td> <td>    1.488</td> <td> 0.137</td> <td>   -0.016</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT4_PAY_0</th>  <td>   -0.0037</td> <td>    0.027</td> <td>   -0.135</td> <td> 0.893</td> <td>   -0.057</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT5_PAY_0</th>  <td>   -0.1001</td> <td>    0.022</td> <td>   -4.486</td> <td> 0.000</td> <td>   -0.144</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PAY_AMT6_PAY_0</th>  <td>   -0.0120</td> <td>    0.026</td> <td>   -0.455</td> <td> 0.649</td> <td>   -0.063</td> <td>    0.040</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   No. Observations:                27976\n",
       "Model:                          Logit   Df Residuals:                    27929\n",
       "Method:                           MLE   Df Model:                           46\n",
       "Date:                Wed, 12 Aug 2020   Pseudo R-squ.:                  0.1513\n",
       "Time:                        16:58:37   Log-Likelihood:                -16458.\n",
       "converged:                       True   LL-Null:                       -19391.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const              -0.1994      0.014    -13.862      0.000      -0.228      -0.171\n",
       "LIMIT_BAL          -0.2322      0.019    -12.286      0.000      -0.269      -0.195\n",
       "SEX                -0.0638      0.013     -4.737      0.000      -0.090      -0.037\n",
       "EDUCATION           0.0105      0.015      0.706      0.480      -0.019       0.040\n",
       "MARRIAGE           -0.1145      0.015     -7.573      0.000      -0.144      -0.085\n",
       "AGE                 0.0135      0.015      0.879      0.380      -0.017       0.044\n",
       "PAY_0               0.3103      0.129      2.408      0.016       0.058       0.563\n",
       "PAY_2               0.1099      0.024      4.598      0.000       0.063       0.157\n",
       "PAY_3               0.1520      0.025      6.136      0.000       0.103       0.201\n",
       "PAY_4               0.0837      0.028      3.026      0.002       0.029       0.138\n",
       "PAY_5              -0.0050      0.029     -0.172      0.864      -0.062       0.052\n",
       "PAY_6               0.0299      0.025      1.197      0.231      -0.019       0.079\n",
       "BILL_AMT1          -0.3370      0.076     -4.440      0.000      -0.486      -0.188\n",
       "BILL_AMT2           0.2171      0.098      2.219      0.027       0.025       0.409\n",
       "BILL_AMT3           0.0953      0.090      1.064      0.287      -0.080       0.271\n",
       "BILL_AMT4           0.0738      0.081      0.906      0.365      -0.086       0.234\n",
       "BILL_AMT5          -0.1418      0.090     -1.577      0.115      -0.318       0.034\n",
       "BILL_AMT6           0.0861      0.069      1.242      0.214      -0.050       0.222\n",
       "PAY_AMT1           -0.2713      0.035     -7.729      0.000      -0.340      -0.203\n",
       "PAY_AMT2           -0.3122      0.053     -5.939      0.000      -0.415      -0.209\n",
       "PAY_AMT3           -0.0547      0.030     -1.798      0.072      -0.114       0.005\n",
       "PAY_AMT4           -0.0350      0.025     -1.416      0.157      -0.083       0.013\n",
       "PAY_AMT5           -0.1103      0.027     -4.160      0.000      -0.162      -0.058\n",
       "PAY_AMT6           -0.0624      0.022     -2.883      0.004      -0.105      -0.020\n",
       "LIMIT_BAL_PAY_0    -0.2289      0.032     -7.255      0.000      -0.291      -0.167\n",
       "SEX_PAY_0           0.0599      0.051      1.179      0.238      -0.040       0.159\n",
       "EDUCATION_PAY_0    -0.0043      0.052     -0.084      0.933      -0.106       0.097\n",
       "MARRIAGE_PAY_0     -0.0698      0.053     -1.326      0.185      -0.173       0.033\n",
       "AGE_PAY_0           0.0562      0.068      0.826      0.409      -0.077       0.190\n",
       "PAY_0_PAY_0         0.8989      0.047     19.085      0.000       0.807       0.991\n",
       "PAY_2_PAY_0        -0.3451      0.044     -7.795      0.000      -0.432      -0.258\n",
       "PAY_3_PAY_0        -0.1322      0.045     -2.914      0.004      -0.221      -0.043\n",
       "PAY_4_PAY_0        -0.1000      0.049     -2.044      0.041      -0.196      -0.004\n",
       "PAY_5_PAY_0        -0.0066      0.049     -0.134      0.893      -0.103       0.089\n",
       "PAY_6_PAY_0         0.1545      0.040      3.898      0.000       0.077       0.232\n",
       "BILL_AMT1_PAY_0     0.2122      0.115      1.841      0.066      -0.014       0.438\n",
       "BILL_AMT2_PAY_0     0.0386      0.162      0.238      0.812      -0.279       0.356\n",
       "BILL_AMT3_PAY_0    -0.1150      0.158     -0.728      0.466      -0.425       0.195\n",
       "BILL_AMT4_PAY_0    -0.0998      0.130     -0.765      0.444      -0.355       0.156\n",
       "BILL_AMT5_PAY_0    -0.0432      0.115     -0.374      0.708      -0.269       0.183\n",
       "BILL_AMT6_PAY_0     0.2947      0.073      4.012      0.000       0.151       0.439\n",
       "PAY_AMT1_PAY_0      0.0769      0.043      1.782      0.075      -0.008       0.162\n",
       "PAY_AMT2_PAY_0      0.0594      0.070      0.850      0.396      -0.078       0.196\n",
       "PAY_AMT3_PAY_0      0.0497      0.033      1.488      0.137      -0.016       0.115\n",
       "PAY_AMT4_PAY_0     -0.0037      0.027     -0.135      0.893      -0.057       0.050\n",
       "PAY_AMT5_PAY_0     -0.1001      0.022     -4.486      0.000      -0.144      -0.056\n",
       "PAY_AMT6_PAY_0     -0.0120      0.026     -0.455      0.649      -0.063       0.040\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_train_log = sm.tools.add_constant(X_train)\n",
    "logit_model = sm.Logit(y_train, X_train_log)\n",
    "result = logit_model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.7876455125797972\n",
      "Testing Precision:  0.5051993067590987\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.5997998284243637\n",
      "Testing Recall:  0.5732546705998034\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.7190448956248213\n",
      "Testing Accuracy:  0.7766666666666666\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.6810064935064936\n",
      "Testing F1-Score:  0.5370796867802856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bc_dtc = BaggingClassifier(\n",
    "            base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
    "                       max_depth=10, max_features=0.1461, max_leaf_nodes=14,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=8, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=42, splitter='best'), \n",
    "            n_estimators= 300,\n",
    "            max_samples= 0.66,\n",
    "            max_features= .8,\n",
    "            oob_score= True, n_jobs=-1\n",
    "                )\n",
    "# {'rf_max_depth': 10, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.14612189898099304, 'rf_min_samples_leaf': 8, 'rf_criterion': 'gini'}\n",
    "\n",
    "bc_dtc.fit(X_train, y_train)\n",
    "y_train_pred = bc_dtc.predict(X_train)\n",
    "y_test_pred = bc_dtc.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 2, 32)\n",
    "    rf_max_leaf_nodes = trial.suggest_int('rf_max_leaf_nodes', 10, 64)\n",
    "    rf_max_features = trial.suggest_loguniform('rf_max_features', .1, .9)\n",
    "    rf_min_samples_leaf = trial.suggest_int('rf_min_samples_leaf', 2, 20)\n",
    "    rf_criterion = trial.suggest_categorical('rf_criterion', ['gini', 'entropy'])\n",
    "    \n",
    "    regressor_obj = DecisionTreeClassifier(max_depth = rf_max_depth,\n",
    "                                          max_leaf_nodes = rf_max_leaf_nodes,\n",
    "                                          max_features = rf_max_features,\n",
    "                                          min_samples_leaf = rf_min_samples_leaf,\n",
    "                                          random_state=42,\n",
    "                                          criterion = rf_criterion)\n",
    "    \n",
    "    regressor_obj.fit(X_train, y_train)\n",
    "    y_pred = regressor_obj.predict(X_test)\n",
    "    \n",
    "    return (1 - f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-12 17:06:30,646] Finished trial#0 with value: 0.4710424710424711 with parameters: {'rf_max_depth': 17, 'rf_max_leaf_nodes': 13, 'rf_max_features': 0.16648840070282345, 'rf_min_samples_leaf': 9, 'rf_criterion': 'gini'}. Best is trial#0 with value: 0.4710424710424711.\n",
      "[I 2020-08-12 17:06:31,066] Finished trial#1 with value: 0.48395604395604397 with parameters: {'rf_max_depth': 19, 'rf_max_leaf_nodes': 25, 'rf_max_features': 0.3787485023593908, 'rf_min_samples_leaf': 20, 'rf_criterion': 'entropy'}. Best is trial#0 with value: 0.4710424710424711.\n",
      "[I 2020-08-12 17:06:31,239] Finished trial#2 with value: 0.4722624216111915 with parameters: {'rf_max_depth': 2, 'rf_max_leaf_nodes': 26, 'rf_max_features': 0.10946825056636159, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial#0 with value: 0.4710424710424711.\n",
      "[I 2020-08-12 17:06:31,701] Finished trial#3 with value: 0.47303271441202477 with parameters: {'rf_max_depth': 25, 'rf_max_leaf_nodes': 45, 'rf_max_features': 0.611753012759454, 'rf_min_samples_leaf': 11, 'rf_criterion': 'gini'}. Best is trial#0 with value: 0.4710424710424711.\n",
      "[I 2020-08-12 17:06:32,621] Finished trial#4 with value: 0.483319772172498 with parameters: {'rf_max_depth': 12, 'rf_max_leaf_nodes': 54, 'rf_max_features': 0.802958399372662, 'rf_min_samples_leaf': 15, 'rf_criterion': 'entropy'}. Best is trial#0 with value: 0.4710424710424711.\n",
      "[I 2020-08-12 17:06:32,870] Finished trial#5 with value: 0.4849128771780705 with parameters: {'rf_max_depth': 17, 'rf_max_leaf_nodes': 23, 'rf_max_features': 0.2592118530036288, 'rf_min_samples_leaf': 10, 'rf_criterion': 'gini'}. Best is trial#0 with value: 0.4710424710424711.\n",
      "[I 2020-08-12 17:06:33,121] Finished trial#6 with value: 0.4852617685877695 with parameters: {'rf_max_depth': 11, 'rf_max_leaf_nodes': 31, 'rf_max_features': 0.25178771341313994, 'rf_min_samples_leaf': 14, 'rf_criterion': 'gini'}. Best is trial#0 with value: 0.4710424710424711.\n",
      "[I 2020-08-12 17:06:33,604] Finished trial#7 with value: 0.475 with parameters: {'rf_max_depth': 15, 'rf_max_leaf_nodes': 48, 'rf_max_features': 0.36744868397143177, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial#0 with value: 0.4710424710424711.\n",
      "[I 2020-08-12 17:06:33,999] Finished trial#8 with value: 0.47640249332146034 with parameters: {'rf_max_depth': 19, 'rf_max_leaf_nodes': 57, 'rf_max_features': 0.4791343600378503, 'rf_min_samples_leaf': 7, 'rf_criterion': 'gini'}. Best is trial#0 with value: 0.4710424710424711.\n",
      "[I 2020-08-12 17:06:34,250] Finished trial#9 with value: 0.4846374436706268 with parameters: {'rf_max_depth': 19, 'rf_max_leaf_nodes': 57, 'rf_max_features': 0.21612896610077123, 'rf_min_samples_leaf': 5, 'rf_criterion': 'gini'}. Best is trial#0 with value: 0.4710424710424711.\n",
      "[I 2020-08-12 17:06:34,454] Finished trial#10 with value: 0.46535580524344555 with parameters: {'rf_max_depth': 31, 'rf_max_leaf_nodes': 11, 'rf_max_features': 0.1294372701528288, 'rf_min_samples_leaf': 19, 'rf_criterion': 'gini'}. Best is trial#10 with value: 0.46535580524344555.\n",
      "[I 2020-08-12 17:06:34,662] Finished trial#11 with value: 0.465105808194507 with parameters: {'rf_max_depth': 30, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.11889409096506456, 'rf_min_samples_leaf': 20, 'rf_criterion': 'gini'}. Best is trial#11 with value: 0.465105808194507.\n",
      "[I 2020-08-12 17:06:34,866] Finished trial#12 with value: 0.4874251497005988 with parameters: {'rf_max_depth': 32, 'rf_max_leaf_nodes': 12, 'rf_max_features': 0.10266928712945454, 'rf_min_samples_leaf': 20, 'rf_criterion': 'gini'}. Best is trial#11 with value: 0.465105808194507.\n",
      "[I 2020-08-12 17:06:35,074] Finished trial#13 with value: 0.45587518283764017 with parameters: {'rf_max_depth': 32, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.14113102073141146, 'rf_min_samples_leaf': 17, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:35,303] Finished trial#14 with value: 0.4691358024691358 with parameters: {'rf_max_depth': 27, 'rf_max_leaf_nodes': 17, 'rf_max_features': 0.16640543453976306, 'rf_min_samples_leaf': 17, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:35,535] Finished trial#15 with value: 0.47094017094017093 with parameters: {'rf_max_depth': 27, 'rf_max_leaf_nodes': 34, 'rf_max_features': 0.1388897355232243, 'rf_min_samples_leaf': 17, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:35,758] Finished trial#16 with value: 0.4671434957532409 with parameters: {'rf_max_depth': 32, 'rf_max_leaf_nodes': 16, 'rf_max_features': 0.1890624447588682, 'rf_min_samples_leaf': 13, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:35,965] Finished trial#17 with value: 0.4878550843968711 with parameters: {'rf_max_depth': 25, 'rf_max_leaf_nodes': 19, 'rf_max_features': 0.12767414493073945, 'rf_min_samples_leaf': 17, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:36,169] Finished trial#18 with value: 0.4885690093141405 with parameters: {'rf_max_depth': 29, 'rf_max_leaf_nodes': 41, 'rf_max_features': 0.1008976188801147, 'rf_min_samples_leaf': 18, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:36,366] Finished trial#19 with value: 0.45587518283764017 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.15173337130038067, 'rf_min_samples_leaf': 12, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:36,558] Finished trial#20 with value: 0.4722624216111915 with parameters: {'rf_max_depth': 2, 'rf_max_leaf_nodes': 20, 'rf_max_features': 0.15140366375770498, 'rf_min_samples_leaf': 13, 'rf_criterion': 'entropy'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:36,761] Finished trial#21 with value: 0.465105808194507 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.11635466482897688, 'rf_min_samples_leaf': 15, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:37,011] Finished trial#22 with value: 0.4873881204231083 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 64, 'rf_max_features': 0.19454168644440434, 'rf_min_samples_leaf': 15, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:37,214] Finished trial#23 with value: 0.46453089244851264 with parameters: {'rf_max_depth': 24, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.10098183143182586, 'rf_min_samples_leaf': 20, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:37,428] Finished trial#24 with value: 0.4846980976013233 with parameters: {'rf_max_depth': 22, 'rf_max_leaf_nodes': 29, 'rf_max_features': 0.10167699680886758, 'rf_min_samples_leaf': 12, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:37,658] Finished trial#25 with value: 0.4715525554484089 with parameters: {'rf_max_depth': 23, 'rf_max_leaf_nodes': 16, 'rf_max_features': 0.15335816064142588, 'rf_min_samples_leaf': 18, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:37,921] Finished trial#26 with value: 0.4784876140808344 with parameters: {'rf_max_depth': 22, 'rf_max_leaf_nodes': 21, 'rf_max_features': 0.22288768697196032, 'rf_min_samples_leaf': 9, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:38,208] Finished trial#27 with value: 0.47416287722199246 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.3064872300284426, 'rf_min_samples_leaf': 16, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:38,435] Finished trial#28 with value: 0.46895893027698177 with parameters: {'rf_max_depth': 13, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.18485078966754173, 'rf_min_samples_leaf': 7, 'rf_criterion': 'gini'}. Best is trial#13 with value: 0.45587518283764017.\n",
      "[I 2020-08-12 17:06:38,654] Finished trial#29 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 10, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.14612189898099304, 'rf_min_samples_leaf': 8, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:38,877] Finished trial#30 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.14870109604281745, 'rf_min_samples_leaf': 8, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:39,102] Finished trial#31 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.14899637519671707, 'rf_min_samples_leaf': 8, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:39,334] Finished trial#32 with value: 0.4710424710424711 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.17259221430910254, 'rf_min_samples_leaf': 8, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:39,537] Finished trial#33 with value: 0.46854554604932064 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 24, 'rf_max_features': 0.15741018391779318, 'rf_min_samples_leaf': 5, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:39,802] Finished trial#34 with value: 0.46726862302483074 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 19, 'rf_max_features': 0.2165160960833002, 'rf_min_samples_leaf': 10, 'rf_criterion': 'entropy'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:40,026] Finished trial#35 with value: 0.4817610062893082 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 27, 'rf_max_features': 0.12801449110119711, 'rf_min_samples_leaf': 6, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:40,289] Finished trial#36 with value: 0.45827372436814495 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.2450787623127912, 'rf_min_samples_leaf': 9, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:40,570] Finished trial#37 with value: 0.5011494252873563 with parameters: {'rf_max_depth': 14, 'rf_max_leaf_nodes': 23, 'rf_max_features': 0.142970155500097, 'rf_min_samples_leaf': 8, 'rf_criterion': 'entropy'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:40,856] Finished trial#38 with value: 0.4797979797979798 with parameters: {'rf_max_depth': 11, 'rf_max_leaf_nodes': 16, 'rf_max_features': 0.3035904301107638, 'rf_min_samples_leaf': 12, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:41,080] Finished trial#39 with value: 0.4685114503816793 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 33, 'rf_max_features': 0.17718319742575234, 'rf_min_samples_leaf': 11, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:41,308] Finished trial#40 with value: 0.48063973063973064 with parameters: {'rf_max_depth': 16, 'rf_max_leaf_nodes': 26, 'rf_max_features': 0.11437243086271424, 'rf_min_samples_leaf': 10, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:41,528] Finished trial#41 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 13, 'rf_max_features': 0.13553621150771986, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:41,752] Finished trial#42 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 13, 'rf_max_features': 0.1346558675653035, 'rf_min_samples_leaf': 3, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:41,973] Finished trial#43 with value: 0.48941368078175895 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 13, 'rf_max_features': 0.1269089750493158, 'rf_min_samples_leaf': 2, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:42,223] Finished trial#44 with value: 0.4774305555555556 with parameters: {'rf_max_depth': 11, 'rf_max_leaf_nodes': 22, 'rf_max_features': 0.20507212687175408, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:42,440] Finished trial#45 with value: 0.4926108374384236 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 18, 'rf_max_features': 0.11025163965213114, 'rf_min_samples_leaf': 3, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:43,052] Finished trial#46 with value: 0.49186844958438747 with parameters: {'rf_max_depth': 10, 'rf_max_leaf_nodes': 13, 'rf_max_features': 0.7366414839517422, 'rf_min_samples_leaf': 6, 'rf_criterion': 'entropy'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:43,291] Finished trial#47 with value: 0.4715525554484089 with parameters: {'rf_max_depth': 13, 'rf_max_leaf_nodes': 16, 'rf_max_features': 0.16519870428831795, 'rf_min_samples_leaf': 2, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:43,511] Finished trial#48 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 12, 'rf_max_features': 0.13637374937596994, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:43,732] Finished trial#49 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 12, 'rf_max_features': 0.13552007780706987, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:43,975] Finished trial#50 with value: 0.47859922178988334 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 48, 'rf_max_features': 0.13490939766537902, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:44,197] Finished trial#51 with value: 0.49193548387096764 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 18, 'rf_max_features': 0.12300856600595496, 'rf_min_samples_leaf': 6, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:44,421] Finished trial#52 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 12, 'rf_max_features': 0.1380012156676317, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:44,641] Finished trial#53 with value: 0.46590909090909083 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 12, 'rf_max_features': 0.11215328287951858, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:44,831] Finished trial#54 with value: 0.4722624216111915 with parameters: {'rf_max_depth': 2, 'rf_max_leaf_nodes': 16, 'rf_max_features': 0.1651950709425684, 'rf_min_samples_leaf': 3, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:45,023] Finished trial#55 with value: 0.46535580524344555 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 12, 'rf_max_features': 0.11915146099981216, 'rf_min_samples_leaf': 5, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:45,350] Finished trial#56 with value: 0.47289719626168214 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 20, 'rf_max_features': 0.4871312443401377, 'rf_min_samples_leaf': 2, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:45,585] Finished trial#57 with value: 0.47594501718213056 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 40, 'rf_max_features': 0.13846670031916272, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:45,811] Finished trial#58 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 10, 'rf_max_leaf_nodes': 15, 'rf_max_features': 0.1482761696720903, 'rf_min_samples_leaf': 7, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:46,037] Finished trial#59 with value: 0.45587518283764017 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.13592534320518868, 'rf_min_samples_leaf': 3, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:46,235] Finished trial#60 with value: 0.46927628584433323 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 12, 'rf_max_features': 0.10356487635236362, 'rf_min_samples_leaf': 5, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:46,474] Finished trial#61 with value: 0.4715525554484089 with parameters: {'rf_max_depth': 12, 'rf_max_leaf_nodes': 15, 'rf_max_features': 0.160080444094829, 'rf_min_samples_leaf': 6, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:46,711] Finished trial#62 with value: 0.4690189328743545 with parameters: {'rf_max_depth': 10, 'rf_max_leaf_nodes': 18, 'rf_max_features': 0.14796631637617078, 'rf_min_samples_leaf': 7, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:46,950] Finished trial#63 with value: 0.4934959349593496 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 11, 'rf_max_features': 0.18274837430967864, 'rf_min_samples_leaf': 7, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:47,203] Finished trial#64 with value: 0.4790697674418605 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 21, 'rf_max_features': 0.19441288315944044, 'rf_min_samples_leaf': 5, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:47,469] Finished trial#65 with value: 0.49330085261875756 with parameters: {'rf_max_depth': 11, 'rf_max_leaf_nodes': 17, 'rf_max_features': 0.12844602811776779, 'rf_min_samples_leaf': 9, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:47,699] Finished trial#66 with value: 0.48941368078175895 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.12078183078487427, 'rf_min_samples_leaf': 8, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:47,930] Finished trial#67 with value: 0.45587518283764017 with parameters: {'rf_max_depth': 18, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.14878371608125915, 'rf_min_samples_leaf': 8, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:48,161] Finished trial#68 with value: 0.49086843086097653 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 12, 'rf_max_features': 0.10753454701797156, 'rf_min_samples_leaf': 3, 'rf_criterion': 'entropy'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:48,410] Finished trial#69 with value: 0.4890698671238749 with parameters: {'rf_max_depth': 10, 'rf_max_leaf_nodes': 19, 'rf_max_features': 0.17267428172577307, 'rf_min_samples_leaf': 7, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:48,679] Finished trial#70 with value: 0.4854234150856086 with parameters: {'rf_max_depth': 12, 'rf_max_leaf_nodes': 15, 'rf_max_features': 0.2377759535831212, 'rf_min_samples_leaf': 9, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:48,911] Finished trial#71 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 13, 'rf_max_features': 0.13856218333007486, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:49,144] Finished trial#72 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 11, 'rf_max_features': 0.1345022225465093, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:49,374] Finished trial#73 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 11, 'rf_max_features': 0.13629172575998835, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:49,655] Finished trial#74 with value: 0.5037181996086105 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 12, 'rf_max_features': 0.279741880253011, 'rf_min_samples_leaf': 2, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:49,876] Finished trial#75 with value: 0.45587518283764017 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.13246266265964504, 'rf_min_samples_leaf': 3, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:50,123] Finished trial#76 with value: 0.4715525554484089 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 15, 'rf_max_features': 0.15516558054024235, 'rf_min_samples_leaf': 5, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:50,335] Finished trial#77 with value: 0.4722624216111915 with parameters: {'rf_max_depth': 2, 'rf_max_leaf_nodes': 17, 'rf_max_features': 0.14354911227567363, 'rf_min_samples_leaf': 11, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:50,585] Finished trial#78 with value: 0.4710424710424711 with parameters: {'rf_max_depth': 14, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.1574906232582881, 'rf_min_samples_leaf': 6, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:50,836] Finished trial#79 with value: 0.4855643044619421 with parameters: {'rf_max_depth': 10, 'rf_max_leaf_nodes': 61, 'rf_max_features': 0.12283083644730065, 'rf_min_samples_leaf': 5, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:51,107] Finished trial#80 with value: 0.46879271070615036 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 20, 'rf_max_features': 0.2020268415619072, 'rf_min_samples_leaf': 6, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:51,352] Finished trial#81 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 13, 'rf_max_features': 0.1410286504727001, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:51,592] Finished trial#82 with value: 0.49330085261875756 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 17, 'rf_max_features': 0.11639230105959833, 'rf_min_samples_leaf': 3, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:51,838] Finished trial#83 with value: 0.4710424710424711 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 13, 'rf_max_features': 0.17085831848677083, 'rf_min_samples_leaf': 10, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:52,070] Finished trial#84 with value: 0.465105808194507 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.12738716860982396, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:52,318] Finished trial#85 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 11, 'rf_max_leaf_nodes': 15, 'rf_max_features': 0.14674452395520257, 'rf_min_samples_leaf': 8, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:52,551] Finished trial#86 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 11, 'rf_max_features': 0.14013688084746068, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:52,794] Finished trial#87 with value: 0.49086843086097653 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 11, 'rf_max_features': 0.10695983409610582, 'rf_min_samples_leaf': 2, 'rf_criterion': 'entropy'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:53,056] Finished trial#88 with value: 0.4715525554484089 with parameters: {'rf_max_depth': 6, 'rf_max_leaf_nodes': 16, 'rf_max_features': 0.16113724787287503, 'rf_min_samples_leaf': 5, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:53,278] Finished trial#89 with value: 0.4645373414748708 with parameters: {'rf_max_depth': 4, 'rf_max_leaf_nodes': 13, 'rf_max_features': 0.1167528922658282, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:53,526] Finished trial#90 with value: 0.4690189328743545 with parameters: {'rf_max_depth': 10, 'rf_max_leaf_nodes': 18, 'rf_max_features': 0.15119368700504204, 'rf_min_samples_leaf': 9, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:53,763] Finished trial#91 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 12, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.13327086302053254, 'rf_min_samples_leaf': 7, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:53,990] Finished trial#92 with value: 0.48941368078175895 with parameters: {'rf_max_depth': 12, 'rf_max_leaf_nodes': 14, 'rf_max_features': 0.12849825521812727, 'rf_min_samples_leaf': 8, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:54,223] Finished trial#93 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 11, 'rf_max_leaf_nodes': 15, 'rf_max_features': 0.15097988371345208, 'rf_min_samples_leaf': 8, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:54,474] Finished trial#94 with value: 0.46785714285714286 with parameters: {'rf_max_depth': 9, 'rf_max_leaf_nodes': 22, 'rf_max_features': 0.1801479357905613, 'rf_min_samples_leaf': 10, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:54,712] Finished trial#95 with value: 0.4710424710424711 with parameters: {'rf_max_depth': 5, 'rf_max_leaf_nodes': 13, 'rf_max_features': 0.16632516076283518, 'rf_min_samples_leaf': 3, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:54,954] Finished trial#96 with value: 0.45159752026704814 with parameters: {'rf_max_depth': 7, 'rf_max_leaf_nodes': 11, 'rf_max_features': 0.14496473445107028, 'rf_min_samples_leaf': 4, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:55,192] Finished trial#97 with value: 0.48941368078175895 with parameters: {'rf_max_depth': 8, 'rf_max_leaf_nodes': 12, 'rf_max_features': 0.12371422331595222, 'rf_min_samples_leaf': 5, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:55,457] Finished trial#98 with value: 0.4720229555236729 with parameters: {'rf_max_depth': 3, 'rf_max_leaf_nodes': 16, 'rf_max_features': 0.3284825725877901, 'rf_min_samples_leaf': 6, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n",
      "[I 2020-08-12 17:06:55,693] Finished trial#99 with value: 0.45587518283764017 with parameters: {'rf_max_depth': 13, 'rf_max_leaf_nodes': 10, 'rf_max_features': 0.13281927685753894, 'rf_min_samples_leaf': 2, 'rf_criterion': 'gini'}. Best is trial#29 with value: 0.45159752026704814.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.7697157726180944\n",
      "Testing Precision:  0.5149911816578483\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.5498284243637404\n",
      "Testing Recall:  0.5742379547689282\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.6926651415498999\n",
      "Testing Accuracy:  0.7815555555555556\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.6414512093411175\n",
      "Testing F1-Score:  0.5430032543003254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "bc_lr1 = BaggingClassifier(\n",
    "            base_estimator=LogisticRegression(solver='saga', penalty='l2', C=.04108295837286748, max_iter = 1000, tol = 1e-3), \n",
    "            n_estimators= 300,\n",
    "            max_samples= 0.66,\n",
    "            max_features= .8,\n",
    "            oob_score= True, n_jobs=-1\n",
    "                )\n",
    "\n",
    "# {'lr_C': 0.04108295837286748, 'lr_solver': 'saga'}\n",
    "bc_lr1.fit(X_train, y_train)\n",
    "y_train_pred = bc_lr1.predict(X_train)\n",
    "y_test_pred = bc_lr1.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    lr_C = trial.suggest_loguniform('lr_C', 1e-8, 1)\n",
    "    lr_solver = trial.suggest_categorical('lr_solver', ['newton-cg','lbfgs','sag','saga','liblinear'])\n",
    "    if lr_solver == 'liblinear':\n",
    "        lr_penalty = trial.suggest_categorical('lr_penalty', ['l1', 'l2'])\n",
    "    else:\n",
    "        lr_penalty = 'l2'\n",
    "    \n",
    "    regressor_obj = LogisticRegression(penalty = lr_penalty,\n",
    "                                          C = lr_C,\n",
    "                                          solver = lr_solver,\n",
    "                                          max_iter = 1000,\n",
    "                                          tol = 1e-3)\n",
    "    \n",
    "    regressor_obj.fit(X_train, y_train)\n",
    "    y_pred = regressor_obj.predict(X_test)\n",
    "    \n",
    "    return (1 - f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-12 17:18:10,842] Finished trial#0 with value: 0.47122133832475444 with parameters: {'lr_C': 0.00019853880704122752, 'lr_solver': 'newton-cg'}. Best is trial#0 with value: 0.47122133832475444.\n",
      "[I 2020-08-12 17:18:11,212] Finished trial#1 with value: 0.5079059005013498 with parameters: {'lr_C': 2.3348048709984127e-07, 'lr_solver': 'liblinear', 'lr_penalty': 'l2'}. Best is trial#0 with value: 0.47122133832475444.\n",
      "[I 2020-08-12 17:18:11,659] Finished trial#2 with value: 0.4668470906630582 with parameters: {'lr_C': 0.0024028218065910013, 'lr_solver': 'lbfgs'}. Best is trial#2 with value: 0.4668470906630582.\n",
      "[I 2020-08-12 17:18:15,810] Finished trial#3 with value: 0.45627548708654275 with parameters: {'lr_C': 0.11661600526778318, 'lr_solver': 'saga'}. Best is trial#3 with value: 0.45627548708654275.\n",
      "[I 2020-08-12 17:18:16,185] Finished trial#4 with value: 0.4658385093167702 with parameters: {'lr_C': 9.722217407215602e-06, 'lr_solver': 'lbfgs'}. Best is trial#3 with value: 0.45627548708654275.\n",
      "[I 2020-08-12 17:18:16,535] Finished trial#5 with value: 0.508513931888545 with parameters: {'lr_C': 1.2674219310877372e-08, 'lr_solver': 'liblinear', 'lr_penalty': 'l2'}. Best is trial#3 with value: 0.45627548708654275.\n",
      "[I 2020-08-12 17:18:16,900] Finished trial#6 with value: 0.46496815286624193 with parameters: {'lr_C': 6.841253353458426e-07, 'lr_solver': 'lbfgs'}. Best is trial#3 with value: 0.45627548708654275.\n",
      "[I 2020-08-12 17:18:17,503] Finished trial#7 with value: 0.45931283905967457 with parameters: {'lr_C': 0.01141458812429335, 'lr_solver': 'liblinear', 'lr_penalty': 'l2'}. Best is trial#3 with value: 0.45627548708654275.\n",
      "[I 2020-08-12 17:18:18,088] Finished trial#8 with value: 0.4673170731707317 with parameters: {'lr_C': 5.417458437693578e-05, 'lr_solver': 'newton-cg'}. Best is trial#3 with value: 0.45627548708654275.\n",
      "[I 2020-08-12 17:18:19,933] Finished trial#9 with value: 0.45693563009972793 with parameters: {'lr_C': 0.04270502526513361, 'lr_solver': 'sag'}. Best is trial#3 with value: 0.45627548708654275.\n",
      "[I 2020-08-12 17:18:23,977] Finished trial#10 with value: 0.4561085972850678 with parameters: {'lr_C': 0.8685761152583543, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:18:27,977] Finished trial#11 with value: 0.4561085972850678 with parameters: {'lr_C': 0.6594232070169032, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:18:31,986] Finished trial#12 with value: 0.4563545906829489 with parameters: {'lr_C': 0.28103862681544417, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:18:35,992] Finished trial#13 with value: 0.4563545906829489 with parameters: {'lr_C': 0.33785278463303475, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:18:40,070] Finished trial#14 with value: 0.4561085972850678 with parameters: {'lr_C': 0.8996883264820829, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:18:42,230] Finished trial#15 with value: 0.4652213188798556 with parameters: {'lr_C': 0.002907650113656034, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:18:44,399] Finished trial#16 with value: 0.4563545906829489 with parameters: {'lr_C': 0.589668807307057, 'lr_solver': 'sag'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:18:47,634] Finished trial#17 with value: 0.45759637188208613 with parameters: {'lr_C': 0.021527911243734533, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:18:49,053] Finished trial#18 with value: 0.46855059252506837 with parameters: {'lr_C': 0.0007874596347450974, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:18:52,764] Finished trial#19 with value: 0.456689342403628 with parameters: {'lr_C': 0.057342478806458694, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:18:53,744] Finished trial#20 with value: 0.45733634311512406 with parameters: {'lr_C': 0.9499634799771407, 'lr_solver': 'newton-cg'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:18:57,745] Finished trial#21 with value: 0.4561085972850678 with parameters: {'lr_C': 0.7999532554597479, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:01,789] Finished trial#22 with value: 0.4561085972850678 with parameters: {'lr_C': 0.5959053306286531, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:04,519] Finished trial#23 with value: 0.4613987284287012 with parameters: {'lr_C': 0.008176481146100891, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:08,520] Finished trial#24 with value: 0.4561085972850678 with parameters: {'lr_C': 0.13308406375496726, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:10,523] Finished trial#25 with value: 0.4563545906829489 with parameters: {'lr_C': 0.12331779546740605, 'lr_solver': 'sag'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:14,534] Finished trial#26 with value: 0.4561085972850678 with parameters: {'lr_C': 0.9723124706191497, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:18,424] Finished trial#27 with value: 0.45627548708654275 with parameters: {'lr_C': 0.10979785686551295, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:20,979] Finished trial#28 with value: 0.4590909090909091 with parameters: {'lr_C': 0.005811651602573661, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:21,568] Finished trial#29 with value: 0.46474677259185704 with parameters: {'lr_C': 3.9617399689413426e-05, 'lr_solver': 'newton-cg'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:22,468] Finished trial#30 with value: 0.4708896134140661 with parameters: {'lr_C': 0.00028196717194728605, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:26,462] Finished trial#31 with value: 0.4563545906829489 with parameters: {'lr_C': 0.2449159123080232, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:30,495] Finished trial#32 with value: 0.4561085972850678 with parameters: {'lr_C': 0.9874223938205177, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:31,123] Finished trial#33 with value: 0.45750452079566006 with parameters: {'lr_C': 0.03161906054826396, 'lr_solver': 'liblinear', 'lr_penalty': 'l2'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:35,194] Finished trial#34 with value: 0.45627548708654275 with parameters: {'lr_C': 0.10100117387817087, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:35,912] Finished trial#35 with value: 0.45709123757904246 with parameters: {'lr_C': 0.14710262354179074, 'lr_solver': 'lbfgs'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:40,105] Finished trial#36 with value: 0.4561085972850678 with parameters: {'lr_C': 0.920694044483852, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:41,537] Finished trial#37 with value: 0.4676390154968094 with parameters: {'lr_C': 0.000802365409607084, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:41,868] Finished trial#38 with value: 0.508513931888545 with parameters: {'lr_C': 1.1144614673618897e-08, 'lr_solver': 'lbfgs'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:42,244] Finished trial#39 with value: 0.5097216927182615 with parameters: {'lr_C': 7.197190266947814e-07, 'lr_solver': 'liblinear', 'lr_penalty': 'l2'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:43,023] Finished trial#40 with value: 0.45735027223230484 with parameters: {'lr_C': 0.01651972041586141, 'lr_solver': 'newton-cg'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:47,060] Finished trial#41 with value: 0.4563545906829489 with parameters: {'lr_C': 0.4760983759799465, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:50,992] Finished trial#42 with value: 0.4563545906829489 with parameters: {'lr_C': 0.31796148053646917, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:54,832] Finished trial#43 with value: 0.45693563009972793 with parameters: {'lr_C': 0.0651097675822408, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:19:58,966] Finished trial#44 with value: 0.4561085972850678 with parameters: {'lr_C': 0.7895385632357477, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:02,994] Finished trial#45 with value: 0.4561085972850678 with parameters: {'lr_C': 0.20901183098879014, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:03,526] Finished trial#46 with value: 0.4644923724355603 with parameters: {'lr_C': 4.032121601941644e-06, 'lr_solver': 'sag'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:07,143] Finished trial#47 with value: 0.4565217391304349 with parameters: {'lr_C': 0.041614354389616436, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:07,492] Finished trial#48 with value: 0.5072124756335282 with parameters: {'lr_C': 6.106860529423121e-08, 'lr_solver': 'lbfgs'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:11,830] Finished trial#49 with value: 0.4561085972850678 with parameters: {'lr_C': 0.9422517760200995, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:12,735] Finished trial#50 with value: 0.4570135746606335 with parameters: {'lr_C': 0.20447953793299017, 'lr_solver': 'liblinear', 'lr_penalty': 'l1'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:17,011] Finished trial#51 with value: 0.4561085972850678 with parameters: {'lr_C': 0.486365557031873, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:21,412] Finished trial#52 with value: 0.4561085972850678 with parameters: {'lr_C': 0.47776022790625716, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:25,442] Finished trial#53 with value: 0.4561085972850678 with parameters: {'lr_C': 0.8129562685182505, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:29,470] Finished trial#54 with value: 0.4563545906829489 with parameters: {'lr_C': 0.27212690129319317, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:33,568] Finished trial#55 with value: 0.4561085972850678 with parameters: {'lr_C': 0.9264902097308725, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:37,321] Finished trial#56 with value: 0.456689342403628 with parameters: {'lr_C': 0.05793564141028061, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:41,426] Finished trial#57 with value: 0.4563545906829489 with parameters: {'lr_C': 0.3778468234988206, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:43,398] Finished trial#58 with value: 0.4563545906829489 with parameters: {'lr_C': 0.10321103183606532, 'lr_solver': 'sag'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:47,512] Finished trial#59 with value: 0.4561085972850678 with parameters: {'lr_C': 0.9944404016604026, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:51,570] Finished trial#60 with value: 0.4561085972850678 with parameters: {'lr_C': 0.9684985563902675, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:55,706] Finished trial#61 with value: 0.4561085972850678 with parameters: {'lr_C': 0.4747874037497727, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:20:59,746] Finished trial#62 with value: 0.4563545906829489 with parameters: {'lr_C': 0.18095987583168088, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:03,774] Finished trial#63 with value: 0.4563545906829489 with parameters: {'lr_C': 0.5048043908736242, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:07,919] Finished trial#64 with value: 0.4561085972850678 with parameters: {'lr_C': 0.43341979662464264, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:11,997] Finished trial#65 with value: 0.4561085972850678 with parameters: {'lr_C': 0.9391716542770575, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:12,841] Finished trial#66 with value: 0.4570135746606335 with parameters: {'lr_C': 0.026791581150603205, 'lr_solver': 'newton-cg'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:16,909] Finished trial#67 with value: 0.4563545906829489 with parameters: {'lr_C': 0.4791062702869077, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:20,741] Finished trial#68 with value: 0.45693563009972793 with parameters: {'lr_C': 0.0930382581806727, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:24,887] Finished trial#69 with value: 0.4561085972850678 with parameters: {'lr_C': 0.9618801232754206, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:28,820] Finished trial#70 with value: 0.4563545906829489 with parameters: {'lr_C': 0.19270741801695407, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:32,843] Finished trial#71 with value: 0.4563545906829489 with parameters: {'lr_C': 0.21324950912108045, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:36,888] Finished trial#72 with value: 0.4561085972850678 with parameters: {'lr_C': 0.756332620320509, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:40,699] Finished trial#73 with value: 0.45693563009972793 with parameters: {'lr_C': 0.06923636973346878, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:44,919] Finished trial#74 with value: 0.4561085972850678 with parameters: {'lr_C': 0.6919457234420251, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:49,465] Finished trial#75 with value: 0.4563545906829489 with parameters: {'lr_C': 0.3015392742271726, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:53,641] Finished trial#76 with value: 0.45627548708654275 with parameters: {'lr_C': 0.11756386921671784, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:54,274] Finished trial#77 with value: 0.45733634311512406 with parameters: {'lr_C': 0.5350431334825232, 'lr_solver': 'lbfgs'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:58,357] Finished trial#78 with value: 0.4561085972850678 with parameters: {'lr_C': 0.9471928863053599, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:21:59,139] Finished trial#79 with value: 0.45709123757904246 with parameters: {'lr_C': 0.15363516570078772, 'lr_solver': 'liblinear', 'lr_penalty': 'l2'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:22:01,206] Finished trial#80 with value: 0.4561085972850678 with parameters: {'lr_C': 0.3052396651908863, 'lr_solver': 'sag'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:22:02,132] Finished trial#81 with value: 0.45733634311512406 with parameters: {'lr_C': 0.3101319422698131, 'lr_solver': 'newton-cg'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:22:04,185] Finished trial#82 with value: 0.4561085972850678 with parameters: {'lr_C': 0.35676728440952565, 'lr_solver': 'sag'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:22:06,281] Finished trial#83 with value: 0.4566003616636528 with parameters: {'lr_C': 0.5627323051290899, 'lr_solver': 'sag'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:22:10,352] Finished trial#84 with value: 0.4561085972850678 with parameters: {'lr_C': 0.6001809974970135, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:22:14,364] Finished trial#85 with value: 0.4561085972850678 with parameters: {'lr_C': 0.8733437122473368, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:22:18,481] Finished trial#86 with value: 0.4561085972850678 with parameters: {'lr_C': 0.8935252948256328, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:22:21,594] Finished trial#87 with value: 0.4589196550158875 with parameters: {'lr_C': 0.016170935776460667, 'lr_solver': 'saga'}. Best is trial#10 with value: 0.4561085972850678.\n",
      "[I 2020-08-12 17:22:25,216] Finished trial#88 with value: 0.4558623811679493 with parameters: {'lr_C': 0.04108295837286748, 'lr_solver': 'saga'}. Best is trial#88 with value: 0.4558623811679493.\n",
      "[I 2020-08-12 17:22:27,669] Finished trial#89 with value: 0.4580879021295876 with parameters: {'lr_C': 0.0048629742271961, 'lr_solver': 'saga'}. Best is trial#88 with value: 0.4558623811679493.\n",
      "[I 2020-08-12 17:22:31,317] Finished trial#90 with value: 0.456689342403628 with parameters: {'lr_C': 0.05315855634518624, 'lr_solver': 'saga'}. Best is trial#88 with value: 0.4558623811679493.\n",
      "[I 2020-08-12 17:22:35,178] Finished trial#91 with value: 0.45693563009972793 with parameters: {'lr_C': 0.07895564023227827, 'lr_solver': 'saga'}. Best is trial#88 with value: 0.4558623811679493.\n",
      "[I 2020-08-12 17:22:39,160] Finished trial#92 with value: 0.4561085972850678 with parameters: {'lr_C': 0.1616067601782321, 'lr_solver': 'saga'}. Best is trial#88 with value: 0.4558623811679493.\n",
      "[I 2020-08-12 17:22:40,920] Finished trial#93 with value: 0.45718169460806524 with parameters: {'lr_C': 0.037722250352973496, 'lr_solver': 'sag'}. Best is trial#88 with value: 0.4558623811679493.\n",
      "[I 2020-08-12 17:22:43,004] Finished trial#94 with value: 0.4561085972850678 with parameters: {'lr_C': 0.3018799434794883, 'lr_solver': 'sag'}. Best is trial#88 with value: 0.4558623811679493.\n",
      "[I 2020-08-12 17:22:43,685] Finished trial#95 with value: 0.46666666666666656 with parameters: {'lr_C': 0.001085731545016275, 'lr_solver': 'sag'}. Best is trial#88 with value: 0.4558623811679493.\n",
      "[I 2020-08-12 17:22:44,378] Finished trial#96 with value: 0.46363636363636374 with parameters: {'lr_C': 2.8118305939828444e-05, 'lr_solver': 'saga'}. Best is trial#88 with value: 0.4558623811679493.\n",
      "[I 2020-08-12 17:22:48,341] Finished trial#97 with value: 0.4563545906829489 with parameters: {'lr_C': 0.168080725978205, 'lr_solver': 'saga'}. Best is trial#88 with value: 0.4558623811679493.\n",
      "[I 2020-08-12 17:22:52,325] Finished trial#98 with value: 0.4563545906829489 with parameters: {'lr_C': 0.23575544960372377, 'lr_solver': 'saga'}. Best is trial#88 with value: 0.4558623811679493.\n",
      "[I 2020-08-12 17:22:53,201] Finished trial#99 with value: 0.4722610722610723 with parameters: {'lr_C': 0.00026421210382203327, 'lr_solver': 'saga'}. Best is trial#88 with value: 0.4558623811679493.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.7283851113716295\n",
      "Testing Precision:  0.42341220423412207\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.7106805833571633\n",
      "Testing Recall:  0.6686332350049164\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.7228338575922219\n",
      "Testing Accuracy:  0.7193333333333334\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.7194239397886815\n",
      "Testing F1-Score:  0.5184902783072817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 82,\n",
    "                                          algorithm = 'ball_tree',\n",
    "                                          p = 2)\n",
    "            \n",
    "\n",
    "# {'lr_C': 0.04108295837286748, 'lr_solver': 'saga'} {'knn_n_neighbors': 82, 'knn_algorithm': 'ball_tree', 'knn_p': 2}\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_train_pred = knn_clf.predict(X_train)\n",
    "y_test_pred = knn_clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    knn_n_neighbors = trial.suggest_int('knn_n_neighbors', 40, 100)\n",
    "    knn_algorithm = trial.suggest_categorical('knn_algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "    knn_p = trial.suggest_categorical('knn_p', [1,2])\n",
    "    \n",
    "    regressor_obj = KNeighborsClassifier(n_neighbors = knn_n_neighbors,\n",
    "                                          algorithm = knn_algorithm,\n",
    "                                          p = knn_p,\n",
    "                                          )\n",
    "    \n",
    "    regressor_obj.fit(X_train, y_train)\n",
    "    y_pred = regressor_obj.predict(X_test)\n",
    "    \n",
    "    return (1 - f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-12 17:39:07,652] Finished trial#0 with value: 0.49327354260089684 with parameters: {'knn_n_neighbors': 51, 'knn_algorithm': 'brute', 'knn_p': 1}. Best is trial#0 with value: 0.49327354260089684.\n",
      "[I 2020-08-12 17:39:19,463] Finished trial#1 with value: 0.48928024502297096 with parameters: {'knn_n_neighbors': 50, 'knn_algorithm': 'kd_tree', 'knn_p': 1}. Best is trial#1 with value: 0.48928024502297096.\n",
      "[I 2020-08-12 17:39:33,418] Finished trial#2 with value: 0.48888051262721444 with parameters: {'knn_n_neighbors': 64, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#2 with value: 0.48888051262721444.\n",
      "[I 2020-08-12 17:39:37,107] Finished trial#3 with value: 0.4834537847090148 with parameters: {'knn_n_neighbors': 72, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:39:40,758] Finished trial#4 with value: 0.5031101353823637 with parameters: {'knn_n_neighbors': 40, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:39:49,704] Finished trial#5 with value: 0.48928024502297096 with parameters: {'knn_n_neighbors': 50, 'knn_algorithm': 'brute', 'knn_p': 1}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:40:03,806] Finished trial#6 with value: 0.48677248677248675 with parameters: {'knn_n_neighbors': 68, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:40:12,777] Finished trial#7 with value: 0.48551564310544615 with parameters: {'knn_n_neighbors': 68, 'knn_algorithm': 'brute', 'knn_p': 1}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:40:16,469] Finished trial#8 with value: 0.4888203546646106 with parameters: {'knn_n_neighbors': 96, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:40:25,415] Finished trial#9 with value: 0.48731541082923135 with parameters: {'knn_n_neighbors': 71, 'knn_algorithm': 'brute', 'knn_p': 1}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:40:44,093] Finished trial#10 with value: 0.48789712556732223 with parameters: {'knn_n_neighbors': 89, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:41:01,481] Finished trial#11 with value: 0.492003046458492 with parameters: {'knn_n_neighbors': 81, 'knn_algorithm': 'ball_tree', 'knn_p': 1}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:41:13,893] Finished trial#12 with value: 0.4853395061728395 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'auto', 'knn_p': 1}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:41:28,245] Finished trial#13 with value: 0.4851336093338352 with parameters: {'knn_n_neighbors': 81, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:41:42,779] Finished trial#14 with value: 0.4856927710843374 with parameters: {'knn_n_neighbors': 83, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:41:57,536] Finished trial#15 with value: 0.4907120743034057 with parameters: {'knn_n_neighbors': 98, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:42:11,274] Finished trial#16 with value: 0.4911952041963281 with parameters: {'knn_n_neighbors': 58, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:42:25,589] Finished trial#17 with value: 0.4851258581235698 with parameters: {'knn_n_neighbors': 78, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:42:40,123] Finished trial#18 with value: 0.48789712556732223 with parameters: {'knn_n_neighbors': 89, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#3 with value: 0.4834537847090148.\n",
      "[I 2020-08-12 17:42:54,408] Finished trial#19 with value: 0.483206106870229 with parameters: {'knn_n_neighbors': 76, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#19 with value: 0.483206106870229.\n",
      "[I 2020-08-12 17:43:08,201] Finished trial#20 with value: 0.4911952041963281 with parameters: {'knn_n_neighbors': 58, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#19 with value: 0.483206106870229.\n",
      "[I 2020-08-12 17:43:22,469] Finished trial#21 with value: 0.483206106870229 with parameters: {'knn_n_neighbors': 76, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#19 with value: 0.483206106870229.\n",
      "[I 2020-08-12 17:43:36,728] Finished trial#22 with value: 0.482811306340718 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:43:51,252] Finished trial#23 with value: 0.48466257668711665 with parameters: {'knn_n_neighbors': 88, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:44:05,567] Finished trial#24 with value: 0.483206106870229 with parameters: {'knn_n_neighbors': 76, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:44:19,508] Finished trial#25 with value: 0.48888051262721444 with parameters: {'knn_n_neighbors': 64, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:44:33,987] Finished trial#26 with value: 0.4849170437405732 with parameters: {'knn_n_neighbors': 85, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:44:48,639] Finished trial#27 with value: 0.4878331402085748 with parameters: {'knn_n_neighbors': 94, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:45:02,568] Finished trial#28 with value: 0.48895434462444776 with parameters: {'knn_n_neighbors': 63, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:45:16,955] Finished trial#29 with value: 0.48449757190885323 with parameters: {'knn_n_neighbors': 79, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:45:35,547] Finished trial#30 with value: 0.483206106870229 with parameters: {'knn_n_neighbors': 76, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:45:54,157] Finished trial#31 with value: 0.482811306340718 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:46:12,734] Finished trial#32 with value: 0.49241583425823165 with parameters: {'knn_n_neighbors': 69, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:46:31,293] Finished trial#33 with value: 0.4834537847090148 with parameters: {'knn_n_neighbors': 72, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:46:45,283] Finished trial#34 with value: 0.4910157682434909 with parameters: {'knn_n_neighbors': 65, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:47:03,871] Finished trial#35 with value: 0.4865671641791045 with parameters: {'knn_n_neighbors': 75, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:47:22,390] Finished trial#36 with value: 0.49306336707911513 with parameters: {'knn_n_neighbors': 60, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:47:41,048] Finished trial#37 with value: 0.4849170437405732 with parameters: {'knn_n_neighbors': 85, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:47:59,458] Finished trial#38 with value: 0.49545619774627403 with parameters: {'knn_n_neighbors': 53, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:48:18,085] Finished trial#39 with value: 0.4854802680565897 with parameters: {'knn_n_neighbors': 73, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:48:35,287] Finished trial#40 with value: 0.4870806016197454 with parameters: {'knn_n_neighbors': 66, 'knn_algorithm': 'ball_tree', 'knn_p': 1}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:48:49,815] Finished trial#41 with value: 0.4851258581235698 with parameters: {'knn_n_neighbors': 78, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:49:04,693] Finished trial#42 with value: 0.483206106870229 with parameters: {'knn_n_neighbors': 76, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:49:19,553] Finished trial#43 with value: 0.4909228441754917 with parameters: {'knn_n_neighbors': 70, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:49:38,269] Finished trial#44 with value: 0.4851336093338352 with parameters: {'knn_n_neighbors': 81, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:49:41,965] Finished trial#45 with value: 0.4834537847090148 with parameters: {'knn_n_neighbors': 72, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:50:00,507] Finished trial#46 with value: 0.48657844990548205 with parameters: {'knn_n_neighbors': 68, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:50:13,000] Finished trial#47 with value: 0.48880308880308876 with parameters: {'knn_n_neighbors': 78, 'knn_algorithm': 'kd_tree', 'knn_p': 1}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:50:27,468] Finished trial#48 with value: 0.4849170437405732 with parameters: {'knn_n_neighbors': 85, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:50:46,025] Finished trial#49 with value: 0.482811306340718 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:51:04,646] Finished trial#50 with value: 0.4851336093338352 with parameters: {'knn_n_neighbors': 81, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:51:23,203] Finished trial#51 with value: 0.4865671641791045 with parameters: {'knn_n_neighbors': 75, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:51:37,372] Finished trial#52 with value: 0.4879406307977736 with parameters: {'knn_n_neighbors': 71, 'knn_algorithm': 'kd_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:51:55,959] Finished trial#53 with value: 0.482811306340718 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:52:14,561] Finished trial#54 with value: 0.4854802680565897 with parameters: {'knn_n_neighbors': 73, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:52:33,101] Finished trial#55 with value: 0.48657844990548205 with parameters: {'knn_n_neighbors': 68, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:52:51,758] Finished trial#56 with value: 0.48449757190885323 with parameters: {'knn_n_neighbors': 79, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:09,161] Finished trial#57 with value: 0.49413988657845 with parameters: {'knn_n_neighbors': 83, 'knn_algorithm': 'ball_tree', 'knn_p': 1}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:12,933] Finished trial#58 with value: 0.48300878197785413 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:16,639] Finished trial#59 with value: 0.5062611806797854 with parameters: {'knn_n_neighbors': 43, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:20,402] Finished trial#60 with value: 0.4868761552680222 with parameters: {'knn_n_neighbors': 67, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:24,182] Finished trial#61 with value: 0.48300878197785413 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:27,954] Finished trial#62 with value: 0.4909228441754917 with parameters: {'knn_n_neighbors': 70, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:31,808] Finished trial#63 with value: 0.48300878197785413 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:35,556] Finished trial#64 with value: 0.4909909909909911 with parameters: {'knn_n_neighbors': 62, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:39,380] Finished trial#65 with value: 0.48300878197785413 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:43,174] Finished trial#66 with value: 0.4879406307977736 with parameters: {'knn_n_neighbors': 71, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:46,953] Finished trial#67 with value: 0.4851258581235698 with parameters: {'knn_n_neighbors': 78, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:50,767] Finished trial#68 with value: 0.48300878197785413 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:54,515] Finished trial#69 with value: 0.4845124282982791 with parameters: {'knn_n_neighbors': 80, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:53:58,340] Finished trial#70 with value: 0.4854151084517577 with parameters: {'knn_n_neighbors': 77, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:54:02,270] Finished trial#71 with value: 0.4865671641791045 with parameters: {'knn_n_neighbors': 75, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:54:06,241] Finished trial#72 with value: 0.4854802680565897 with parameters: {'knn_n_neighbors': 73, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:54:10,132] Finished trial#73 with value: 0.49241583425823165 with parameters: {'knn_n_neighbors': 69, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:54:24,597] Finished trial#74 with value: 0.4856927710843374 with parameters: {'knn_n_neighbors': 83, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:54:28,386] Finished trial#75 with value: 0.48300878197785413 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:54:32,167] Finished trial#76 with value: 0.4864457831325302 with parameters: {'knn_n_neighbors': 66, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:54:36,135] Finished trial#77 with value: 0.4834537847090148 with parameters: {'knn_n_neighbors': 72, 'knn_algorithm': 'brute', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:54:45,190] Finished trial#78 with value: 0.49146110056925996 with parameters: {'knn_n_neighbors': 77, 'knn_algorithm': 'brute', 'knn_p': 1}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:54:59,424] Finished trial#79 with value: 0.482811306340718 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:55:13,587] Finished trial#80 with value: 0.4909228441754917 with parameters: {'knn_n_neighbors': 70, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:55:27,847] Finished trial#81 with value: 0.482811306340718 with parameters: {'knn_n_neighbors': 74, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:55:42,156] Finished trial#82 with value: 0.4854151084517577 with parameters: {'knn_n_neighbors': 77, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:55:56,353] Finished trial#83 with value: 0.4834537847090148 with parameters: {'knn_n_neighbors': 72, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:56:10,786] Finished trial#84 with value: 0.4845124282982791 with parameters: {'knn_n_neighbors': 80, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:56:25,070] Finished trial#85 with value: 0.4865671641791045 with parameters: {'knn_n_neighbors': 75, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:56:39,177] Finished trial#86 with value: 0.49241583425823165 with parameters: {'knn_n_neighbors': 69, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:56:53,354] Finished trial#87 with value: 0.4854802680565897 with parameters: {'knn_n_neighbors': 73, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:57:07,567] Finished trial#88 with value: 0.4879406307977736 with parameters: {'knn_n_neighbors': 71, 'knn_algorithm': 'auto', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:57:26,173] Finished trial#89 with value: 0.48449757190885323 with parameters: {'knn_n_neighbors': 79, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#22 with value: 0.482811306340718.\n",
      "[I 2020-08-12 17:57:44,964] Finished trial#90 with value: 0.48150972169271833 with parameters: {'knn_n_neighbors': 82, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#90 with value: 0.48150972169271833.\n",
      "[I 2020-08-12 17:58:04,032] Finished trial#91 with value: 0.48150972169271833 with parameters: {'knn_n_neighbors': 82, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#90 with value: 0.48150972169271833.\n",
      "[I 2020-08-12 17:58:22,907] Finished trial#92 with value: 0.4869230769230769 with parameters: {'knn_n_neighbors': 92, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#90 with value: 0.48150972169271833.\n",
      "[I 2020-08-12 17:58:41,566] Finished trial#93 with value: 0.48264021365890875 with parameters: {'knn_n_neighbors': 84, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#90 with value: 0.48150972169271833.\n",
      "[I 2020-08-12 17:59:00,235] Finished trial#94 with value: 0.4871794871794872 with parameters: {'knn_n_neighbors': 87, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#90 with value: 0.48150972169271833.\n",
      "[I 2020-08-12 17:59:18,896] Finished trial#95 with value: 0.4856927710843374 with parameters: {'knn_n_neighbors': 83, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#90 with value: 0.48150972169271833.\n",
      "[I 2020-08-12 17:59:37,608] Finished trial#96 with value: 0.4871794871794872 with parameters: {'knn_n_neighbors': 87, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#90 with value: 0.48150972169271833.\n",
      "[I 2020-08-12 17:59:56,330] Finished trial#97 with value: 0.4914740431981811 with parameters: {'knn_n_neighbors': 91, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#90 with value: 0.48150972169271833.\n",
      "[I 2020-08-12 18:00:14,973] Finished trial#98 with value: 0.4851336093338352 with parameters: {'knn_n_neighbors': 81, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#90 with value: 0.48150972169271833.\n",
      "[I 2020-08-12 18:00:33,644] Finished trial#99 with value: 0.4845124282982791 with parameters: {'knn_n_neighbors': 80, 'knn_algorithm': 'ball_tree', 'knn_p': 2}. Best is trial#90 with value: 0.48150972169271833.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=0.2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc_overfit = RandomForestClassifier(max_depth=5,\n",
    "                            max_leaf_nodes=39,\n",
    "                            max_features = .2479,\n",
    "                            min_samples_leaf=8,\n",
    "                            max_samples = 0.2647,\n",
    "                            criterion='entropy')\n",
    "\n",
    "\n",
    "# {'rf_max_depth': 5, 'rf_max_leaf_nodes': 39, 'rf_max_features': 0.24795749696390704, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.26471291186578816, 'rf_criterion': 'entropy'}\n",
    "# parameters = {'max_leaf_nodes': range(10,100,1)}\n",
    "#     'min_samples_split': range(2,10,1)}\n",
    "#     'n_estimators': range(100, 500, 50)}\n",
    "#     'max_depth': range(10,25,1)}\n",
    "#              'min_samples_leaf': range(1,10,1),\n",
    "#              'class_weight': ['balanced',None,'balanced_subsample']}\n",
    "# grid_tree = GridSearchCV(rfc, parameters, cv=5, scoring='f1', n_jobs=-1,verbose=1)\n",
    "\n",
    "rfc_overfit.fit(X_train, y_train)\n",
    "y_train_pred = rfc_overfit.predict(X_train)\n",
    "y_test_pred = rfc_overfit.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 50, 120)\n",
    "    rf_max_leaf_nodes = trial.suggest_int('rf_max_leaf_nodes', 70, 240)\n",
    "    rf_max_features = trial.suggest_loguniform('rf_max_features', .1, .9)\n",
    "    rf_min_samples_leaf = trial.suggest_int('rf_min_samples_leaf', 2, 20)\n",
    "    rf_max_samples = trial.suggest_loguniform('rf_max_samples', .1, .9)\n",
    "    rf_criterion = trial.suggest_categorical('rf_criterion', ['gini', 'entropy'])\n",
    "    \n",
    "    regressor_obj = RandomForestClassifier(max_depth = rf_max_depth,\n",
    "                                          max_leaf_nodes = rf_max_leaf_nodes,\n",
    "                                          max_features = rf_max_features,\n",
    "                                          min_samples_leaf = rf_min_samples_leaf,\n",
    "                                          max_samples = rf_max_samples,\n",
    "                                          n_estimators=300,\n",
    "                                          random_state=42,\n",
    "                                          criterion = rf_criterion)\n",
    "    \n",
    "    regressor_obj.fit(X_train, y_train)\n",
    "    y_pred = regressor_obj.predict(X_test)\n",
    "    \n",
    "    return (1 - f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-12 18:28:19,026] Finished trial#0 with value: 0.46220009053870537 with parameters: {'rf_max_depth': 51, 'rf_max_leaf_nodes': 103, 'rf_max_features': 0.5688882165344097, 'rf_min_samples_leaf': 19, 'rf_max_samples': 0.12774545996747017, 'rf_criterion': 'gini'}. Best is trial#0 with value: 0.46220009053870537.\n",
      "[I 2020-08-12 18:28:25,409] Finished trial#1 with value: 0.4589941096511101 with parameters: {'rf_max_depth': 91, 'rf_max_leaf_nodes': 154, 'rf_max_features': 0.12630569012206003, 'rf_min_samples_leaf': 17, 'rf_max_samples': 0.13388884320727892, 'rf_criterion': 'entropy'}. Best is trial#1 with value: 0.4589941096511101.\n",
      "[I 2020-08-12 18:28:29,345] Finished trial#2 with value: 0.45884492951341516 with parameters: {'rf_max_depth': 92, 'rf_max_leaf_nodes': 73, 'rf_max_features': 0.10241779538408154, 'rf_min_samples_leaf': 17, 'rf_max_samples': 0.14333395362889853, 'rf_criterion': 'gini'}. Best is trial#2 with value: 0.45884492951341516.\n",
      "[I 2020-08-12 18:28:33,639] Finished trial#3 with value: 0.4609800362976406 with parameters: {'rf_max_depth': 74, 'rf_max_leaf_nodes': 110, 'rf_max_features': 0.1029722731426769, 'rf_min_samples_leaf': 14, 'rf_max_samples': 0.15554712965950082, 'rf_criterion': 'gini'}. Best is trial#2 with value: 0.45884492951341516.\n",
      "[I 2020-08-12 18:29:04,897] Finished trial#4 with value: 0.45734265734265744 with parameters: {'rf_max_depth': 84, 'rf_max_leaf_nodes': 160, 'rf_max_features': 0.21581912884692095, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.49612758893620457, 'rf_criterion': 'entropy'}. Best is trial#4 with value: 0.45734265734265744.\n",
      "[I 2020-08-12 18:30:42,763] Finished trial#5 with value: 0.4601978332548281 with parameters: {'rf_max_depth': 69, 'rf_max_leaf_nodes': 154, 'rf_max_features': 0.6902670018675935, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.48483408482905727, 'rf_criterion': 'entropy'}. Best is trial#4 with value: 0.45734265734265744.\n",
      "[I 2020-08-12 18:32:31,573] Finished trial#6 with value: 0.46045197740112986 with parameters: {'rf_max_depth': 94, 'rf_max_leaf_nodes': 133, 'rf_max_features': 0.5882795585497443, 'rf_min_samples_leaf': 20, 'rf_max_samples': 0.7295660229115362, 'rf_criterion': 'entropy'}. Best is trial#4 with value: 0.45734265734265744.\n",
      "[I 2020-08-12 18:33:02,242] Finished trial#7 with value: 0.4615384615384617 with parameters: {'rf_max_depth': 67, 'rf_max_leaf_nodes': 112, 'rf_max_features': 0.8317243681595189, 'rf_min_samples_leaf': 14, 'rf_max_samples': 0.21654023369436584, 'rf_criterion': 'gini'}. Best is trial#4 with value: 0.45734265734265744.\n",
      "[I 2020-08-12 18:33:11,803] Finished trial#8 with value: 0.46105072463768115 with parameters: {'rf_max_depth': 51, 'rf_max_leaf_nodes': 180, 'rf_max_features': 0.2579970643752465, 'rf_min_samples_leaf': 20, 'rf_max_samples': 0.17724540631385566, 'rf_criterion': 'gini'}. Best is trial#4 with value: 0.45734265734265744.\n",
      "[I 2020-08-12 18:33:35,299] Finished trial#9 with value: 0.46474953617810766 with parameters: {'rf_max_depth': 80, 'rf_max_leaf_nodes': 176, 'rf_max_features': 0.5052957488431963, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.11961384803351245, 'rf_criterion': 'entropy'}. Best is trial#4 with value: 0.45734265734265744.\n",
      "[I 2020-08-12 18:34:04,272] Finished trial#10 with value: 0.4576271186440679 with parameters: {'rf_max_depth': 118, 'rf_max_leaf_nodes': 229, 'rf_max_features': 0.20190465345370162, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.3976854390787373, 'rf_criterion': 'entropy'}. Best is trial#4 with value: 0.45734265734265744.\n",
      "[I 2020-08-12 18:34:33,302] Finished trial#11 with value: 0.4558270676691729 with parameters: {'rf_max_depth': 117, 'rf_max_leaf_nodes': 217, 'rf_max_features': 0.2073482631306686, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.40042572216304445, 'rf_criterion': 'entropy'}. Best is trial#11 with value: 0.4558270676691729.\n",
      "[I 2020-08-12 18:35:09,493] Finished trial#12 with value: 0.45625587958607716 with parameters: {'rf_max_depth': 111, 'rf_max_leaf_nodes': 232, 'rf_max_features': 0.17214433873991522, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.7643688655902169, 'rf_criterion': 'entropy'}. Best is trial#11 with value: 0.4558270676691729.\n",
      "[I 2020-08-12 18:35:49,512] Finished trial#13 with value: 0.45667447306791575 with parameters: {'rf_max_depth': 120, 'rf_max_leaf_nodes': 237, 'rf_max_features': 0.1534448223885462, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.884492046325145, 'rf_criterion': 'entropy'}. Best is trial#11 with value: 0.4558270676691729.\n",
      "[I 2020-08-12 18:36:27,604] Finished trial#14 with value: 0.4606317774634606 with parameters: {'rf_max_depth': 110, 'rf_max_leaf_nodes': 208, 'rf_max_features': 0.3424582464956395, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.3202345961904727, 'rf_criterion': 'entropy'}. Best is trial#11 with value: 0.4558270676691729.\n",
      "[I 2020-08-12 18:37:34,389] Finished trial#15 with value: 0.4601226993865031 with parameters: {'rf_max_depth': 107, 'rf_max_leaf_nodes': 214, 'rf_max_features': 0.34637119691072316, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.6619387190836236, 'rf_criterion': 'entropy'}. Best is trial#11 with value: 0.4558270676691729.\n",
      "[I 2020-08-12 18:37:50,627] Finished trial#16 with value: 0.46050808314087754 with parameters: {'rf_max_depth': 106, 'rf_max_leaf_nodes': 205, 'rf_max_features': 0.1617567255843368, 'rf_min_samples_leaf': 10, 'rf_max_samples': 0.2665073773831005, 'rf_criterion': 'entropy'}. Best is trial#11 with value: 0.4558270676691729.\n",
      "[I 2020-08-12 18:38:41,752] Finished trial#17 with value: 0.4596126594237129 with parameters: {'rf_max_depth': 115, 'rf_max_leaf_nodes': 239, 'rf_max_features': 0.26553362023603433, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.598427891502431, 'rf_criterion': 'entropy'}. Best is trial#11 with value: 0.4558270676691729.\n",
      "[I 2020-08-12 18:39:02,377] Finished trial#18 with value: 0.45632881830920125 with parameters: {'rf_max_depth': 99, 'rf_max_leaf_nodes': 193, 'rf_max_features': 0.1731410902720525, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.3660456851350278, 'rf_criterion': 'entropy'}. Best is trial#11 with value: 0.4558270676691729.\n",
      "[I 2020-08-12 18:39:22,721] Finished trial#19 with value: 0.4579614842649131 with parameters: {'rf_max_depth': 103, 'rf_max_leaf_nodes': 222, 'rf_max_features': 0.12991418288895515, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.5125734485762582, 'rf_criterion': 'entropy'}. Best is trial#11 with value: 0.4558270676691729.\n",
      "[I 2020-08-12 18:40:11,010] Finished trial#20 with value: 0.4626585251291686 with parameters: {'rf_max_depth': 112, 'rf_max_leaf_nodes': 239, 'rf_max_features': 0.2097023097539149, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.8450178666035633, 'rf_criterion': 'entropy'}. Best is trial#11 with value: 0.4558270676691729.\n",
      "[I 2020-08-12 18:40:30,750] Finished trial#21 with value: 0.4546300604932526 with parameters: {'rf_max_depth': 99, 'rf_max_leaf_nodes': 193, 'rf_max_features': 0.17225496483980712, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.34544146152310096, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:40:42,866] Finished trial#22 with value: 0.4621771217712177 with parameters: {'rf_max_depth': 100, 'rf_max_leaf_nodes': 195, 'rf_max_features': 0.12940826078486126, 'rf_min_samples_leaf': 11, 'rf_max_samples': 0.2700423803341314, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:41:03,207] Finished trial#23 with value: 0.45925925925925926 with parameters: {'rf_max_depth': 119, 'rf_max_leaf_nodes': 222, 'rf_max_features': 0.2518804055190564, 'rf_min_samples_leaf': 12, 'rf_max_samples': 0.22011479024981032, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:41:28,721] Finished trial#24 with value: 0.45945945945945954 with parameters: {'rf_max_depth': 111, 'rf_max_leaf_nodes': 188, 'rf_max_features': 0.17765347079832558, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.41444140113324685, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:41:45,070] Finished trial#25 with value: 0.4601398601398602 with parameters: {'rf_max_depth': 96, 'rf_max_leaf_nodes': 169, 'rf_max_features': 0.1417554457228658, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.3310795171398316, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:42:30,199] Finished trial#26 with value: 0.46121297602256706 with parameters: {'rf_max_depth': 106, 'rf_max_leaf_nodes': 204, 'rf_max_features': 0.31432355744196516, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.4266722000364917, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:43:38,225] Finished trial#27 with value: 0.4607058823529411 with parameters: {'rf_max_depth': 115, 'rf_max_leaf_nodes': 222, 'rf_max_features': 0.38569909229463756, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.587512639927452, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:43:56,257] Finished trial#28 with value: 0.4610059990770651 with parameters: {'rf_max_depth': 87, 'rf_max_leaf_nodes': 199, 'rf_max_features': 0.18900813465618535, 'rf_min_samples_leaf': 12, 'rf_max_samples': 0.27026738089857194, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:44:23,033] Finished trial#29 with value: 0.4634831460674158 with parameters: {'rf_max_depth': 101, 'rf_max_leaf_nodes': 213, 'rf_max_features': 0.225221094380806, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.7231062679327179, 'rf_criterion': 'gini'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:44:34,101] Finished trial#30 with value: 0.462037037037037 with parameters: {'rf_max_depth': 115, 'rf_max_leaf_nodes': 232, 'rf_max_features': 0.1130281163182756, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.22627525309910057, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:44:53,740] Finished trial#31 with value: 0.4613233923578751 with parameters: {'rf_max_depth': 99, 'rf_max_leaf_nodes': 185, 'rf_max_features': 0.17376186512846822, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.3488220481293932, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:45:00,354] Finished trial#32 with value: 0.4635701275045536 with parameters: {'rf_max_depth': 88, 'rf_max_leaf_nodes': 194, 'rf_max_features': 0.1496891626167001, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.10062074174864816, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:45:26,590] Finished trial#33 with value: 0.4572490706319703 with parameters: {'rf_max_depth': 97, 'rf_max_leaf_nodes': 134, 'rf_max_features': 0.23593706236574102, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.3592867848930887, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:45:45,337] Finished trial#34 with value: 0.4607571560480147 with parameters: {'rf_max_depth': 104, 'rf_max_leaf_nodes': 165, 'rf_max_features': 0.18351006151918142, 'rf_min_samples_leaf': 11, 'rf_max_samples': 0.2944218373103565, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:46:00,675] Finished trial#35 with value: 0.45539467538533396 with parameters: {'rf_max_depth': 90, 'rf_max_leaf_nodes': 215, 'rf_max_features': 0.10678829294419759, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.4538662424342287, 'rf_criterion': 'entropy'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:46:11,706] Finished trial#36 with value: 0.45821596244131446 with parameters: {'rf_max_depth': 81, 'rf_max_leaf_nodes': 218, 'rf_max_features': 0.10913406258364598, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.44552447905096626, 'rf_criterion': 'gini'}. Best is trial#21 with value: 0.4546300604932526.\n",
      "[I 2020-08-12 18:46:32,589] Finished trial#37 with value: 0.4543744120413924 with parameters: {'rf_max_depth': 93, 'rf_max_leaf_nodes': 229, 'rf_max_features': 0.1168943819995875, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.5307110460624413, 'rf_criterion': 'entropy'}. Best is trial#37 with value: 0.4543744120413924.\n",
      "[I 2020-08-12 18:46:52,069] Finished trial#38 with value: 0.4577530176415969 with parameters: {'rf_max_depth': 91, 'rf_max_leaf_nodes': 140, 'rf_max_features': 0.11715792093043134, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.5514636661933058, 'rf_criterion': 'entropy'}. Best is trial#37 with value: 0.4543744120413924.\n",
      "[I 2020-08-12 18:47:02,016] Finished trial#39 with value: 0.4606317774634606 with parameters: {'rf_max_depth': 75, 'rf_max_leaf_nodes': 227, 'rf_max_features': 0.10528379612777614, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.48810159817801485, 'rf_criterion': 'gini'}. Best is trial#37 with value: 0.4543744120413924.\n",
      "[I 2020-08-12 18:47:23,497] Finished trial#40 with value: 0.45821596244131446 with parameters: {'rf_max_depth': 93, 'rf_max_leaf_nodes': 211, 'rf_max_features': 0.13759434930777614, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.4464711232373316, 'rf_criterion': 'entropy'}. Best is trial#37 with value: 0.4543744120413924.\n",
      "[I 2020-08-12 18:47:47,510] Finished trial#41 with value: 0.4629803186504218 with parameters: {'rf_max_depth': 89, 'rf_max_leaf_nodes': 232, 'rf_max_features': 0.12454651800215936, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.6523872583696995, 'rf_criterion': 'entropy'}. Best is trial#37 with value: 0.4543744120413924.\n",
      "[I 2020-08-12 18:48:05,170] Finished trial#42 with value: 0.45621274644658405 with parameters: {'rf_max_depth': 83, 'rf_max_leaf_nodes': 72, 'rf_max_features': 0.1573132075690443, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.3868881555435818, 'rf_criterion': 'entropy'}. Best is trial#37 with value: 0.4543744120413924.\n",
      "[I 2020-08-12 18:48:23,088] Finished trial#43 with value: 0.4601113172541744 with parameters: {'rf_max_depth': 84, 'rf_max_leaf_nodes': 121, 'rf_max_features': 0.14687978033006505, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.4069993973314136, 'rf_criterion': 'entropy'}. Best is trial#37 with value: 0.4543744120413924.\n",
      "[I 2020-08-12 18:48:34,277] Finished trial#44 with value: 0.4558011049723757 with parameters: {'rf_max_depth': 77, 'rf_max_leaf_nodes': 83, 'rf_max_features': 0.10376824350481317, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.37280852871822256, 'rf_criterion': 'entropy'}. Best is trial#37 with value: 0.4543744120413924.\n",
      "[I 2020-08-12 18:48:44,041] Finished trial#45 with value: 0.4610778443113772 with parameters: {'rf_max_depth': 64, 'rf_max_leaf_nodes': 86, 'rf_max_features': 0.10441600081999004, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.3044082627194448, 'rf_criterion': 'entropy'}. Best is trial#37 with value: 0.4543744120413924.\n",
      "[I 2020-08-12 18:49:03,542] Finished trial#46 with value: 0.45650140318054255 with parameters: {'rf_max_depth': 76, 'rf_max_leaf_nodes': 150, 'rf_max_features': 0.1210181165374855, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.5401952438033898, 'rf_criterion': 'entropy'}. Best is trial#37 with value: 0.4543744120413924.\n",
      "[I 2020-08-12 18:49:16,510] Finished trial#47 with value: 0.452960073428178 with parameters: {'rf_max_depth': 69, 'rf_max_leaf_nodes': 84, 'rf_max_features': 0.10385749840650846, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.46897494221697006, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:49:29,725] Finished trial#48 with value: 0.45831414094887146 with parameters: {'rf_max_depth': 70, 'rf_max_leaf_nodes': 89, 'rf_max_features': 0.10079662149402796, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.4634075753710174, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:49:38,597] Finished trial#49 with value: 0.4576584914391486 with parameters: {'rf_max_depth': 56, 'rf_max_leaf_nodes': 101, 'rf_max_features': 0.10107379087945619, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.503528068611417, 'rf_criterion': 'gini'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:49:54,621] Finished trial#50 with value: 0.46341463414634143 with parameters: {'rf_max_depth': 63, 'rf_max_leaf_nodes': 96, 'rf_max_features': 0.10002208405606348, 'rf_min_samples_leaf': 16, 'rf_max_samples': 0.6323588456141559, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:50:08,142] Finished trial#51 with value: 0.4588883785025265 with parameters: {'rf_max_depth': 71, 'rf_max_leaf_nodes': 84, 'rf_max_features': 0.11324899143066411, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.3781184215553778, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:50:21,953] Finished trial#52 with value: 0.45646196150320806 with parameters: {'rf_max_depth': 78, 'rf_max_leaf_nodes': 76, 'rf_max_features': 0.13715525360163297, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.325563046429964, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:50:50,643] Finished trial#53 with value: 0.4589008924377642 with parameters: {'rf_max_depth': 73, 'rf_max_leaf_nodes': 203, 'rf_max_features': 0.19388243919900947, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.46630124531879147, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:51:08,504] Finished trial#54 with value: 0.4590088003705418 with parameters: {'rf_max_depth': 66, 'rf_max_leaf_nodes': 111, 'rf_max_features': 0.12250504079683208, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.5213716885844014, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:51:54,961] Finished trial#55 with value: 0.46334586466165417 with parameters: {'rf_max_depth': 79, 'rf_max_leaf_nodes': 179, 'rf_max_features': 0.2787235986574686, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.572259590709724, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:52:15,120] Finished trial#56 with value: 0.4587242026266417 with parameters: {'rf_max_depth': 60, 'rf_max_leaf_nodes': 217, 'rf_max_features': 0.1328787808778441, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.4077577106448366, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:52:53,235] Finished trial#57 with value: 0.4610059990770651 with parameters: {'rf_max_depth': 95, 'rf_max_leaf_nodes': 77, 'rf_max_features': 0.4443379253182601, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.2951642199992029, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:53:19,413] Finished trial#58 with value: 0.45882352941176463 with parameters: {'rf_max_depth': 90, 'rf_max_leaf_nodes': 226, 'rf_max_features': 0.2111835464921075, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.3455241000410767, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:53:41,448] Finished trial#59 with value: 0.45513413506012956 with parameters: {'rf_max_depth': 86, 'rf_max_leaf_nodes': 124, 'rf_max_features': 0.16287710427925658, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.4348544907499681, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:53:55,083] Finished trial#60 with value: 0.4610778443113772 with parameters: {'rf_max_depth': 86, 'rf_max_leaf_nodes': 119, 'rf_max_features': 0.16453080099634654, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.23820618198627952, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:54:15,572] Finished trial#61 with value: 0.4573785517873511 with parameters: {'rf_max_depth': 82, 'rf_max_leaf_nodes': 92, 'rf_max_features': 0.16322014934587178, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.43351444480826273, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:54:38,682] Finished trial#62 with value: 0.4567329939842666 with parameters: {'rf_max_depth': 92, 'rf_max_leaf_nodes': 104, 'rf_max_features': 0.20022741417246795, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.36722464209006395, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:55:10,798] Finished trial#63 with value: 0.45691662785281784 with parameters: {'rf_max_depth': 85, 'rf_max_leaf_nodes': 120, 'rf_max_features': 0.23671292954766135, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.47954222655233303, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:55:24,571] Finished trial#64 with value: 0.45921173235563706 with parameters: {'rf_max_depth': 77, 'rf_max_leaf_nodes': 80, 'rf_max_features': 0.11045514032970839, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.3939972246878197, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:55:45,196] Finished trial#65 with value: 0.45633802816901414 with parameters: {'rf_max_depth': 73, 'rf_max_leaf_nodes': 208, 'rf_max_features': 0.14407643765297062, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.42775164164038604, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:56:05,449] Finished trial#66 with value: 0.45882352941176463 with parameters: {'rf_max_depth': 97, 'rf_max_leaf_nodes': 240, 'rf_max_features': 0.1279997140166692, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.4966414444037699, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:56:20,864] Finished trial#67 with value: 0.45637277295568757 with parameters: {'rf_max_depth': 94, 'rf_max_leaf_nodes': 70, 'rf_max_features': 0.15406231331730208, 'rf_min_samples_leaf': 10, 'rf_max_samples': 0.330043459158061, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:56:41,730] Finished trial#68 with value: 0.45903165735567975 with parameters: {'rf_max_depth': 80, 'rf_max_leaf_nodes': 153, 'rf_max_features': 0.11796053386969696, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.5970311216859183, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:58:58,189] Finished trial#69 with value: 0.4612826603325416 with parameters: {'rf_max_depth': 68, 'rf_max_leaf_nodes': 146, 'rf_max_features': 0.8805527194929524, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.5426214666158704, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:59:34,242] Finished trial#70 with value: 0.45650140318054255 with parameters: {'rf_max_depth': 86, 'rf_max_leaf_nodes': 174, 'rf_max_features': 0.18431352323962027, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.6855925528346939, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 18:59:51,528] Finished trial#71 with value: 0.459533607681756 with parameters: {'rf_max_depth': 83, 'rf_max_leaf_nodes': 70, 'rf_max_features': 0.1531413427767341, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.3764717823871004, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:00:13,052] Finished trial#72 with value: 0.4572490706319703 with parameters: {'rf_max_depth': 88, 'rf_max_leaf_nodes': 161, 'rf_max_features': 0.16258002701735214, 'rf_min_samples_leaf': 2, 'rf_max_samples': 0.3943801883180986, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:00:35,346] Finished trial#73 with value: 0.45710267229254575 with parameters: {'rf_max_depth': 82, 'rf_max_leaf_nodes': 236, 'rf_max_features': 0.13552050181127778, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.45247944021682573, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:00:55,900] Finished trial#74 with value: 0.4584702017832003 with parameters: {'rf_max_depth': 90, 'rf_max_leaf_nodes': 218, 'rf_max_features': 0.17388370108330636, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.34771261116146135, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:01:07,274] Finished trial#75 with value: 0.46082089552238803 with parameters: {'rf_max_depth': 109, 'rf_max_leaf_nodes': 190, 'rf_max_features': 0.10579107417890589, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.3079695146655238, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:01:23,057] Finished trial#76 with value: 0.46139359698681737 with parameters: {'rf_max_depth': 84, 'rf_max_leaf_nodes': 201, 'rf_max_features': 0.21469560980867133, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.3891526609480484, 'rf_criterion': 'gini'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:01:49,176] Finished trial#77 with value: 0.4566527584608252 with parameters: {'rf_max_depth': 92, 'rf_max_leaf_nodes': 105, 'rf_max_features': 0.19916113150416068, 'rf_min_samples_leaf': 3, 'rf_max_samples': 0.42091729717964044, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:02:06,449] Finished trial#78 with value: 0.4591836734693877 with parameters: {'rf_max_depth': 102, 'rf_max_leaf_nodes': 132, 'rf_max_features': 0.1172827345846005, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.4748886345799953, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:02:20,031] Finished trial#79 with value: 0.4602298850574714 with parameters: {'rf_max_depth': 88, 'rf_max_leaf_nodes': 95, 'rf_max_features': 0.15600295574685194, 'rf_min_samples_leaf': 4, 'rf_max_samples': 0.25149854011493783, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:02:35,182] Finished trial#80 with value: 0.4558823529411764 with parameters: {'rf_max_depth': 80, 'rf_max_leaf_nodes': 81, 'rf_max_features': 0.14412748078370993, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.36141772987874043, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:02:47,686] Finished trial#81 with value: 0.4579696830500689 with parameters: {'rf_max_depth': 79, 'rf_max_leaf_nodes': 80, 'rf_max_features': 0.14567768492864974, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.27946692460086736, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:03:02,054] Finished trial#82 with value: 0.4571297569922055 with parameters: {'rf_max_depth': 77, 'rf_max_leaf_nodes': 71, 'rf_max_features': 0.1306271079481703, 'rf_min_samples_leaf': 5, 'rf_max_samples': 0.34664208648890454, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:03:19,526] Finished trial#83 with value: 0.45613229214515394 with parameters: {'rf_max_depth': 74, 'rf_max_leaf_nodes': 83, 'rf_max_features': 0.16718687156763315, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.3685930432977994, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:03:37,311] Finished trial#84 with value: 0.4586397058823529 with parameters: {'rf_max_depth': 73, 'rf_max_leaf_nodes': 85, 'rf_max_features': 0.18030126156718504, 'rf_min_samples_leaf': 10, 'rf_max_samples': 0.3195372816152159, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:03:55,363] Finished trial#85 with value: 0.4580645161290323 with parameters: {'rf_max_depth': 75, 'rf_max_leaf_nodes': 95, 'rf_max_features': 0.16920727877430367, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.3660325111763624, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:04:16,763] Finished trial#86 with value: 0.4579439252336448 with parameters: {'rf_max_depth': 65, 'rf_max_leaf_nodes': 224, 'rf_max_features': 0.1415643837401942, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.4438118938564049, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:05:57,184] Finished trial#87 with value: 0.45999064108563403 with parameters: {'rf_max_depth': 71, 'rf_max_leaf_nodes': 100, 'rf_max_features': 0.7183202162443144, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.5218397020435367, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:06:11,959] Finished trial#88 with value: 0.4583908045977011 with parameters: {'rf_max_depth': 117, 'rf_max_leaf_nodes': 91, 'rf_max_features': 0.1103126715315406, 'rf_min_samples_leaf': 10, 'rf_max_samples': 0.42241247479651395, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:06:21,924] Finished trial#89 with value: 0.45572554473806204 with parameters: {'rf_max_depth': 70, 'rf_max_leaf_nodes': 209, 'rf_max_features': 0.12467210216485046, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.2023928553340195, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:06:26,590] Finished trial#90 with value: 0.4599728629579376 with parameters: {'rf_max_depth': 60, 'rf_max_leaf_nodes': 209, 'rf_max_features': 0.1247960544413966, 'rf_min_samples_leaf': 12, 'rf_max_samples': 0.12285988341858022, 'rf_criterion': 'gini'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:06:35,461] Finished trial#91 with value: 0.4605504587155963 with parameters: {'rf_max_depth': 69, 'rf_max_leaf_nodes': 198, 'rf_max_features': 0.11793916543481706, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.17308976120042793, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:06:43,996] Finished trial#92 with value: 0.46125461254612543 with parameters: {'rf_max_depth': 71, 'rf_max_leaf_nodes': 216, 'rf_max_features': 0.13852782486555582, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.1368423384555697, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:06:52,515] Finished trial#93 with value: 0.4580824455766559 with parameters: {'rf_max_depth': 67, 'rf_max_leaf_nodes': 230, 'rf_max_features': 0.10531608694735715, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.20411850124840028, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:07:11,843] Finished trial#94 with value: 0.460999532928538 with parameters: {'rf_max_depth': 75, 'rf_max_leaf_nodes': 213, 'rf_max_features': 0.19125877699284125, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.2808219171700115, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:07:25,914] Finished trial#95 with value: 0.4571297569922055 with parameters: {'rf_max_depth': 72, 'rf_max_leaf_nodes': 78, 'rf_max_features': 0.11300829091272376, 'rf_min_samples_leaf': 7, 'rf_max_samples': 0.4121253952072034, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:07:41,173] Finished trial#96 with value: 0.46031746031746035 with parameters: {'rf_max_depth': 98, 'rf_max_leaf_nodes': 221, 'rf_max_features': 0.12769139842743452, 'rf_min_samples_leaf': 9, 'rf_max_samples': 0.3506527923769867, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:08:07,466] Finished trial#97 with value: 0.45845004668534084 with parameters: {'rf_max_depth': 78, 'rf_max_leaf_nodes': 234, 'rf_max_features': 0.1484813039607745, 'rf_min_samples_leaf': 6, 'rf_max_samples': 0.5717233012910908, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:08:17,165] Finished trial#98 with value: 0.4586191129401007 with parameters: {'rf_max_depth': 81, 'rf_max_leaf_nodes': 83, 'rf_max_features': 0.10105641402252712, 'rf_min_samples_leaf': 11, 'rf_max_samples': 0.31000153798237573, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n",
      "[I 2020-08-12 19:08:30,436] Finished trial#99 with value: 0.46068455134135056 with parameters: {'rf_max_depth': 62, 'rf_max_leaf_nodes': 205, 'rf_max_features': 0.16621799674661908, 'rf_min_samples_leaf': 8, 'rf_max_samples': 0.20184739847896732, 'rf_criterion': 'entropy'}. Best is trial#47 with value: 0.452960073428178.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.5416055334311465\n",
      "Testing Precision:  0.5195996663886572\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.6442283719770631\n",
      "Testing Recall:  0.6125860373647984\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.7992110672815156\n",
      "Testing Accuracy:  0.7844444444444445\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.5884764290594398\n",
      "Testing F1-Score:  0.5622743682310468\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=0.2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
    "                       criterion='gini', max_depth=19, max_features=0.5,\n",
    "                       max_leaf_nodes=74, max_samples=0.66,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=13, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
    "                       warm_start=False)\n",
    "\n",
    "\n",
    "\n",
    "# parameters = {'max_leaf_nodes': range(10,100,1)}\n",
    "#     'min_samples_split': range(2,10,1)}\n",
    "#     'n_estimators': range(100, 500, 50)}\n",
    "#     'max_depth': range(10,25,1)}\n",
    "#              'min_samples_leaf': range(1,10,1),\n",
    "#              'class_weight': ['balanced',None,'balanced_subsample']}\n",
    "# grid_tree = GridSearchCV(rfc, parameters, cv=5, scoring='f1', n_jobs=-1,verbose=1)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "y_train_pred = rfc.predict(X_train)\n",
    "y_test_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.5098631239935588\n",
      "Testing Precision:  0.5035913806863528\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.6315133383196211\n",
      "Testing Recall:  0.6204523107177975\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.7825990332796267\n",
      "Testing Accuracy:  0.776\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.5642053680810781\n",
      "Testing F1-Score:  0.5559471365638767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bc_dtc = BaggingClassifier(\n",
    "            base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
    "                       max_depth=6, max_features=0.4, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=8, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=42, splitter='best'), \n",
    "            n_estimators= 300,\n",
    "            max_samples= 0.66,\n",
    "            max_features= .8,\n",
    "            oob_score= True, n_jobs=-1\n",
    "                )\n",
    "\n",
    "\n",
    "bc_dtc.fit(X_train, y_train)\n",
    "y_train_pred = bc_dtc.predict(X_train)\n",
    "y_test_pred = bc_dtc.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.7302631578947368\n",
      "Testing Precision:  0.6858846918489065\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.387434554973822\n",
      "Testing Recall:  0.3392330383480826\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.8316017556530918\n",
      "Testing Accuracy:  0.8155555555555556\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.5062713797035349\n",
      "Testing F1-Score:  0.45394736842105265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier(random_state=42, n_estimators=300)\n",
    "\n",
    "\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "y_train_pred = adaboost_clf.predict(X_train)\n",
    "y_test_pred = adaboost_clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.7211174242424242\n",
      "Testing Precision:  0.6948529411764706\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.37970580902518075\n",
      "Testing Recall:  0.37168141592920356\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.8290460581143397\n",
      "Testing Accuracy:  0.8211111111111111\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.4974685611628287\n",
      "Testing F1-Score:  0.48430493273542596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "gbt_clf  = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "\n",
    "gbt_clf.fit(X_train, y_train)\n",
    "y_train_pred = gbt_clf.predict(X_train)\n",
    "y_test_pred = gbt_clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.5153196622436671\n",
      "Testing Precision:  0.5377990430622009\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.5325355272999253\n",
      "Testing Recall:  0.5526057030481809\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.7842102339018835\n",
      "Testing Accuracy:  0.7915555555555556\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.523786169691025\n",
      "Testing F1-Score:  0.545101842870999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "bc_lr1 = BaggingClassifier(\n",
    "            base_estimator=LogisticRegression(solver='liblinear', class_weight='balanced', penalty='l1', C=.01), \n",
    "            n_estimators= 300,\n",
    "            max_samples= 0.66,\n",
    "            max_features= .8,\n",
    "            oob_score= True, n_jobs=-1\n",
    "                )\n",
    "\n",
    "\n",
    "bc_lr1.fit(X_train, y_train)\n",
    "y_train_pred = bc_lr1.predict(X_train)\n",
    "y_test_pred = bc_lr1.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "                estimators=[('rfc', rfc), ('bc_dtc', bc_dtc),  ('bc_lr1', bc_lr1)],\n",
    "                voting='hard', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.532349841938883\n",
      "Testing Precision:  0.5188916876574308\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.6297681376215407\n",
      "Testing Recall:  0.6076696165191741\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.7942107894883049\n",
      "Testing Accuracy:  0.784\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.5769757880310644\n",
      "Testing F1-Score:  0.5597826086956521\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=0.2)\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_train = pd.DataFrame(data = X_train,\n",
    "#                       columns = X.columns)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# X_test = pd.DataFrame(data = X_test,\n",
    "#                      columns = X.columns)\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_train_pred = voting_clf.predict(X_train)\n",
    "y_test_pred = voting_clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\albert\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.9835447377442578\n",
      "Testing Precision:  0.6342281879194631\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  0.7152829718274745\n",
      "Testing Recall:  0.37168141592920356\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.9338852158453247\n",
      "Testing Accuracy:  0.8095555555555556\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.8282332563510393\n",
      "Testing F1-Score:  0.4686918784872908\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas.util.testing as tm\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.1],\n",
    "    'max_depth': [6],\n",
    "    'min_child_weight': [10],\n",
    "    'subsample': [ 0.7],\n",
    "    'n_estimators': [5, 30, 100, 250],\n",
    "}\n",
    "grid_clf = GridSearchCV(xgb_clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "\n",
    "grid_clf.fit(X_train, y_train)\n",
    "y_train_pred = grid_clf.predict(X_train)\n",
    "y_test_pred = grid_clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.5332358415315076\n",
      "Testing Precision:  0.35747021081576535\n",
      "\n",
      "\n",
      "\n",
      "Training Recall:  1.0\n",
      "Testing Recall:  0.7669616519174042\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy:  0.8049336074226346\n",
      "Testing Accuracy:  0.6357777777777778\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score:  0.6955692361050898\n",
      "Testing F1-Score:  0.4876523913723039\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints=None,\n",
    "              learning_rate=0.02, max_delta_step=0, max_depth=18,\n",
    "              min_child_weight=5, monotone_constraints=None,\n",
    "              n_estimators=230, n_jobs=-1, num_parallel_tree=1, \n",
    "              objective='binary:logistic', random_state=42, reg_alpha=0.1,\n",
    "              reg_lambda=0.1, scale_pos_weight=67, subsample=0.8, tree_method=None,\n",
    "              validate_parameters=False, verbosity=None)\n",
    "\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     \"learning_rate\": [0.1],\n",
    "#     'max_depth': [6],\n",
    "#     'min_child_weight': [10],\n",
    "#     'subsample': [ 0.7],\n",
    "#     'n_estimators': [5, 30, 100, 250],\n",
    "# }\n",
    "# grid_clf = GridSearchCV(xgb_clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_train_pred = xgb_clf.predict(X_train)\n",
    "y_test_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas.util.testing as tm\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints=None,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=18,\n",
    "              min_child_weight=7, monotone_constraints=None,\n",
    "              n_estimators=130, n_jobs=0, num_parallel_tree=1,\n",
    "              objective='binary:logistic', random_state=42, reg_alpha=0,\n",
    "              reg_lambda=1, scale_pos_weight=67, subsample=0.9, tree_method=None,\n",
    "              validate_parameters=False, verbosity=None)\n",
    "\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     \"learning_rate\": [0.1],\n",
    "#     'max_depth': [6],\n",
    "#     'min_child_weight': [10],\n",
    "#     'subsample': [ 0.7],\n",
    "#     'n_estimators': [5, 30, 100, 250],\n",
    "# }\n",
    "# grid_clf = GridSearchCV(xgb_clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_train_pred = xgb_clf.predict(X_train)\n",
    "y_test_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=30, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=0.7, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'n_estimators': 130, 'max_depth': 18, 'min_child_weight': 7, 'scale_pos_weight': 67, 'subsample': 0.9, 'colsample_bytree': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.6min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-c4a4b3a3cb56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mgrid_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mgrid_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas.util.testing as tm\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(gpu_id=-1)\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "    'max_depth': [6, 7, 8, 9],\n",
    "    'min_child_weight': [8,10,12],\n",
    "    'subsample': [ 0.5,0.7],\n",
    "    'n_estimators': [5, 30, 100, 250],\n",
    "}\n",
    "grid_clf = GridSearchCV(xgb_clf, param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_clf.fit(X_train, y_train)\n",
    "y_train_pred = grid_clf.predict(X_train)\n",
    "y_test_pred = grid_clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "\n",
    "    \n",
    "    param = {\n",
    "        'silent':1,\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'booster': trial.suggest_categorical('booster', {'gbtree', 'gblinear', 'dart'}),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
    "    }\n",
    "    \n",
    "    if param['booster'] == 'gbtree' or param['booster'] == 'dart':\n",
    "        param['max_depth'] = trial.suggest_int('max_depth', 1, 9)\n",
    "        param['eta'] = trial.suggest_loguniform('eta', 1e-8, 1.0)\n",
    "        param['gamma'] = trial.suggest_loguniform('gamma', 1e-8, 1.0)\n",
    "        param['grow_policy'] = trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide'])\n",
    "    \n",
    "    if param['booster'] == 'dart':\n",
    "        param['sample_type'] = trial.suggest_categorical('sample_type', ['uniform', 'weighted'])\n",
    "        param['normalize_type'] = trial.suggest_categorical('normalize_type', ['tree','forest'])\n",
    "        param['rate_drop'] = trial.suggest_loguniform('rate_drop', 1e-8, 1.0)\n",
    "        param['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)\n",
    "        \n",
    "        \n",
    "\n",
    "    xgboost_tuna = xgb.XGBClassifier()\n",
    "    \n",
    "    xgboost_tuna.fit(X_train, y_train)\n",
    "    tuna_pred_test = xgboost_tuna.predict(X_test)\n",
    "    \n",
    "    return (1-f1_score(y_test, tuna_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt(X_train, y_train, X_test, y_test, trial):\n",
    "    #param_list\n",
    "    booster = 'gbtree'\n",
    "#     lambda_ = trial.suggest_loguniform('lambda', 1e-8, 1.0)\n",
    "    alpha_ = trial.suggest_loguniform('alpha', 1e-8, 1.0)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 9)\n",
    "    eta = trial.suggest_loguniform('eta', 1e-8, 1.0)\n",
    "    gamma =trial.suggest_loguniform('gamma', 1e-8, 1.0)\n",
    "    grow_policy = trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide'])\n",
    "    \n",
    "\n",
    "    xgboost_tuna = xgb.XGBClassifier(\n",
    "        random_state=42, \n",
    "        booster = booster,\n",
    "        alpha = alpha_,\n",
    "        max_depth = max_depth,\n",
    "        eta = eta,\n",
    "        gamma = gamma,\n",
    "        grow_policy = grow_policy\n",
    "    )\n",
    "    xgboost_tuna.fit(X_train, y_train)\n",
    "    tuna_pred_test = xgboost_tuna.predict(X_test)\n",
    "    \n",
    "    return (1-f1_score(y_test, tuna_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt(X_train, y_train, X_test, y_test, trial):\n",
    "    #param_list\n",
    "\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 0, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 40)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 30)\n",
    "    learning_rate = trial.suggest_discrete_uniform('learning_rate', 0.01, 0.1, 0.01)\n",
    "    scale_pos_weight = trial.suggest_int('scale_pos_weight', 1, 100)\n",
    "    subsample = trial.suggest_discrete_uniform('subsample', 0.4, 0.9, 0.1)\n",
    "    colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.4, 0.9, 0.1)\n",
    "\n",
    "    xgboost_tuna = xgb.XGBClassifier(\n",
    "        random_state=42, \n",
    "        tree_method='gpu_hist',\n",
    "        n_estimators = n_estimators,\n",
    "        max_depth = max_depth,\n",
    "        min_child_weight = min_child_weight,\n",
    "        learning_rate = learning_rate,\n",
    "        scale_pos_weight = scale_pos_weight,\n",
    "        subsample = subsample,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "    )\n",
    "    xgboost_tuna.fit(X_train, y_train)\n",
    "    tuna_pred_test = xgboost_tuna.predict(X_test)\n",
    "    \n",
    "    return (1-f1_score(y_test, tuna_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\albert\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning:\n",
      "\n",
      "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas.testing\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "import functools\n",
    "study.optimize(functools.partial(opt, X_train, y_train, X_test, y_test), n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'n_estimators': 234, 'max_depth': 40, 'min_child_weight': 12, 'learning_rate': 0.060000000000000005, 'scale_pos_weight': 7, 'subsample': 0.5, 'colsample_bytree': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas.util.testing as tm\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(gpu_id=-1)\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "    'max_depth': [6, 7, 8, 9],\n",
    "    'min_child_weight': [8,10,12],\n",
    "    'subsample': [ 0.5,0.7],\n",
    "    'n_estimators': [5, 30, 100, 250],\n",
    "}\n",
    "grid_clf = GridSearchCV(xgb_clf, param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_clf.fit(X_train, y_train)\n",
    "y_train_pred = grid_clf.predict(X_train)\n",
    "y_test_pred = grid_clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-auc:0.74282\n",
      "[1]\tvalidation-auc:0.74897\n",
      "[2]\tvalidation-auc:0.75378\n",
      "[3]\tvalidation-auc:0.75323\n",
      "[4]\tvalidation-auc:0.75277\n",
      "[5]\tvalidation-auc:0.75307\n",
      "[6]\tvalidation-auc:0.75253\n",
      "[7]\tvalidation-auc:0.75219\n",
      "[8]\tvalidation-auc:0.75184\n",
      "[9]\tvalidation-auc:0.75199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-12 08:49:38,997] Finished trial#0 with value: 0.8073333333333333 with parameters: {'booster': 'gblinear', 'lambda': 4.456886019648993e-07, 'alpha': 0.034263600573274974}. Best is trial#0 with value: 0.8073333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-auc:0.74358\n",
      "[1]\tvalidation-auc:0.74400\n",
      "[2]\tvalidation-auc:0.75995\n",
      "[3]\tvalidation-auc:0.77288\n",
      "[4]\tvalidation-auc:0.77311\n",
      "[5]\tvalidation-auc:0.77683\n",
      "[6]\tvalidation-auc:0.77753\n",
      "[7]\tvalidation-auc:0.77954\n",
      "[8]\tvalidation-auc:0.77997\n",
      "[9]\tvalidation-auc:0.78039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-12 08:49:40,586] Finished trial#1 with value: 0.8226666666666667 with parameters: {'booster': 'dart', 'lambda': 0.28620214818397915, 'alpha': 0.005755769888038868, 'max_depth': 3, 'eta': 0.15782301315139421, 'gamma': 0.007067552755752852, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 8.635053410458381e-08, 'skip_drop': 1.8187042298764968e-08}. Best is trial#0 with value: 0.8073333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-auc:0.75804\n",
      "[1]\tvalidation-auc:0.76268\n",
      "[2]\tvalidation-auc:0.76491\n",
      "[3]\tvalidation-auc:0.76473\n",
      "[4]\tvalidation-auc:0.76746\n",
      "[5]\tvalidation-auc:0.76756\n",
      "[6]\tvalidation-auc:0.77028\n",
      "[7]\tvalidation-auc:0.77120\n",
      "[8]\tvalidation-auc:0.77198\n",
      "[9]\tvalidation-auc:0.77243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-12 08:49:43,779] Finished trial#2 with value: 0.8166666666666667 with parameters: {'booster': 'gbtree', 'lambda': 1.2831527099149306e-05, 'alpha': 1.606872674693005e-05, 'max_depth': 7, 'eta': 0.004339937997300324, 'gamma': 3.089278839700702e-07, 'grow_policy': 'lossguide'}. Best is trial#0 with value: 0.8073333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-auc:0.50000\n",
      "[1]\tvalidation-auc:0.50000\n",
      "[2]\tvalidation-auc:0.50000\n",
      "[3]\tvalidation-auc:0.56266\n",
      "[4]\tvalidation-auc:0.56266\n",
      "[5]\tvalidation-auc:0.69845\n",
      "[6]\tvalidation-auc:0.70232\n",
      "[7]\tvalidation-auc:0.70232\n",
      "[8]\tvalidation-auc:0.70232\n",
      "[9]\tvalidation-auc:0.70232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-12 08:49:45,176] Finished trial#3 with value: 0.8202222222222222 with parameters: {'booster': 'gbtree', 'lambda': 4.803349021360904e-06, 'alpha': 0.042726156481543265, 'max_depth': 2, 'eta': 2.318138409578163e-08, 'gamma': 2.5336928569809252e-08, 'grow_policy': 'depthwise'}. Best is trial#0 with value: 0.8073333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-auc:0.70510\n",
      "[1]\tvalidation-auc:0.75092\n",
      "[2]\tvalidation-auc:0.75113\n",
      "[3]\tvalidation-auc:0.75100\n",
      "[4]\tvalidation-auc:0.75097\n",
      "[5]\tvalidation-auc:0.75134\n",
      "[6]\tvalidation-auc:0.75138\n",
      "[7]\tvalidation-auc:0.75103\n",
      "[8]\tvalidation-auc:0.75099\n",
      "[9]\tvalidation-auc:0.75135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-12 08:49:47,015] Finished trial#4 with value: 0.82 with parameters: {'booster': 'gbtree', 'lambda': 0.8126054411330562, 'alpha': 0.0008412211426558617, 'max_depth': 4, 'eta': 3.3744751949930707e-07, 'gamma': 0.002192157250346616, 'grow_policy': 'depthwise'}. Best is trial#0 with value: 0.8073333333333333.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:0.38509\n",
      "[1]\tvalidation-rmse:0.38306\n",
      "[2]\tvalidation-rmse:0.38227\n",
      "[3]\tvalidation-rmse:0.38176\n",
      "[4]\tvalidation-rmse:0.38141\n",
      "[5]\tvalidation-rmse:0.38120\n",
      "[6]\tvalidation-rmse:0.38106\n",
      "[7]\tvalidation-rmse:0.38094\n",
      "[8]\tvalidation-rmse:0.38086\n",
      "[9]\tvalidation-rmse:0.38079\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "('Expecting data to be a DMatrix object, got: ', <class 'pandas.core.frame.DataFrame'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-b14a6accb5cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# xgb_clf.fit(X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[0;32m   1438\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m             raise TypeError('Expecting data to be a DMatrix object, got: ',\n\u001b[1;32m-> 1440\u001b[1;33m                             type(data))\n\u001b[0m\u001b[0;32m   1441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('Expecting data to be a DMatrix object, got: ', <class 'pandas.core.frame.DataFrame'>)"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas.util.testing as tm\n",
    "\n",
    "param = {'booster': 'gblinear', \n",
    "         'lambda': 0.0006425358326832809, \n",
    "         'alpha': 0.0003101918662407133}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "dtrain = xgb.DMatrix(X_train, label= y_train)\n",
    "dtest = xgb.DMatrix(X_test, label= y_test)\n",
    "\n",
    "bst = xgb.train(param, dtrain, evals=[(dtest, 'validation')])\n",
    "\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "#     'max_depth': [6, 7, 8, 9],\n",
    "#     'min_child_weight': [8,10,12],\n",
    "#     'subsample': [ 0.5,0.7],\n",
    "#     'n_estimators': [5, 30, 100, 250],\n",
    "# }\n",
    "# grid_clf = GridSearchCV(xgb_clf, param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# xgb_clf.fit(X_train, y_train)\n",
    "y_train_pred = bst.predict(X_train)\n",
    "y_test_pred = bst.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "clf = SVC(kernel='poly', degree=8)\n",
    "# feature_map_nystroem = Nystroem(gamma=.2,\n",
    "#                                random_state=1,\n",
    "#                                n_components=300)\n",
    "# X_train_transformed = feature_map_nystroem.fit_transform(X_train)\n",
    "# X_test_transformed = feature_map_nystroem.transform(X_test)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# bc_dtc = BaggingClassifier(\n",
    "#             base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
    "#                        max_depth=6, max_features=0.4, max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                        min_samples_leaf=8, min_samples_split=2,\n",
    "#                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "#                        random_state=42, splitter='best'), \n",
    "#             n_estimators= 100,\n",
    "#             max_samples= 0.66,\n",
    "#             max_features= .8,\n",
    "#             oob_score= True, n_jobs=-1\n",
    "#                 )\n",
    "\n",
    "\n",
    "# bc_dtc.fit(X_train, y_train)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "clf = SVC(kernel='poly')\n",
    "# feature_map_nystroem = Nystroem(gamma=.2,\n",
    "#                                random_state=1,\n",
    "#                                n_components=300)\n",
    "# X_train_transformed = feature_map_nystroem.fit_transform(X_train)\n",
    "# X_test_transformed = feature_map_nystroem.transform(X_test)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# bc_dtc = BaggingClassifier(\n",
    "#             base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
    "#                        max_depth=6, max_features=0.4, max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                        min_samples_leaf=8, min_samples_split=2,\n",
    "#                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "#                        random_state=42, splitter='best'), \n",
    "#             n_estimators= 100,\n",
    "#             max_samples= 0.66,\n",
    "#             max_features= .8,\n",
    "#             oob_score= True, n_jobs=-1\n",
    "#                 )\n",
    "\n",
    "\n",
    "# bc_dtc.fit(X_train, y_train)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Training Precision: ', precision_score(y_train, y_train_pred))\n",
    "print('Testing Precision: ', precision_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_train, y_train_pred))\n",
    "print('Testing Recall: ', recall_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ', f1_score(y_train, y_train_pred))\n",
    "print('Testing F1-Score: ', f1_score(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
